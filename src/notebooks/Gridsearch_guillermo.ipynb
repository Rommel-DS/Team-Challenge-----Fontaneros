{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "import Toolbox as tb\n",
    "from Toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "data = pd.read_csv(\"../data/wines_dataset.csv\", sep=\"|\")\n",
    "\n",
    "\"\"\"\n",
    "División de datos en entrenamiento y prueba.\n",
    "\n",
    "Se toma el 80% de los datos para entrenamiento y el 20% restante para prueba.\n",
    "\n",
    "Parámetros:\n",
    "- test_size (float): Proporción del conjunto de prueba (0.2 = 20% de los datos).\n",
    "- random_state (int): Semilla para la reproducibilidad de la división.\n",
    "\n",
    "Salida:\n",
    "- train (DataFrame): Conjunto de entrenamiento.\n",
    "- test (DataFrame): Conjunto de prueba.\n",
    "\"\"\"\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "Guardado de los conjuntos de datos en archivos CSV.\n",
    "\n",
    "Los archivos se almacenan en la carpeta \"../data/\" con los nombres:\n",
    "- wines_train.csv → Contiene el 80% de los datos para entrenamiento.\n",
    "- wines_test.csv → Contiene el 20% de los datos para prueba.\n",
    "\n",
    "index=False evita que se guarde el índice en los archivos.\n",
    "\"\"\"\n",
    "train.to_csv(os.path.join(\"../data/\", 'wines_train.csv'), index=False)\n",
    "test.to_csv(os.path.join(\"../data/\", 'wines_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.049</td>\n",
       "      <td>38.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99600</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.93</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.74</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.044</td>\n",
       "      <td>44.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.040</td>\n",
       "      <td>10.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.053</td>\n",
       "      <td>37.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99489</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.99604</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.58</td>\n",
       "      <td>11.9</td>\n",
       "      <td>7</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>0.047</td>\n",
       "      <td>60.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.05</td>\n",
       "      <td>0.058</td>\n",
       "      <td>25.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.99856</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.052</td>\n",
       "      <td>30.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.99470</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.032</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.98889</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.35</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.039</td>\n",
       "      <td>50.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.99165</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.3</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.9              0.18         0.40            2.20      0.049   \n",
       "1               7.1              0.18         0.74           15.60      0.044   \n",
       "2               7.6              0.51         0.24            1.20      0.040   \n",
       "3               6.0              0.25         0.28            7.70      0.053   \n",
       "4               9.0              0.38         0.41            2.40      0.103   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "5192            6.4              0.24         0.50           11.60      0.047   \n",
       "5193            6.6              0.22         0.28           12.05      0.058   \n",
       "5194            6.6              0.20         0.38            7.90      0.052   \n",
       "5195            7.3              0.41         0.29            1.80      0.032   \n",
       "5196            5.9              0.18         0.28            5.10      0.039   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    38.0                  67.0  0.99600  3.33       0.93   \n",
       "1                    44.0                 176.0  0.99960  3.38       0.67   \n",
       "2                    10.0                 104.0  0.99200  3.05       0.29   \n",
       "3                    37.0                 132.0  0.99489  3.06       0.50   \n",
       "4                     6.0                  10.0  0.99604  3.13       0.58   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "5192                 60.0                 211.0  0.99660  3.18       0.57   \n",
       "5193                 25.0                 125.0  0.99856  3.45       0.45   \n",
       "5194                 30.0                 145.0  0.99470  3.32       0.56   \n",
       "5195                 26.0                  74.0  0.98889  2.96       0.35   \n",
       "5196                 50.0                 139.0  0.99165  3.16       0.44   \n",
       "\n",
       "      alcohol  quality  class  \n",
       "0        11.3        5    red  \n",
       "1         9.0        6  white  \n",
       "2        10.8        6  white  \n",
       "3         9.4        6  white  \n",
       "4        11.9        7    red  \n",
       "...       ...      ...    ...  \n",
       "5192      9.3        5  white  \n",
       "5193      9.4        5  white  \n",
       "5194     11.0        7  white  \n",
       "5195     13.0        8  white  \n",
       "5196     11.3        6  white  \n",
       "\n",
       "[5197 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de entrenamiento desde el archivo CSV\n",
    "df = pd.read_csv(\"../data/wines_train.csv\")\n",
    "\n",
    "# Mostrar el DataFrame cargado\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.049</td>\n",
       "      <td>38.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99335</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.034</td>\n",
       "      <td>29.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99031</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.026</td>\n",
       "      <td>43.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99040</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.038</td>\n",
       "      <td>58.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.98930</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.063</td>\n",
       "      <td>32.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>11.6</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.147</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99836</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.052</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99458</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.073</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99425</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.036</td>\n",
       "      <td>38.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.99622</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.320         0.27             1.4      0.049   \n",
       "1               6.6             0.340         0.24             3.3      0.034   \n",
       "2               6.4             0.320         0.35             4.8      0.030   \n",
       "3               6.8             0.230         0.32             1.6      0.026   \n",
       "4               6.7             0.340         0.26             1.9      0.038   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1295            7.6             0.285         0.32            14.6      0.063   \n",
       "1296           11.6             0.470         0.44             1.6      0.147   \n",
       "1297           10.2             0.340         0.48             2.1      0.052   \n",
       "1298            6.2             0.460         0.17             1.6      0.073   \n",
       "1299            6.2             0.360         0.14             8.9      0.036   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    38.0                 173.0  0.99335  3.03       0.52   \n",
       "1                    29.0                  99.0  0.99031  3.10       0.40   \n",
       "2                    34.0                 101.0  0.99120  3.36       0.60   \n",
       "3                    43.0                 147.0  0.99040  3.29       0.54   \n",
       "4                    58.0                 138.0  0.98930  3.00       0.47   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1295                 32.0                 201.0  0.99800  3.00       0.45   \n",
       "1296                 36.0                  51.0  0.99836  3.38       0.86   \n",
       "1297                  5.0                   9.0  0.99458  3.20       0.69   \n",
       "1298                  7.0                  11.0  0.99425  3.61       0.54   \n",
       "1299                 38.0                 155.0  0.99622  3.27       0.50   \n",
       "\n",
       "      alcohol  quality  class  \n",
       "0         9.3        5  white  \n",
       "1        12.3        7  white  \n",
       "2        12.5        8  white  \n",
       "3        12.5        6  white  \n",
       "4        12.2        7  white  \n",
       "...       ...      ...    ...  \n",
       "1295      9.2        5  white  \n",
       "1296      9.9        4    red  \n",
       "1297     12.1        7    red  \n",
       "1298     11.4        5    red  \n",
       "1299      9.4        5  white  \n",
       "\n",
       "[1300 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de prueba desde el archivo CSV\n",
    "df_test = pd.read_csv(\"../data/wines_test.csv\")\n",
    "\n",
    "# Mostrar el DataFrame cargado\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COL_N</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>100</td>\n",
       "      <td>177</td>\n",
       "      <td>87</td>\n",
       "      <td>308</td>\n",
       "      <td>194</td>\n",
       "      <td>132</td>\n",
       "      <td>274</td>\n",
       "      <td>951</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COL_N         fixed acidity volatile acidity citric acid residual sugar  \\\n",
       "DATA_TYPE           float64          float64     float64        float64   \n",
       "MISSINGS (%)            0.0              0.0         0.0            0.0   \n",
       "UNIQUE_VALUES           100              177          87            308   \n",
       "CARDIN (%)             0.02             0.03        0.02           0.06   \n",
       "\n",
       "COL_N         chlorides free sulfur dioxide total sulfur dioxide  density  \\\n",
       "DATA_TYPE       float64             float64              float64  float64   \n",
       "MISSINGS (%)        0.0                 0.0                  0.0      0.0   \n",
       "UNIQUE_VALUES       194                 132                  274      951   \n",
       "CARDIN (%)         0.04                0.03                 0.05     0.18   \n",
       "\n",
       "COL_N               pH sulphates  alcohol quality   class  \n",
       "DATA_TYPE      float64   float64  float64   int64  object  \n",
       "MISSINGS (%)       0.0       0.0      0.0     0.0     0.0  \n",
       "UNIQUE_VALUES      106       106      102       7       2  \n",
       "CARDIN (%)        0.02      0.02     0.02     0.0     0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genera un resumen descriptivo del DataFrame utilizando la función tb.describe_df(df).\n",
    "# \n",
    "#  Muestra información sobre:\n",
    "#    - DATA_TYPE: Tipo de dato de cada columna (numérico, categórico, etc.).\n",
    "#    - MISSINGS (%): Porcentaje de valores nulos en cada columna.\n",
    "#    - UNIQUE_VALUES: Cantidad de valores únicos en cada columna.\n",
    "#    - CARDIN (%): Cardinalidad relativa (valores únicos / total de filas).\n",
    "# \n",
    "# Útil para comprender la estructura de los datos antes del preprocesamiento.\n",
    "\n",
    "tb.describe_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variables objetivo para el análisis:\n",
    "\n",
    "# target_clf = \"quality\" → Problema de Clasificación\n",
    "#    - La variable `quality` representa la calidad del vino.\n",
    "#    - Es una variable categórica con 7 valores únicos (multiclase).\n",
    "#    - Se utilizarán modelos de clasificación, como RandomForestClassifier o XGBoost.\n",
    "#    - Es necesario aplicar OneHotEncoder a variables categóricas y StandardScaler a las numéricas.\n",
    "\n",
    "# target_reg = \"alcohol\" → Problema de Regresión\n",
    "#    - La variable `alcohol` indica el porcentaje de alcohol en el vino.\n",
    "#    - Es una variable numérica continua.\n",
    "#    - Se utilizarán modelos de regresión, como RandomForestRegressor o LinearRegression.\n",
    "#    - Requiere escalado de las variables numéricas (StandardScaler) y codificación de las categóricas (OneHotEncoder).\n",
    "\n",
    "# 📌 Ambos problemas requieren preprocesamiento adecuado según el tipo de modelo utilizado.\n",
    "\n",
    "target_clf = \"quality\"\n",
    "target_reg = \"alcohol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las características (features) utilizadas en la clasificación:\n",
    "\n",
    "# features_cat_clf → Variables categóricas\n",
    "#    - Contiene solo la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables numéricas.\n",
    "\n",
    "# features_num_clf_1 → Variables numéricas principales\n",
    "#    - Incluye medidas químicas clave como \"volatile acidity\", \"chlorides\", \"density\", \"pH\", etc.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas características.\n",
    "\n",
    "# features_num_clf_2 → Variables numéricas adicionales\n",
    "#    - Contiene \"fixed acidity\" y \"residual sugar\".\n",
    "#    - Estas características pueden ser analizadas por separado o combinadas con las anteriores.\n",
    "\n",
    "features_cat_clf = [\"class\"]\n",
    "features_num_clf_1 = [\"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "                      \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]\n",
    "features_num_clf_2 = [\"fixed acidity\", \"residual sugar\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de características (features) para el problema de regresión:\n",
    "\n",
    "# features_cat_reg → Variables categóricas\n",
    "#    - Contiene \"class\" (tipo de vino: tinto o blanco) y \"quality\" (calidad del vino).\n",
    "#    - Estas variables deben ser transformadas con OneHotEncoder.\n",
    "\n",
    "# features_num_reg → Variables numéricas\n",
    "#    - Se seleccionan todas las columnas del DataFrame excepto las categóricas.\n",
    "#    - Esto se logra con una lista por comprensión, excluyendo las columnas en features_cat_reg.\n",
    "#    - Estas variables deben ser escaladas con StandardScaler.\n",
    "\n",
    "features_cat_reg = [\"class\", \"quality\"]\n",
    "features_num_reg = [col for col in df.columns if col not in features_cat_reg]\n",
    "\n",
    "# Ahora features_num_reg contiene solo las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                 1.000000\n",
       "density                 0.682345\n",
       "residual sugar          0.357459\n",
       "total sulfur dioxide    0.272970\n",
       "chlorides               0.260508\n",
       "free sulfur dioxide     0.188460\n",
       "pH                      0.116497\n",
       "fixed acidity           0.091964\n",
       "volatile acidity        0.036041\n",
       "citric acid             0.005690\n",
       "sulphates               0.000412\n",
       "Name: alcohol, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudio de correlaciones entre las variables numéricas y la variable objetivo de regresión.\n",
    "\n",
    "# Calculamos la matriz de correlación solo para las variables numéricas.\n",
    "#    - Se utiliza df[features_num_reg] para excluir las variables categóricas.\n",
    "#    - numeric_only=\"True\" se usa para evitar advertencias en versiones recientes de pandas.\n",
    "\n",
    "# Extraemos la correlación absoluta de cada variable con el target de regresión (\"alcohol\").\n",
    "#    - np.abs() se usa para obtener la magnitud de la correlación sin importar el signo.\n",
    "#    - .sort_values(ascending=False) ordena las variables de mayor a menor correlación.\n",
    "\n",
    "corr = df[features_num_reg].corr(numeric_only=\"True\")\n",
    "serie_corr = np.abs(corr[target_reg]).sort_values(ascending=False)\n",
    "serie_corr\n",
    "\n",
    "# Ahora, serie_corr contiene las variables ordenadas según su grado de correlación con \"alcohol\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características numéricas basadas en la correlación con el target de regresión.\n",
    "\n",
    "# Definimos un umbral mínimo de correlación.\n",
    "#    - r_min = 0.05 significa que solo seleccionaremos variables con correlación mayor a 0.05.\n",
    "\n",
    "r_min = 0.05\n",
    "\n",
    "# Seleccionamos las variables numéricas con correlación significativa con el target.\n",
    "#    - Tomamos solo las variables con correlación absoluta mayor que r_min.\n",
    "#    - Convertimos los nombres de las columnas en una lista.\n",
    "#    - Eliminamos el target (\"alcohol\") de la lista, ya que no es una feature.\n",
    "\n",
    "features_num_reg_1 = serie_corr[serie_corr > r_min].index.to_list()\n",
    "features_num_reg_1.remove(target_reg)\n",
    "\n",
    "# Identificamos las variables numéricas con correlación baja o nula con el target.\n",
    "#    - Excluimos las variables en features_num_reg_1.\n",
    "#    - Excluimos el target y las variables categóricas.\n",
    "\n",
    "features_num_reg_2 = [col for col in df.columns if col not in features_num_reg_1 and col != target_reg\n",
    "                       and col not in features_cat_reg]\n",
    "\n",
    "# Ahora:\n",
    "# - features_num_reg_1 contiene las variables más correlacionadas con \"alcohol\".\n",
    "# - features_num_reg_2 contiene las variables menos correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quality'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición del problema de clasificación.\n",
    "\n",
    "# target_clf → Variable objetivo para clasificación.\n",
    "#    - Se ha definido previamente como \"quality\".\n",
    "#    - Representa la calidad del vino en una escala categórica.\n",
    "#    - Es un problema de clasificación **multiclase** (7 categorías posibles).\n",
    "\n",
    "target_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de las características categóricas para el problema de clasificación.\n",
    "\n",
    "# features_cat_clf → Variables categóricas a incluir en el modelo de clasificación.\n",
    "#    - Contiene la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables numéricas.\n",
    "\n",
    "features_cat_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity',\n",
       " 'citric acid',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de características numéricas principales para clasificación.\n",
    "\n",
    "# features_num_clf_1 → Variables numéricas seleccionadas para el modelo de clasificación.\n",
    "#    - Incluye medidas químicas clave del vino:\n",
    "#      - \"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "#      - \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\".\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas características antes del modelado.\n",
    "\n",
    "features_num_clf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alcohol'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición del problema de regresión.\n",
    "\n",
    "# target_reg → Variable objetivo para regresión.\n",
    "#    - Se ha definido previamente como \"alcohol\".\n",
    "#    - Representa el porcentaje de alcohol en el vino (variable continua).\n",
    "#    - Es un problema de regresión, ya que el target es numérico y continuo.\n",
    "\n",
    "target_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'quality']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de las características categóricas para el problema de regresión.\n",
    "\n",
    "# features_cat_reg → Variables categóricas a incluir en el modelo de regresión.\n",
    "#    - Contiene:\n",
    "#      - \"class\" (tipo de vino: tinto o blanco).\n",
    "#      - \"quality\" (calidad del vino en una escala categórica).\n",
    "#    - Ambas variables deben ser transformadas con OneHotEncoder para su uso en modelos numéricos.\n",
    "\n",
    "features_cat_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de características numéricas principales para regresión.\n",
    "\n",
    "# features_num_reg_1 → Variables numéricas con mayor correlación con el target de regresión (\"alcohol\").\n",
    "#    - Se han seleccionado aquellas con correlación absoluta > r_min (0.05).\n",
    "#    - Estas variables son las más relevantes para predecir el contenido de alcohol en el vino.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas características antes del modelado.\n",
    "\n",
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity', 'residual sugar']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definición de columnas a incluir y excluir en el modelo de clasificación.\n",
    "\n",
    "# columns_to_keep_clf → Columnas que se mantendrán en el modelo de clasificación.\n",
    "#    - Incluye:\n",
    "#      - target_clf (variable objetivo de clasificación: \"quality\").\n",
    "#      - features_num_clf_1 (variables numéricas relevantes).\n",
    "#      - features_cat_clf (variables categóricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_clf → Columnas que se excluirán del modelo de clasificación.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_clf.\n",
    "#    - Estas columnas no serán utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_clf = [target_clf] + features_num_clf_1 + features_cat_clf\n",
    "\n",
    "columns_to_exclude_clf = [col for col in df.columns if col not in columns_to_keep_clf]\n",
    "\n",
    "columns_to_exclude_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity', 'citric acid', 'sulphates']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de columnas a incluir y excluir en el modelo de regresión.\n",
    "\n",
    "# columns_to_keep_reg → Columnas que se mantendrán en el modelo de regresión.\n",
    "#    - Incluye:\n",
    "#      - target_reg (variable objetivo de regresión: \"alcohol\").\n",
    "#      - features_num_reg_1 (variables numéricas más correlacionadas con el target).\n",
    "#      - features_cat_reg (variables categóricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_reg → Columnas que se excluirán del modelo de regresión.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_reg.\n",
    "#    - Estas columnas no serán utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_reg = [target_reg] + features_num_reg_1 + features_cat_reg\n",
    "\n",
    "columns_to_exclude_reg = [col for col in df.columns if col not in columns_to_keep_reg]\n",
    "\n",
    "columns_to_exclude_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definición de Pipelines para preprocesamiento de datos en clasificación.\n",
    "\n",
    "# cat_pipeline → Preprocesamiento de variables categóricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor más frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categorías desconocidas.\n",
    "\n",
    "# logaritmica → Transformación logarítmica de variables numéricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las características.\n",
    "\n",
    "# num_pipeline → Preprocesamiento de variables numéricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformación logarítmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables numéricas.\n",
    "\n",
    "# imputer_step_cat → ColumnTransformer para aplicar los Pipelines según el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_clf_1 (variables numéricas).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_clf (variables categóricas).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_clf.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_cat → Pipeline final que aplica el ColumnTransformer imputer_step_cat.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputación con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categorías desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") \n",
    "# Esto le indica al Pipeline que el número de características no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_cat = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_clf_1), # feature_numericas seleccionadas para clasificación\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_clf), # feature_categoriacas seleccionadas para regresión\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_clf)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_cat = Pipeline([(\"first_stage\", imputer_step_cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definición de Pipelines para preprocesamiento de datos en regresión.\n",
    "\n",
    "# cat_pipeline → Preprocesamiento de variables categóricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor más frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categorías desconocidas.\n",
    "\n",
    "# logaritmica → Transformación logarítmica de variables numéricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las características.\n",
    "\n",
    "# num_pipeline → Preprocesamiento de variables numéricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformación logarítmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables numéricas.\n",
    "\n",
    "# imputer_step_reg → ColumnTransformer para aplicar los Pipelines según el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_reg_1 (variables numéricas seleccionadas para regresión).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_reg (variables categóricas seleccionadas para regresión).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_reg.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_reg → Pipeline final que aplica el ColumnTransformer imputer_step_reg.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputación con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categorías desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") # Esto le indica al Pipeline que el número de características no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_reg = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_reg_1), # feature_numericas seleccionadas para clasificación\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_reg), # feature_categoriacas seleccionadas para regresión\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_reg)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_reg = Pipeline([(\"first_stage\", imputer_step_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06561088, -0.27783928, -0.1913355 , ...,  0.        ,\n",
       "         1.        ,  5.        ],\n",
       "       [ 0.061259  , -0.49980343, -0.57998343, ...,  0.        ,\n",
       "         1.        ,  7.        ],\n",
       "       [-0.06561088,  0.2893635 , -0.68457525, ...,  0.        ,\n",
       "         1.        ,  8.        ],\n",
       "       ...,\n",
       "       [ 0.061259  ,  1.14300849, -0.11427313, ...,  1.        ,\n",
       "         0.        ,  7.        ],\n",
       "       [ 0.78484693, -1.03933617,  0.41908799, ...,  1.        ,\n",
       "         0.        ,  5.        ],\n",
       "       [ 0.18624926, -1.28052007, -0.52783916, ...,  0.        ,\n",
       "         1.        ,  5.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicación del pipeline de preprocesamiento a los datos de prueba.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df_test)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificación.\n",
    "#    - Imputa valores faltantes en variables numéricas y categóricas.\n",
    "#    - Transforma variables categóricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformación logarítmica a las variables numéricas.\n",
    "\n",
    "# pipe_df_test → Contiene los datos de prueba preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df_test = pipe_missings_cat.fit_transform(df_test)\n",
    "\n",
    "pipe_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05515355,  0.59288805, -0.20549433, ...,  1.        ,\n",
       "         0.        ,  5.        ],\n",
       "       [-1.05515355,  2.5608768 , -0.37024226, ...,  0.        ,\n",
       "         1.        ,  6.        ],\n",
       "       [ 1.11199789, -0.50565223, -0.5026097 , ...,  0.        ,\n",
       "         1.        ,  6.        ],\n",
       "       ...,\n",
       "       [-0.90744764,  0.46264335, -0.10702207, ...,  0.        ,\n",
       "         1.        ,  7.        ],\n",
       "       [ 0.5098244 , -0.14782501, -0.7688788 , ...,  0.        ,\n",
       "         1.        ,  8.        ],\n",
       "       [-1.05515355, -0.21826777, -0.53578111, ...,  0.        ,\n",
       "         1.        ,  6.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicación del pipeline de preprocesamiento a los datos de entrenamiento.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificación.\n",
    "#    - Imputa valores faltantes en variables numéricas y categóricas.\n",
    "#    - Transforma variables categóricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformación logarítmica a las variables numéricas.\n",
    "\n",
    "# pipe_df → Contiene los datos de entrenamiento preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df = pipe_missings_cat.fit_transform(df)\n",
    "pipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "      <th>remainder__quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>0.592888</td>\n",
       "      <td>-0.205494</td>\n",
       "      <td>0.603446</td>\n",
       "      <td>-0.505241</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.706744</td>\n",
       "      <td>2.584726</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>2.560877</td>\n",
       "      <td>-0.370242</td>\n",
       "      <td>0.820606</td>\n",
       "      <td>0.855001</td>\n",
       "      <td>1.621578</td>\n",
       "      <td>1.011233</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>-1.312752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.111998</td>\n",
       "      <td>-0.505652</td>\n",
       "      <td>-0.502610</td>\n",
       "      <td>-1.317236</td>\n",
       "      <td>0.112504</td>\n",
       "      <td>-0.901360</td>\n",
       "      <td>-1.066182</td>\n",
       "      <td>-1.830435</td>\n",
       "      <td>0.312635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.548692</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.074260</td>\n",
       "      <td>0.564028</td>\n",
       "      <td>0.448623</td>\n",
       "      <td>0.059153</td>\n",
       "      <td>-1.000780</td>\n",
       "      <td>-0.177558</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320822</td>\n",
       "      <td>0.657314</td>\n",
       "      <td>1.525362</td>\n",
       "      <td>-2.003136</td>\n",
       "      <td>-3.095378</td>\n",
       "      <td>0.440977</td>\n",
       "      <td>-0.547423</td>\n",
       "      <td>0.391872</td>\n",
       "      <td>1.187890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>-0.619281</td>\n",
       "      <td>1.217401</td>\n",
       "      <td>-0.271299</td>\n",
       "      <td>1.282255</td>\n",
       "      <td>1.111562</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>-0.228277</td>\n",
       "      <td>0.322290</td>\n",
       "      <td>-1.022479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>-0.762183</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>0.089083</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>0.371746</td>\n",
       "      <td>1.276901</td>\n",
       "      <td>1.431729</td>\n",
       "      <td>-0.549087</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>-0.907448</td>\n",
       "      <td>0.462643</td>\n",
       "      <td>-0.107022</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.581225</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>0.645425</td>\n",
       "      <td>0.252264</td>\n",
       "      <td>0.477685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0.509824</td>\n",
       "      <td>-0.147825</td>\n",
       "      <td>-0.768879</td>\n",
       "      <td>0.045414</td>\n",
       "      <td>-0.365924</td>\n",
       "      <td>-1.936549</td>\n",
       "      <td>-1.662178</td>\n",
       "      <td>-1.332210</td>\n",
       "      <td>1.991478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.535781</td>\n",
       "      <td>1.010544</td>\n",
       "      <td>0.521557</td>\n",
       "      <td>-1.017779</td>\n",
       "      <td>-0.355475</td>\n",
       "      <td>-0.624929</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -1.055154                      0.592888   \n",
       "1                             -1.055154                      2.560877   \n",
       "2                              1.111998                     -0.505652   \n",
       "3                             -0.548692                     -0.218268   \n",
       "4                              0.320822                      0.657314   \n",
       "...                                 ...                           ...   \n",
       "5192                          -0.619281                      1.217401   \n",
       "5193                          -0.762183                     -0.218268   \n",
       "5194                          -0.907448                      0.462643   \n",
       "5195                           0.509824                     -0.147825   \n",
       "5196                          -1.055154                     -0.218268   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.205494                              0.603446   \n",
       "1                      -0.370242                              0.820606   \n",
       "2                      -0.502610                             -1.317236   \n",
       "3                      -0.074260                              0.564028   \n",
       "4                       1.525362                             -2.003136   \n",
       "...                          ...                                   ...   \n",
       "5192                   -0.271299                              1.282255   \n",
       "5193                    0.089083                             -0.011858   \n",
       "5194                   -0.107022                              0.255061   \n",
       "5195                   -0.768879                              0.045414   \n",
       "5196                   -0.535781                              1.010544   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                 -0.505241                  0.427700   \n",
       "1                                  0.855001                  1.621578   \n",
       "2                                  0.112504                 -0.901360   \n",
       "3                                  0.448623                  0.059153   \n",
       "4                                 -3.095378                  0.440977   \n",
       "...                                     ...                       ...   \n",
       "5192                               1.111562                  0.626829   \n",
       "5193                               0.371746                  1.276901   \n",
       "5194                               0.581225                 -0.003952   \n",
       "5195                              -0.365924                 -1.936549   \n",
       "5196                               0.521557                 -1.017779   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0                0.706744                    2.584726   \n",
       "1                1.011233                    0.998990   \n",
       "2               -1.066182                   -1.830435   \n",
       "3               -1.000780                   -0.177558   \n",
       "4               -0.547423                    0.391872   \n",
       "...                   ...                         ...   \n",
       "5192            -0.228277                    0.322290   \n",
       "5193             1.431729                   -0.549087   \n",
       "5194             0.645425                    0.252264   \n",
       "5195            -1.662178                   -1.332210   \n",
       "5196            -0.355475                   -0.624929   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                     0.720172                             1.0   \n",
       "1                    -1.312752                             0.0   \n",
       "2                     0.312635                             0.0   \n",
       "3                    -0.927596                             0.0   \n",
       "4                     1.187890                             1.0   \n",
       "...                        ...                             ...   \n",
       "5192                 -1.022479                             0.0   \n",
       "5193                 -0.927596                             0.0   \n",
       "5194                  0.477685                             0.0   \n",
       "5195                  1.991478                             0.0   \n",
       "5196                  0.720172                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  remainder__quality  \n",
       "0                                  0.0                 5.0  \n",
       "1                                  1.0                 6.0  \n",
       "2                                  1.0                 6.0  \n",
       "3                                  1.0                 6.0  \n",
       "4                                  0.0                 7.0  \n",
       "...                                ...                 ...  \n",
       "5192                               1.0                 5.0  \n",
       "5193                               1.0                 5.0  \n",
       "5194                               1.0                 7.0  \n",
       "5195                               1.0                 8.0  \n",
       "5196                               1.0                 6.0  \n",
       "\n",
       "[5197 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversión de los datos preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos preprocesados (pipe_df) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las características generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check → Contiene los datos de entrenamiento preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check = pd.DataFrame(pipe_df, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "      <th>remainder__quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>-0.277839</td>\n",
       "      <td>-0.191336</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.831639</td>\n",
       "      <td>-0.433274</td>\n",
       "      <td>-1.146519</td>\n",
       "      <td>-0.036117</td>\n",
       "      <td>-1.034552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.499803</td>\n",
       "      <td>-0.579983</td>\n",
       "      <td>0.200694</td>\n",
       "      <td>0.019098</td>\n",
       "      <td>-1.467980</td>\n",
       "      <td>-0.701377</td>\n",
       "      <td>-0.919534</td>\n",
       "      <td>1.489510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>0.289363</td>\n",
       "      <td>-0.684575</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>-1.164893</td>\n",
       "      <td>0.887973</td>\n",
       "      <td>0.514885</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.661389</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>-0.789574</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.594218</td>\n",
       "      <td>-1.437325</td>\n",
       "      <td>0.469593</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.351239</td>\n",
       "      <td>-0.475795</td>\n",
       "      <td>1.255666</td>\n",
       "      <td>0.502182</td>\n",
       "      <td>-1.812097</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.395421</td>\n",
       "      <td>1.414987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>-0.292330</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>0.166421</td>\n",
       "      <td>0.349361</td>\n",
       "      <td>1.050532</td>\n",
       "      <td>1.146368</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.542576</td>\n",
       "      <td>-1.130887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.842435</td>\n",
       "      <td>0.888607</td>\n",
       "      <td>2.218732</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>-0.940203</td>\n",
       "      <td>1.268510</td>\n",
       "      <td>1.006277</td>\n",
       "      <td>2.132366</td>\n",
       "      <td>-0.475482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>1.143008</td>\n",
       "      <td>-0.114273</td>\n",
       "      <td>-2.309748</td>\n",
       "      <td>-3.358761</td>\n",
       "      <td>-0.015075</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>1.102750</td>\n",
       "      <td>1.339897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>0.784847</td>\n",
       "      <td>-1.039336</td>\n",
       "      <td>0.419088</td>\n",
       "      <td>-1.861014</td>\n",
       "      <td>-3.091298</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>2.329225</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>0.797644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>0.186249</td>\n",
       "      <td>-1.280520</td>\n",
       "      <td>-0.527839</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.542123</td>\n",
       "      <td>0.348801</td>\n",
       "      <td>-0.178400</td>\n",
       "      <td>-0.939147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -0.065611                     -0.277839   \n",
       "1                              0.061259                     -0.499803   \n",
       "2                             -0.065611                      0.289363   \n",
       "3                             -0.661389                      0.080702   \n",
       "4                              0.061259                     -0.351239   \n",
       "...                                 ...                           ...   \n",
       "1295                          -0.292330                      0.080702   \n",
       "1296                           0.842435                      0.888607   \n",
       "1297                           0.061259                      1.143008   \n",
       "1298                           0.784847                     -1.039336   \n",
       "1299                           0.186249                     -1.280520   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.191336                              0.609936   \n",
       "1                      -0.579983                              0.200694   \n",
       "2                      -0.684575                              0.441142   \n",
       "3                      -0.789574                              0.798095   \n",
       "4                      -0.475795                              1.255666   \n",
       "...                          ...                                   ...   \n",
       "1295                    0.166421                              0.349361   \n",
       "1296                    2.218732                              0.527821   \n",
       "1297                   -0.114273                             -2.309748   \n",
       "1298                    0.419088                             -1.861014   \n",
       "1299                   -0.527839                              0.609936   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                  0.831639                 -0.433274   \n",
       "1                                  0.019098                 -1.467980   \n",
       "2                                  0.048148                 -1.164893   \n",
       "3                                  0.594218                 -1.437325   \n",
       "4                                  0.502182                 -1.812097   \n",
       "...                                     ...                       ...   \n",
       "1295                               1.050532                  1.146368   \n",
       "1296                              -0.940203                  1.268510   \n",
       "1297                              -3.358761                 -0.015075   \n",
       "1298                              -3.091298                 -0.127250   \n",
       "1299                               0.671446                  0.542123   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0               -1.146519                   -0.036117   \n",
       "1               -0.701377                   -0.919534   \n",
       "2                0.887973                    0.514885   \n",
       "3                0.469593                    0.104306   \n",
       "4               -1.339665                   -0.395421   \n",
       "...                   ...                         ...   \n",
       "1295            -1.339665                   -0.542576   \n",
       "1296             1.006277                    2.132366   \n",
       "1297            -0.078471                    1.102750   \n",
       "1298             2.329225                    0.104306   \n",
       "1299             0.348801                   -0.178400   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                    -1.034552                             0.0   \n",
       "1                     1.489510                             0.0   \n",
       "2                     1.636890                             0.0   \n",
       "3                     1.636890                             0.0   \n",
       "4                     1.414987                             0.0   \n",
       "...                        ...                             ...   \n",
       "1295                 -1.130887                             0.0   \n",
       "1296                 -0.475482                             1.0   \n",
       "1297                  1.339897                             1.0   \n",
       "1298                  0.797644                             1.0   \n",
       "1299                 -0.939147                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  remainder__quality  \n",
       "0                                  1.0                 5.0  \n",
       "1                                  1.0                 7.0  \n",
       "2                                  1.0                 8.0  \n",
       "3                                  1.0                 6.0  \n",
       "4                                  1.0                 7.0  \n",
       "...                                ...                 ...  \n",
       "1295                               1.0                 5.0  \n",
       "1296                               0.0                 4.0  \n",
       "1297                               0.0                 7.0  \n",
       "1298                               0.0                 5.0  \n",
       "1299                               1.0                 5.0  \n",
       "\n",
       "[1300 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversión de los datos de prueba preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df_test, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos de prueba preprocesados (pipe_df_test) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las características generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check_test → Contiene los datos de prueba preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check_test = pd.DataFrame(pipe_df_test, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACIÓN DE MODELOS DE CLASIFICACIÓN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quality'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_check\n",
    "y_train = df[target_clf]\n",
    "X_test = df_check_test\n",
    "y_test = df_test[target_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelos_clasificacion(X_train_scaled, y_train):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa múltiples modelos de clasificación utilizando validación cruzada.\n",
    "    \"\"\"\n",
    "    model_names = [\n",
    "        \"Logistic Regression\", \"SVC\", \"Decision Tree\", \"Random Forest\", \"KNN\", \n",
    "        \"Gradient Boosting\", \"AdaBoost\", \"XGBoost\", \"LightGBM\", \"CatBoost\"\n",
    "    ]\n",
    "    model_set = [\n",
    "        LogisticRegression(max_iter=10000),\n",
    "        SVC(),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        KNeighborsClassifier(),\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        LGBMClassifier(random_state=42, verbose=-100),\n",
    "        CatBoostClassifier(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    ]\n",
    "    metricas_cv = {}\n",
    "    valores = []\n",
    "    for nombre, modelo in zip(model_names, model_set):\n",
    "        print(f\"Evaluando modelo: {nombre}...\")\n",
    "        try:\n",
    "            scores = cross_val_score(modelo, X_train_scaled, y_train, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "            metricas_cv[nombre] = scores\n",
    "            valores.append(np.mean(scores))\n",
    "        except Exception as e:\n",
    "            print(f\"Error con el modelo {nombre}: {e}\")\n",
    "            metricas_cv[nombre] = None\n",
    "            valores.append(-np.inf)\n",
    "    ganador = model_names[np.argmax(valores)]\n",
    "    print(f\"\\nEl modelo ganador es: {ganador} con una accuracy media de {np.max(valores):.4f}\\n\")\n",
    "    resultados_df = pd.DataFrame({\n",
    "        \"Modelo\": model_names,\n",
    "        \"Accuracy Media\": valores\n",
    "    }).sort_values(by=\"Accuracy Media\", ascending=False)\n",
    "    print(resultados_df)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=\"Accuracy Media\", y=\"Modelo\", data=resultados_df, palette=\"viridis\", hue=None)\n",
    "    plt.title(\"Comparación de Modelos - Accuracy Media\", fontsize=16)\n",
    "    plt.xlabel(\"Accuracy Media\", fontsize=12)\n",
    "    plt.ylabel(\"Modelos\", fontsize=12)\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelo: Logistic Regression...\n",
      "Evaluando modelo: SVC...\n",
      "Evaluando modelo: Decision Tree...\n",
      "Evaluando modelo: Random Forest...\n",
      "Evaluando modelo: KNN...\n",
      "Evaluando modelo: Gradient Boosting...\n",
      "Evaluando modelo: AdaBoost...\n",
      "Evaluando modelo: XGBoost...\n",
      "Error con el modelo XGBoost: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [3 4 5 6 7 8 9]\n",
      "\n",
      "Evaluando modelo: LightGBM...\n",
      "Evaluando modelo: CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "2 fits failed out of a total of 3.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: ./catboost_temp_fix\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El modelo ganador es: CatBoost con una accuracy media de nan\n",
      "\n",
      "                Modelo  Accuracy Media\n",
      "2        Decision Tree        1.000000\n",
      "5    Gradient Boosting        1.000000\n",
      "8             LightGBM        0.999038\n",
      "0  Logistic Regression        0.993650\n",
      "3        Random Forest        0.993458\n",
      "1                  SVC        0.993073\n",
      "4                  KNN        0.908986\n",
      "6             AdaBoost        0.771407\n",
      "7              XGBoost            -inf\n",
      "9             CatBoost             NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_10100\\174657.py:41: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"Accuracy Media\", y=\"Modelo\", data=resultados_df, palette=\"viridis\", hue=None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.999038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.993650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.993458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.993073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.908986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.771407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Accuracy Media\n",
       "2        Decision Tree        1.000000\n",
       "5    Gradient Boosting        1.000000\n",
       "8             LightGBM        0.999038\n",
       "0  Logistic Regression        0.993650\n",
       "3        Random Forest        0.993458\n",
       "1                  SVC        0.993073\n",
       "4                  KNN        0.908986\n",
       "6             AdaBoost        0.771407\n",
       "7              XGBoost            -inf\n",
       "9             CatBoost             NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelos_clasificacion(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACION DE MODELOS DE REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelos_regresion(X_train_scaled, y_train):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa múltiples modelos de regresión utilizando validación cruzada.\n",
    "    \"\"\"\n",
    "    model_names = [\n",
    "        \"Linear Regression\", \"Ridge\", \"Lasso\", \"SVR\", \"Decision Tree\", \"Random Forest\", \n",
    "        \"KNN\", \"Gradient Boosting\", \"AdaBoost\", \"XGBoost\", \"LightGBM\", \"CatBoost\"\n",
    "    ]\n",
    "    model_set = [\n",
    "        LinearRegression(),\n",
    "        Ridge(alpha=1.0),\n",
    "        Lasso(alpha=0.1),\n",
    "        SVR(),\n",
    "        DecisionTreeRegressor(random_state=42),\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        KNeighborsRegressor(),\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        AdaBoostRegressor(random_state=42),\n",
    "        XGBRegressor(random_state=42, eval_metric=\"rmse\"),\n",
    "        LGBMRegressor(random_state=42, verbose=-100),\n",
    "        CatBoostRegressor(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    ]\n",
    "    metricas_cv = {}\n",
    "    valores = []\n",
    "    for nombre, modelo in zip(model_names, model_set):\n",
    "        print(f\"Evaluando modelo: {nombre}...\")\n",
    "        try:\n",
    "            scores = cross_val_score(modelo, X_train_scaled, y_train, cv=3, scoring=\"r2\", n_jobs=-1)\n",
    "            metricas_cv[nombre] = scores\n",
    "            valores.append(np.mean(scores))\n",
    "        except Exception as e:\n",
    "            print(f\"Error con el modelo {nombre}: {e}\")\n",
    "            metricas_cv[nombre] = None\n",
    "            valores.append(-np.inf)\n",
    "    ganador = model_names[np.argmax(valores)]\n",
    "    print(f\"\\nEl modelo ganador es: {ganador} con un R^2 medio de {np.max(valores):.4f}\\n\")\n",
    "    resultados_df = pd.DataFrame({\n",
    "        \"Modelo\": model_names,\n",
    "        \"R^2 Medio\": valores\n",
    "    }).sort_values(by=\"R^2 Medio\", ascending=False)\n",
    "    print(resultados_df)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=\"R^2 Medio\", y=\"Modelo\", data=resultados_df, palette=\"viridis\", hue=None)\n",
    "    plt.title(\"Comparación de Modelos de Regresión - R^2 Medio\", fontsize=16)\n",
    "    plt.xlabel(\"R^2 Medio\", fontsize=12)\n",
    "    plt.ylabel(\"Modelos\", fontsize=12)\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARGUMENTOS A METER EN EL PIPELINE: TIPO_MODELO, CV, TOP_N (numero de modelos a los que quiero ahcer grid search) (podríamos tbn hacer una última función que hicera un grid_search mas extenso del ganador, con param_grids mas largos y cv mayor) (podriamos añadir alguna forma de obviar esta función y ir directamente a la última del grid_search largo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se si cambiaria la metrica de la regresion al rmse, mse o mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entiendo algunos parametros de XGBoost y CatBoost: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\") \n",
    "\"CatBoost\": CatBoostClassifier(random_state=42, verbose=False, train_dir='./catboost_temp_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def top_grid_search(df_resultados, X_train, y_train, tipo_modelo=\"clasificacion\", top_n=3, cv=5):\n",
    "    \"\"\"\n",
    "    Extrae los n mejores modelos obtenidos en cross-validation, les realiza GridSearchCV y devuelve el mejor modelo optimizado.\n",
    "\n",
    "    Parametros:\n",
    "    - df_resultados: DataFrame con los modelos y sus metricas.\n",
    "    - X_train, y_train: Datos de entrenamiento.\n",
    "    - tipo_modelo: \"clasificacion\" o \"regresion\".\n",
    "    - top_n: Numero de mejores modelos a seleccionar para el GridSearch.\n",
    "    - cv: Número de folds para la validación cruzada.\n",
    "\n",
    "    DEvuelve el nombre del mejor modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    metrica = \"Accuracy Media\" if tipo_modelo == \"clasificacion\" else \"R^2 Medio\"\n",
    "\n",
    "    modelos_clf = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "        \"SVC\": SVC(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        \"LightGBM\": LGBMClassifier(random_state=42, verbose=-100),\n",
    "        \"CatBoost\": CatBoostClassifier(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    }\n",
    "\n",
    "    modelos_reg = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"Lasso\": Lasso(alpha=0.1),\n",
    "        \"SVR\": SVR(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"KNN\": KNeighborsRegressor(),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "        \"AdaBoost\": AdaBoostRegressor(random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42, eval_metric=\"rmse\"),\n",
    "        \"LightGBM\": LGBMRegressor(random_state=42, verbose=-100),\n",
    "        \"CatBoost\": CatBoostRegressor(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    }\n",
    "\n",
    "    param_grids_clf = {\n",
    "        \"Logistic Regression\": {\"C\": [0.01, 0.1, 1, 10, 100], \"solver\": [\"liblinear\", \"lbfgs\"]},\n",
    "        \"SVC\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]},\n",
    "        \"Decision Tree\": {\"max_depth\": [3, 5, 10, None], \"min_samples_split\": [2, 5, 10], \"min_samples_leaf\": [1, 2, 5]},\n",
    "        \"Random Forest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, None], \"min_samples_split\": [2, 5, 10]},\n",
    "        \"KNN\": {\"n_neighbors\": [3, 5, 10], \"weights\": [\"uniform\", \"distance\"]},\n",
    "        \"Gradient Boosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2], \"max_depth\": [3, 5, 7]},\n",
    "        \"AdaBoost\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "        \"XGBoost\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"LightGBM\": {\"n_estimators\": [50, 100, 200], \"num_leaves\": [31, 50, 100], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"CatBoost\": {\"iterations\": [50, 100, 200], \"depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]}\n",
    "    }\n",
    "\n",
    "    param_grids_reg = {\n",
    "        \"Linear Regression\": {},\n",
    "        \"Ridge\": {\"alpha\": [0.01, 0.1, 1, 10, 100]},\n",
    "        \"Lasso\": {\"alpha\": [0.01, 0.1, 1, 10, 100]},\n",
    "        \"SVR\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]},\n",
    "        \"Decision Tree\": {\"max_depth\": [3, 5, 10, None], \"min_samples_split\": [2, 5, 10], \"min_samples_leaf\": [1, 2, 5]},\n",
    "        \"Random Forest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, None], \"min_samples_split\": [2, 5, 10]},\n",
    "        \"KNN\": {\"n_neighbors\": [3, 5, 10], \"weights\": [\"uniform\", \"distance\"]},\n",
    "        \"Gradient Boosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2], \"max_depth\": [3, 5, 7]},\n",
    "        \"AdaBoost\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "        \"XGBoost\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"LightGBM\": {\"n_estimators\": [50, 100, 200], \"num_leaves\": [31, 50, 100], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"CatBoost\": {\"iterations\": [50, 100, 200], \"depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]}\n",
    "    }\n",
    "\n",
    "    modelos = modelos_clf if tipo_modelo == \"clasificacion\" else modelos_reg\n",
    "    param_grids = param_grids_clf if tipo_modelo == \"clasificacion\" else param_grids_reg\n",
    "\n",
    "    top_modelos = df_resultados.nlargest(top_n, metrica)[\"Modelo\"].values\n",
    "\n",
    "    for i, modelo_nombre in enumerate(top_modelos):\n",
    "        modelo = modelos[modelo_nombre]\n",
    "        param_grid = param_grids[modelo_nombre]\n",
    "\n",
    "        grid_search = GridSearchCV(modelo, param_grid, cv=cv, scoring=\"accuracy\" if tipo_modelo == \"clasificacion\" else \"r2\", n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        if i == 0 or grid_search.best_score_ > mejor_puntaje:\n",
    "            mejor_modelo = modelo_nombre\n",
    "            mejor_puntaje = grid_search.best_score_\n",
    "            mejor_params = grid_search.best_params_\n",
    "\n",
    "    print(mejor_modelo)\n",
    "    print(mejor_puntaje)\n",
    "    print(mejor_params)\n",
    "\n",
    "    return mejor_modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
