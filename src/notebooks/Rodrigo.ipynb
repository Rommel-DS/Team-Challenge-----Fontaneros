{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "import Toolbox as tb\n",
    "from Toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "data = pd.read_csv(\"../data/wines_dataset.csv\", sep=\"|\")\n",
    "\n",
    "\"\"\"\n",
    "Divisi√≥n de datos en entrenamiento y prueba.\n",
    "\n",
    "Se toma el 80% de los datos para entrenamiento y el 20% restante para prueba.\n",
    "\n",
    "Par√°metros:\n",
    "- test_size (float): Proporci√≥n del conjunto de prueba (0.2 = 20% de los datos).\n",
    "- random_state (int): Semilla para la reproducibilidad de la divisi√≥n.\n",
    "\n",
    "Salida:\n",
    "- train (DataFrame): Conjunto de entrenamiento.\n",
    "- test (DataFrame): Conjunto de prueba.\n",
    "\"\"\"\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "Guardado de los conjuntos de datos en archivos CSV.\n",
    "\n",
    "Los archivos se almacenan en la carpeta \"../data/\" con los nombres:\n",
    "- wines_train.csv ‚Üí Contiene el 80% de los datos para entrenamiento.\n",
    "- wines_test.csv ‚Üí Contiene el 20% de los datos para prueba.\n",
    "\n",
    "index=False evita que se guarde el √≠ndice en los archivos.\n",
    "\"\"\"\n",
    "train.to_csv(os.path.join(\"../data/\", 'wines_train.csv'), index=False)\n",
    "test.to_csv(os.path.join(\"../data/\", 'wines_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos de entrenamiento desde el archivo CSV\n",
    "df = pd.read_csv(\"../data/wines_train.csv\")\n",
    "y_train_cat = df[\"quality\"]\n",
    "y_train_reg = df[\"alcohol\"]\n",
    "# Mostrar el DataFrame cargado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.049</td>\n",
       "      <td>38.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99335</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.034</td>\n",
       "      <td>29.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99031</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.026</td>\n",
       "      <td>43.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99040</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.038</td>\n",
       "      <td>58.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.98930</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.063</td>\n",
       "      <td>32.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>11.6</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.147</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99836</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.052</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99458</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.073</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99425</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.036</td>\n",
       "      <td>38.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.99622</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.320         0.27             1.4      0.049   \n",
       "1               6.6             0.340         0.24             3.3      0.034   \n",
       "2               6.4             0.320         0.35             4.8      0.030   \n",
       "3               6.8             0.230         0.32             1.6      0.026   \n",
       "4               6.7             0.340         0.26             1.9      0.038   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1295            7.6             0.285         0.32            14.6      0.063   \n",
       "1296           11.6             0.470         0.44             1.6      0.147   \n",
       "1297           10.2             0.340         0.48             2.1      0.052   \n",
       "1298            6.2             0.460         0.17             1.6      0.073   \n",
       "1299            6.2             0.360         0.14             8.9      0.036   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    38.0                 173.0  0.99335  3.03       0.52   \n",
       "1                    29.0                  99.0  0.99031  3.10       0.40   \n",
       "2                    34.0                 101.0  0.99120  3.36       0.60   \n",
       "3                    43.0                 147.0  0.99040  3.29       0.54   \n",
       "4                    58.0                 138.0  0.98930  3.00       0.47   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1295                 32.0                 201.0  0.99800  3.00       0.45   \n",
       "1296                 36.0                  51.0  0.99836  3.38       0.86   \n",
       "1297                  5.0                   9.0  0.99458  3.20       0.69   \n",
       "1298                  7.0                  11.0  0.99425  3.61       0.54   \n",
       "1299                 38.0                 155.0  0.99622  3.27       0.50   \n",
       "\n",
       "      alcohol  quality  class  \n",
       "0         9.3        5  white  \n",
       "1        12.3        7  white  \n",
       "2        12.5        8  white  \n",
       "3        12.5        6  white  \n",
       "4        12.2        7  white  \n",
       "...       ...      ...    ...  \n",
       "1295      9.2        5  white  \n",
       "1296      9.9        4    red  \n",
       "1297     12.1        7    red  \n",
       "1298     11.4        5    red  \n",
       "1299      9.4        5  white  \n",
       "\n",
       "[1300 rows x 13 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de prueba desde el archivo CSV\n",
    "df_test = pd.read_csv(\"../data/wines_test.csv\")\n",
    "y_test = df_test[\"quality\"]\n",
    "# Mostrar el DataFrame cargado\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COL_N</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>100</td>\n",
       "      <td>177</td>\n",
       "      <td>87</td>\n",
       "      <td>308</td>\n",
       "      <td>194</td>\n",
       "      <td>132</td>\n",
       "      <td>274</td>\n",
       "      <td>951</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COL_N         fixed acidity volatile acidity citric acid residual sugar  \\\n",
       "DATA_TYPE           float64          float64     float64        float64   \n",
       "MISSINGS (%)            0.0              0.0         0.0            0.0   \n",
       "UNIQUE_VALUES           100              177          87            308   \n",
       "CARDIN (%)             0.02             0.03        0.02           0.06   \n",
       "\n",
       "COL_N         chlorides free sulfur dioxide total sulfur dioxide  density  \\\n",
       "DATA_TYPE       float64             float64              float64  float64   \n",
       "MISSINGS (%)        0.0                 0.0                  0.0      0.0   \n",
       "UNIQUE_VALUES       194                 132                  274      951   \n",
       "CARDIN (%)         0.04                0.03                 0.05     0.18   \n",
       "\n",
       "COL_N               pH sulphates  alcohol quality   class  \n",
       "DATA_TYPE      float64   float64  float64   int64  object  \n",
       "MISSINGS (%)       0.0       0.0      0.0     0.0     0.0  \n",
       "UNIQUE_VALUES      106       106      102       7       2  \n",
       "CARDIN (%)        0.02      0.02     0.02     0.0     0.0  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genera un resumen descriptivo del DataFrame utilizando la funci√≥n tb.describe_df(df).\n",
    "# \n",
    "#  Muestra informaci√≥n sobre:\n",
    "#    - DATA_TYPE: Tipo de dato de cada columna (num√©rico, categ√≥rico, etc.).\n",
    "#    - MISSINGS (%): Porcentaje de valores nulos en cada columna.\n",
    "#    - UNIQUE_VALUES: Cantidad de valores √∫nicos en cada columna.\n",
    "#    - CARDIN (%): Cardinalidad relativa (valores √∫nicos / total de filas).\n",
    "# \n",
    "# √ötil para comprender la estructura de los datos antes del preprocesamiento.\n",
    "\n",
    "tb.describe_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de variables objetivo para el an√°lisis:\n",
    "\n",
    "# target_clf = \"quality\" ‚Üí Problema de Clasificaci√≥n\n",
    "#    - La variable `quality` representa la calidad del vino.\n",
    "#    - Es una variable categ√≥rica con 7 valores √∫nicos (multiclase).\n",
    "#    - Se utilizar√°n modelos de clasificaci√≥n, como RandomForestClassifier o XGBoost.\n",
    "#    - Es necesario aplicar OneHotEncoder a variables categ√≥ricas y StandardScaler a las num√©ricas.\n",
    "\n",
    "# target_reg = \"alcohol\" ‚Üí Problema de Regresi√≥n\n",
    "#    - La variable `alcohol` indica el porcentaje de alcohol en el vino.\n",
    "#    - Es una variable num√©rica continua.\n",
    "#    - Se utilizar√°n modelos de regresi√≥n, como RandomForestRegressor o LinearRegression.\n",
    "#    - Requiere escalado de las variables num√©ricas (StandardScaler) y codificaci√≥n de las categ√≥ricas (OneHotEncoder).\n",
    "\n",
    "# üìå Ambos problemas requieren preprocesamiento adecuado seg√∫n el tipo de modelo utilizado.\n",
    "\n",
    "target_clf = \"quality\"\n",
    "target_reg = \"alcohol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de las caracter√≠sticas (features) utilizadas en la clasificaci√≥n:\n",
    "\n",
    "# features_cat_clf ‚Üí Variables categ√≥ricas\n",
    "#    - Contiene solo la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables num√©ricas.\n",
    "\n",
    "# features_num_clf_1 ‚Üí Variables num√©ricas principales\n",
    "#    - Incluye medidas qu√≠micas clave como \"volatile acidity\", \"chlorides\", \"density\", \"pH\", etc.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas caracter√≠sticas.\n",
    "\n",
    "# features_num_clf_2 ‚Üí Variables num√©ricas adicionales\n",
    "#    - Contiene \"fixed acidity\" y \"residual sugar\".\n",
    "#    - Estas caracter√≠sticas pueden ser analizadas por separado o combinadas con las anteriores.\n",
    "\n",
    "features_cat_clf = [\"class\"]\n",
    "features_num_clf_1 = [\"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "                      \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]\n",
    "features_num_clf_2 = [\"fixed acidity\", \"residual sugar\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de caracter√≠sticas (features) para el problema de regresi√≥n:\n",
    "\n",
    "# features_cat_reg ‚Üí Variables categ√≥ricas\n",
    "#    - Contiene \"class\" (tipo de vino: tinto o blanco) y \"quality\" (calidad del vino).\n",
    "#    - Estas variables deben ser transformadas con OneHotEncoder.\n",
    "\n",
    "# features_num_reg ‚Üí Variables num√©ricas\n",
    "#    - Se seleccionan todas las columnas del DataFrame excepto las categ√≥ricas.\n",
    "#    - Esto se logra con una lista por comprensi√≥n, excluyendo las columnas en features_cat_reg.\n",
    "#    - Estas variables deben ser escaladas con StandardScaler.\n",
    "\n",
    "features_cat_reg = [\"class\", \"quality\"]\n",
    "features_num_reg = [col for col in df.columns if col not in features_cat_reg]\n",
    "\n",
    "# Ahora features_num_reg contiene solo las variables num√©ricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                 1.000000\n",
       "density                 0.682345\n",
       "residual sugar          0.357459\n",
       "total sulfur dioxide    0.272970\n",
       "chlorides               0.260508\n",
       "free sulfur dioxide     0.188460\n",
       "pH                      0.116497\n",
       "fixed acidity           0.091964\n",
       "volatile acidity        0.036041\n",
       "citric acid             0.005690\n",
       "sulphates               0.000412\n",
       "Name: alcohol, dtype: float64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudio de correlaciones entre las variables num√©ricas y la variable objetivo de regresi√≥n.\n",
    "\n",
    "# Calculamos la matriz de correlaci√≥n solo para las variables num√©ricas.\n",
    "#    - Se utiliza df[features_num_reg] para excluir las variables categ√≥ricas.\n",
    "#    - numeric_only=\"True\" se usa para evitar advertencias en versiones recientes de pandas.\n",
    "\n",
    "# Extraemos la correlaci√≥n absoluta de cada variable con el target de regresi√≥n (\"alcohol\").\n",
    "#    - np.abs() se usa para obtener la magnitud de la correlaci√≥n sin importar el signo.\n",
    "#    - .sort_values(ascending=False) ordena las variables de mayor a menor correlaci√≥n.\n",
    "\n",
    "corr = df[features_num_reg].corr(numeric_only=\"True\")\n",
    "serie_corr = np.abs(corr[target_reg]).sort_values(ascending=False)\n",
    "serie_corr\n",
    "\n",
    "# Ahora, serie_corr contiene las variables ordenadas seg√∫n su grado de correlaci√≥n con \"alcohol\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecci√≥n de caracter√≠sticas num√©ricas basadas en la correlaci√≥n con el target de regresi√≥n.\n",
    "\n",
    "# Definimos un umbral m√≠nimo de correlaci√≥n.\n",
    "#    - r_min = 0.05 significa que solo seleccionaremos variables con correlaci√≥n mayor a 0.05.\n",
    "\n",
    "r_min = 0.05\n",
    "\n",
    "# Seleccionamos las variables num√©ricas con correlaci√≥n significativa con el target.\n",
    "#    - Tomamos solo las variables con correlaci√≥n absoluta mayor que r_min.\n",
    "#    - Convertimos los nombres de las columnas en una lista.\n",
    "#    - Eliminamos el target (\"alcohol\") de la lista, ya que no es una feature.\n",
    "\n",
    "features_num_reg_1 = serie_corr[serie_corr > r_min].index.to_list()\n",
    "features_num_reg_1.remove(target_reg)\n",
    "\n",
    "# Identificamos las variables num√©ricas con correlaci√≥n baja o nula con el target.\n",
    "#    - Excluimos las variables en features_num_reg_1.\n",
    "#    - Excluimos el target y las variables categ√≥ricas.\n",
    "\n",
    "features_num_reg_2 = [col for col in df.columns if col not in features_num_reg_1 and col != target_reg\n",
    "                       and col not in features_cat_reg]\n",
    "\n",
    "# Ahora:\n",
    "# - features_num_reg_1 contiene las variables m√°s correlacionadas con \"alcohol\".\n",
    "# - features_num_reg_2 contiene las variables menos correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quality'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n del problema de clasificaci√≥n.\n",
    "\n",
    "# target_clf ‚Üí Variable objetivo para clasificaci√≥n.\n",
    "#    - Se ha definido previamente como \"quality\".\n",
    "#    - Representa la calidad del vino en una escala categ√≥rica.\n",
    "#    - Es un problema de clasificaci√≥n **multiclase** (7 categor√≠as posibles).\n",
    "\n",
    "target_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de las caracter√≠sticas categ√≥ricas para el problema de clasificaci√≥n.\n",
    "\n",
    "# features_cat_clf ‚Üí Variables categ√≥ricas a incluir en el modelo de clasificaci√≥n.\n",
    "#    - Contiene la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables num√©ricas.\n",
    "\n",
    "features_cat_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity',\n",
       " 'citric acid',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de caracter√≠sticas num√©ricas principales para clasificaci√≥n.\n",
    "\n",
    "# features_num_clf_1 ‚Üí Variables num√©ricas seleccionadas para el modelo de clasificaci√≥n.\n",
    "#    - Incluye medidas qu√≠micas clave del vino:\n",
    "#      - \"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "#      - \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\".\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas caracter√≠sticas antes del modelado.\n",
    "\n",
    "features_num_clf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alcohol'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n del problema de regresi√≥n.\n",
    "\n",
    "# target_reg ‚Üí Variable objetivo para regresi√≥n.\n",
    "#    - Se ha definido previamente como \"alcohol\".\n",
    "#    - Representa el porcentaje de alcohol en el vino (variable continua).\n",
    "#    - Es un problema de regresi√≥n, ya que el target es num√©rico y continuo.\n",
    "\n",
    "target_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'quality']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de las caracter√≠sticas categ√≥ricas para el problema de regresi√≥n.\n",
    "\n",
    "# features_cat_reg ‚Üí Variables categ√≥ricas a incluir en el modelo de regresi√≥n.\n",
    "#    - Contiene:\n",
    "#      - \"class\" (tipo de vino: tinto o blanco).\n",
    "#      - \"quality\" (calidad del vino en una escala categ√≥rica).\n",
    "#    - Ambas variables deben ser transformadas con OneHotEncoder para su uso en modelos num√©ricos.\n",
    "\n",
    "features_cat_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de caracter√≠sticas num√©ricas principales para regresi√≥n.\n",
    "\n",
    "# features_num_reg_1 ‚Üí Variables num√©ricas con mayor correlaci√≥n con el target de regresi√≥n (\"alcohol\").\n",
    "#    - Se han seleccionado aquellas con correlaci√≥n absoluta > r_min (0.05).\n",
    "#    - Estas variables son las m√°s relevantes para predecir el contenido de alcohol en el vino.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas caracter√≠sticas antes del modelado.\n",
    "\n",
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity', 'residual sugar', 'quality', 'quality']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definici√≥n de columnas a incluir y excluir en el modelo de clasificaci√≥n.\n",
    "\n",
    "# columns_to_keep_clf ‚Üí Columnas que se mantendr√°n en el modelo de clasificaci√≥n.\n",
    "#    - Incluye:\n",
    "#      - target_clf (variable objetivo de clasificaci√≥n: \"quality\").\n",
    "#      - features_num_clf_1 (variables num√©ricas relevantes).\n",
    "#      - features_cat_clf (variables categ√≥ricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_clf ‚Üí Columnas que se excluir√°n del modelo de clasificaci√≥n.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_clf.\n",
    "#    - Estas columnas no ser√°n utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_clf =   features_num_clf_1 + features_cat_clf\n",
    "\n",
    "columns_to_exclude_clf = [col for col in df.columns if col not in columns_to_keep_clf] + [target_clf] \n",
    "\n",
    "columns_to_exclude_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity', 'citric acid', 'sulphates', 'alcohol']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de columnas a incluir y excluir en el modelo de regresi√≥n.\n",
    "\n",
    "# columns_to_keep_reg ‚Üí Columnas que se mantendr√°n en el modelo de regresi√≥n.\n",
    "#    - Incluye:\n",
    "#      - target_reg (variable objetivo de regresi√≥n: \"alcohol\").\n",
    "#      - features_num_reg_1 (variables num√©ricas m√°s correlacionadas con el target).\n",
    "#      - features_cat_reg (variables categ√≥ricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_reg ‚Üí Columnas que se excluir√°n del modelo de regresi√≥n.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_reg.\n",
    "#    - Estas columnas no ser√°n utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_reg = features_num_reg_1 + features_cat_reg\n",
    "\n",
    "columns_to_exclude_reg = [col for col in df.columns if col not in columns_to_keep_reg]\n",
    "\n",
    "columns_to_exclude_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definici√≥n de Pipelines para preprocesamiento de datos en clasificaci√≥n.\n",
    "\n",
    "# cat_pipeline ‚Üí Preprocesamiento de variables categ√≥ricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor m√°s frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categor√≠as desconocidas.\n",
    "\n",
    "# logaritmica ‚Üí Transformaci√≥n logar√≠tmica de variables num√©ricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las caracter√≠sticas.\n",
    "\n",
    "# num_pipeline ‚Üí Preprocesamiento de variables num√©ricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformaci√≥n logar√≠tmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables num√©ricas.\n",
    "\n",
    "# imputer_step_cat ‚Üí ColumnTransformer para aplicar los Pipelines seg√∫n el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_clf_1 (variables num√©ricas).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_clf (variables categ√≥ricas).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_clf.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_cat ‚Üí Pipeline final que aplica el ColumnTransformer imputer_step_cat.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputaci√≥n con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categor√≠as desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") # Esto le indica al Pipeline que el n√∫mero de caracter√≠sticas no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_cat = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_clf_1), # feature_numericas seleccionadas para clasificaci√≥n\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_clf), # feature_categoriacas seleccionadas para regresi√≥n\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_clf)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_cat = Pipeline([(\"first_stage\", imputer_step_cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definici√≥n de Pipelines para preprocesamiento de datos en regresi√≥n.\n",
    "\n",
    "# cat_pipeline ‚Üí Preprocesamiento de variables categ√≥ricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor m√°s frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categor√≠as desconocidas.\n",
    "\n",
    "# logaritmica ‚Üí Transformaci√≥n logar√≠tmica de variables num√©ricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las caracter√≠sticas.\n",
    "\n",
    "# num_pipeline ‚Üí Preprocesamiento de variables num√©ricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformaci√≥n logar√≠tmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables num√©ricas.\n",
    "\n",
    "# imputer_step_reg ‚Üí ColumnTransformer para aplicar los Pipelines seg√∫n el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_reg_1 (variables num√©ricas seleccionadas para regresi√≥n).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_reg (variables categ√≥ricas seleccionadas para regresi√≥n).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_reg.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_reg ‚Üí Pipeline final que aplica el ColumnTransformer imputer_step_reg.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputaci√≥n con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categor√≠as desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") # Esto le indica al Pipeline que el n√∫mero de caracter√≠sticas no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_reg = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_reg_1), # feature_numericas seleccionadas para clasificaci√≥n\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_reg), # feature_categoriacas seleccionadas para regresi√≥n\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_reg)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_reg = Pipeline([(\"first_stage\", imputer_step_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06561088, -0.27783928, -0.1913355 , ..., -1.03455179,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.061259  , -0.49980343, -0.57998343, ...,  1.48951019,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.06561088,  0.2893635 , -0.68457525, ...,  1.63689007,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 0.061259  ,  1.14300849, -0.11427313, ...,  1.33989719,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.78484693, -1.03933617,  0.41908799, ...,  0.79764424,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.18624926, -1.28052007, -0.52783916, ..., -0.93914749,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicaci√≥n del pipeline de preprocesamiento a los datos de prueba.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df_test)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificaci√≥n.\n",
    "#    - Imputa valores faltantes en variables num√©ricas y categ√≥ricas.\n",
    "#    - Transforma variables categ√≥ricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformaci√≥n logar√≠tmica a las variables num√©ricas.\n",
    "\n",
    "# pipe_df_test ‚Üí Contiene los datos de prueba preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df_test = pipe_missings_cat.fit_transform(df_test)\n",
    "\n",
    "pipe_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05515355,  0.59288805, -0.20549433, ...,  0.72017181,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.05515355,  2.5608768 , -0.37024226, ..., -1.3127524 ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.11199789, -0.50565223, -0.5026097 , ...,  0.31263542,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.90744764,  0.46264335, -0.10702207, ...,  0.47768498,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.5098244 , -0.14782501, -0.7688788 , ...,  1.99147821,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.05515355, -0.21826777, -0.53578111, ...,  0.72017181,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicaci√≥n del pipeline de preprocesamiento a los datos de entrenamiento.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificaci√≥n.\n",
    "#    - Imputa valores faltantes en variables num√©ricas y categ√≥ricas.\n",
    "#    - Transforma variables categ√≥ricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformaci√≥n logar√≠tmica a las variables num√©ricas.\n",
    "\n",
    "# pipe_df ‚Üí Contiene los datos de entrenamiento preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df = pipe_missings_cat.fit_transform(df)\n",
    "pipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>0.592888</td>\n",
       "      <td>-0.205494</td>\n",
       "      <td>0.603446</td>\n",
       "      <td>-0.505241</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.706744</td>\n",
       "      <td>2.584726</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>2.560877</td>\n",
       "      <td>-0.370242</td>\n",
       "      <td>0.820606</td>\n",
       "      <td>0.855001</td>\n",
       "      <td>1.621578</td>\n",
       "      <td>1.011233</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>-1.312752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.111998</td>\n",
       "      <td>-0.505652</td>\n",
       "      <td>-0.502610</td>\n",
       "      <td>-1.317236</td>\n",
       "      <td>0.112504</td>\n",
       "      <td>-0.901360</td>\n",
       "      <td>-1.066182</td>\n",
       "      <td>-1.830435</td>\n",
       "      <td>0.312635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.548692</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.074260</td>\n",
       "      <td>0.564028</td>\n",
       "      <td>0.448623</td>\n",
       "      <td>0.059153</td>\n",
       "      <td>-1.000780</td>\n",
       "      <td>-0.177558</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320822</td>\n",
       "      <td>0.657314</td>\n",
       "      <td>1.525362</td>\n",
       "      <td>-2.003136</td>\n",
       "      <td>-3.095378</td>\n",
       "      <td>0.440977</td>\n",
       "      <td>-0.547423</td>\n",
       "      <td>0.391872</td>\n",
       "      <td>1.187890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>-0.619281</td>\n",
       "      <td>1.217401</td>\n",
       "      <td>-0.271299</td>\n",
       "      <td>1.282255</td>\n",
       "      <td>1.111562</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>-0.228277</td>\n",
       "      <td>0.322290</td>\n",
       "      <td>-1.022479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>-0.762183</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>0.089083</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>0.371746</td>\n",
       "      <td>1.276901</td>\n",
       "      <td>1.431729</td>\n",
       "      <td>-0.549087</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>-0.907448</td>\n",
       "      <td>0.462643</td>\n",
       "      <td>-0.107022</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.581225</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>0.645425</td>\n",
       "      <td>0.252264</td>\n",
       "      <td>0.477685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0.509824</td>\n",
       "      <td>-0.147825</td>\n",
       "      <td>-0.768879</td>\n",
       "      <td>0.045414</td>\n",
       "      <td>-0.365924</td>\n",
       "      <td>-1.936549</td>\n",
       "      <td>-1.662178</td>\n",
       "      <td>-1.332210</td>\n",
       "      <td>1.991478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.535781</td>\n",
       "      <td>1.010544</td>\n",
       "      <td>0.521557</td>\n",
       "      <td>-1.017779</td>\n",
       "      <td>-0.355475</td>\n",
       "      <td>-0.624929</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -1.055154                      0.592888   \n",
       "1                             -1.055154                      2.560877   \n",
       "2                              1.111998                     -0.505652   \n",
       "3                             -0.548692                     -0.218268   \n",
       "4                              0.320822                      0.657314   \n",
       "...                                 ...                           ...   \n",
       "5192                          -0.619281                      1.217401   \n",
       "5193                          -0.762183                     -0.218268   \n",
       "5194                          -0.907448                      0.462643   \n",
       "5195                           0.509824                     -0.147825   \n",
       "5196                          -1.055154                     -0.218268   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.205494                              0.603446   \n",
       "1                      -0.370242                              0.820606   \n",
       "2                      -0.502610                             -1.317236   \n",
       "3                      -0.074260                              0.564028   \n",
       "4                       1.525362                             -2.003136   \n",
       "...                          ...                                   ...   \n",
       "5192                   -0.271299                              1.282255   \n",
       "5193                    0.089083                             -0.011858   \n",
       "5194                   -0.107022                              0.255061   \n",
       "5195                   -0.768879                              0.045414   \n",
       "5196                   -0.535781                              1.010544   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                 -0.505241                  0.427700   \n",
       "1                                  0.855001                  1.621578   \n",
       "2                                  0.112504                 -0.901360   \n",
       "3                                  0.448623                  0.059153   \n",
       "4                                 -3.095378                  0.440977   \n",
       "...                                     ...                       ...   \n",
       "5192                               1.111562                  0.626829   \n",
       "5193                               0.371746                  1.276901   \n",
       "5194                               0.581225                 -0.003952   \n",
       "5195                              -0.365924                 -1.936549   \n",
       "5196                               0.521557                 -1.017779   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0                0.706744                    2.584726   \n",
       "1                1.011233                    0.998990   \n",
       "2               -1.066182                   -1.830435   \n",
       "3               -1.000780                   -0.177558   \n",
       "4               -0.547423                    0.391872   \n",
       "...                   ...                         ...   \n",
       "5192            -0.228277                    0.322290   \n",
       "5193             1.431729                   -0.549087   \n",
       "5194             0.645425                    0.252264   \n",
       "5195            -1.662178                   -1.332210   \n",
       "5196            -0.355475                   -0.624929   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                     0.720172                             1.0   \n",
       "1                    -1.312752                             0.0   \n",
       "2                     0.312635                             0.0   \n",
       "3                    -0.927596                             0.0   \n",
       "4                     1.187890                             1.0   \n",
       "...                        ...                             ...   \n",
       "5192                 -1.022479                             0.0   \n",
       "5193                 -0.927596                             0.0   \n",
       "5194                  0.477685                             0.0   \n",
       "5195                  1.991478                             0.0   \n",
       "5196                  0.720172                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  \n",
       "0                                  0.0  \n",
       "1                                  1.0  \n",
       "2                                  1.0  \n",
       "3                                  1.0  \n",
       "4                                  0.0  \n",
       "...                                ...  \n",
       "5192                               1.0  \n",
       "5193                               1.0  \n",
       "5194                               1.0  \n",
       "5195                               1.0  \n",
       "5196                               1.0  \n",
       "\n",
       "[5197 rows x 11 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversi√≥n de los datos preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos preprocesados (pipe_df) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las caracter√≠sticas generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check ‚Üí Contiene los datos de entrenamiento preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check = pd.DataFrame(pipe_df, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>-0.277839</td>\n",
       "      <td>-0.191336</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.831639</td>\n",
       "      <td>-0.433274</td>\n",
       "      <td>-1.146519</td>\n",
       "      <td>-0.036117</td>\n",
       "      <td>-1.034552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.499803</td>\n",
       "      <td>-0.579983</td>\n",
       "      <td>0.200694</td>\n",
       "      <td>0.019098</td>\n",
       "      <td>-1.467980</td>\n",
       "      <td>-0.701377</td>\n",
       "      <td>-0.919534</td>\n",
       "      <td>1.489510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>0.289363</td>\n",
       "      <td>-0.684575</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>-1.164893</td>\n",
       "      <td>0.887973</td>\n",
       "      <td>0.514885</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.661389</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>-0.789574</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.594218</td>\n",
       "      <td>-1.437325</td>\n",
       "      <td>0.469593</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.351239</td>\n",
       "      <td>-0.475795</td>\n",
       "      <td>1.255666</td>\n",
       "      <td>0.502182</td>\n",
       "      <td>-1.812097</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.395421</td>\n",
       "      <td>1.414987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>-0.292330</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>0.166421</td>\n",
       "      <td>0.349361</td>\n",
       "      <td>1.050532</td>\n",
       "      <td>1.146368</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.542576</td>\n",
       "      <td>-1.130887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.842435</td>\n",
       "      <td>0.888607</td>\n",
       "      <td>2.218732</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>-0.940203</td>\n",
       "      <td>1.268510</td>\n",
       "      <td>1.006277</td>\n",
       "      <td>2.132366</td>\n",
       "      <td>-0.475482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>1.143008</td>\n",
       "      <td>-0.114273</td>\n",
       "      <td>-2.309748</td>\n",
       "      <td>-3.358761</td>\n",
       "      <td>-0.015075</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>1.102750</td>\n",
       "      <td>1.339897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>0.784847</td>\n",
       "      <td>-1.039336</td>\n",
       "      <td>0.419088</td>\n",
       "      <td>-1.861014</td>\n",
       "      <td>-3.091298</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>2.329225</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>0.797644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>0.186249</td>\n",
       "      <td>-1.280520</td>\n",
       "      <td>-0.527839</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.542123</td>\n",
       "      <td>0.348801</td>\n",
       "      <td>-0.178400</td>\n",
       "      <td>-0.939147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -0.065611                     -0.277839   \n",
       "1                              0.061259                     -0.499803   \n",
       "2                             -0.065611                      0.289363   \n",
       "3                             -0.661389                      0.080702   \n",
       "4                              0.061259                     -0.351239   \n",
       "...                                 ...                           ...   \n",
       "1295                          -0.292330                      0.080702   \n",
       "1296                           0.842435                      0.888607   \n",
       "1297                           0.061259                      1.143008   \n",
       "1298                           0.784847                     -1.039336   \n",
       "1299                           0.186249                     -1.280520   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.191336                              0.609936   \n",
       "1                      -0.579983                              0.200694   \n",
       "2                      -0.684575                              0.441142   \n",
       "3                      -0.789574                              0.798095   \n",
       "4                      -0.475795                              1.255666   \n",
       "...                          ...                                   ...   \n",
       "1295                    0.166421                              0.349361   \n",
       "1296                    2.218732                              0.527821   \n",
       "1297                   -0.114273                             -2.309748   \n",
       "1298                    0.419088                             -1.861014   \n",
       "1299                   -0.527839                              0.609936   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                  0.831639                 -0.433274   \n",
       "1                                  0.019098                 -1.467980   \n",
       "2                                  0.048148                 -1.164893   \n",
       "3                                  0.594218                 -1.437325   \n",
       "4                                  0.502182                 -1.812097   \n",
       "...                                     ...                       ...   \n",
       "1295                               1.050532                  1.146368   \n",
       "1296                              -0.940203                  1.268510   \n",
       "1297                              -3.358761                 -0.015075   \n",
       "1298                              -3.091298                 -0.127250   \n",
       "1299                               0.671446                  0.542123   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0               -1.146519                   -0.036117   \n",
       "1               -0.701377                   -0.919534   \n",
       "2                0.887973                    0.514885   \n",
       "3                0.469593                    0.104306   \n",
       "4               -1.339665                   -0.395421   \n",
       "...                   ...                         ...   \n",
       "1295            -1.339665                   -0.542576   \n",
       "1296             1.006277                    2.132366   \n",
       "1297            -0.078471                    1.102750   \n",
       "1298             2.329225                    0.104306   \n",
       "1299             0.348801                   -0.178400   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                    -1.034552                             0.0   \n",
       "1                     1.489510                             0.0   \n",
       "2                     1.636890                             0.0   \n",
       "3                     1.636890                             0.0   \n",
       "4                     1.414987                             0.0   \n",
       "...                        ...                             ...   \n",
       "1295                 -1.130887                             0.0   \n",
       "1296                 -0.475482                             1.0   \n",
       "1297                  1.339897                             1.0   \n",
       "1298                  0.797644                             1.0   \n",
       "1299                 -0.939147                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  \n",
       "0                                  1.0  \n",
       "1                                  1.0  \n",
       "2                                  1.0  \n",
       "3                                  1.0  \n",
       "4                                  1.0  \n",
       "...                                ...  \n",
       "1295                               1.0  \n",
       "1296                               0.0  \n",
       "1297                               0.0  \n",
       "1298                               0.0  \n",
       "1299                               1.0  \n",
       "\n",
       "[1300 rows x 11 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversi√≥n de los datos de prueba preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df_test, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos de prueba preprocesados (pipe_df_test) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las caracter√≠sticas generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check_test ‚Üí Contiene los datos de prueba preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check_test = pd.DataFrame(pipe_df_test, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACI√ìN DE MODELOS DE CLASIFICACI√ìN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic: 0.5470\n",
      "[0.52980769 0.55769231 0.54186718 0.54764196 0.55822907]\n",
      "randomF: 0.6611\n",
      "[0.66442308 0.66153846 0.6612127  0.66506256 0.65351299]\n",
      "Kneighbors: 0.5449\n",
      "[0.55288462 0.55480769 0.53224254 0.54475457 0.53994225]\n",
      "LGBM: 0.6423\n",
      "[0.65       0.63942308 0.64773821 0.63522618 0.63907603]\n"
     ]
    }
   ],
   "source": [
    "logistic_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", LogisticRegression(max_iter=10000))\n",
    "    ])\n",
    "\n",
    "random_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "Kneighbors_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "LGBM_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", LGBMClassifier(verbose=-1))\n",
    "    ])\n",
    "\n",
    "\n",
    "for name, pipe in zip([\"logistic\",\"randomF\", \"Kneighbors\",\"LGBM\"],[logistic_pipeline, random_pipeline, Kneighbors_pipeline, LGBM_pipeline]):\n",
    "    resultado_\n",
    "    resultado = cross_val_score(pipe, df, y_train_cat, cv = 5, scoring = \"accuracy\")\n",
    "    print(f\"{name}: {np.mean(resultado):.4f}\")\n",
    "    print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACION DE MODELOS DE REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomF: 0.0276\n",
      "[-0.02877444 -0.0284786  -0.02691515 -0.02693453 -0.02710483]\n",
      "XGB: 0.0271\n",
      "[-0.02807295 -0.02796904 -0.02587827 -0.02658056 -0.02686444]\n",
      "LGBM: 0.0287\n",
      "[-0.02986407 -0.02965162 -0.02812008 -0.02791631 -0.02802684]\n"
     ]
    }
   ],
   "source": [
    "randomreg_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_reg),\n",
    "     (\"Modelo\", RandomForestRegressor())\n",
    "    ])\n",
    "\n",
    "XGB_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_reg),\n",
    "     (\"Modelo\", XGBRegressor())\n",
    "    ])\n",
    "\n",
    "LGBMreg_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_reg),\n",
    "     (\"Modelo\", LGBMRegressor(verbose=-1))\n",
    "    ])\n",
    "\n",
    "\n",
    "for name, pipe in zip([\"RandomF\",\"XGB\",\"LGBM\"],[randomreg_pipeline, XGB_pipeline, LGBMreg_pipeline]):\n",
    "    resultado_reg = cross_val_score(pipe, df, y_train_reg, cv = 5, scoring = \"neg_mean_absolute_percentage_error\")\n",
    "    print(f\"{name}: {-np.mean(resultado_reg):.4f}\")\n",
    "    print(resultado_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACION DE PARAMETROS DE CLASIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos sus hiperparametros\n",
    "reg_log_param = {    \n",
    "                 \"penalty\": [None,\"l2\"], \n",
    "                 \"C\": np.logspace(0, 4, 10)\n",
    "                }\n",
    "\n",
    "rand_forest_param = {\n",
    "    'n_estimators': [10, 100, 200, 400],\n",
    "    'max_depth': [1,2,4,8],\n",
    "    'max_features': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'Modelo__num_leaves': [15, 31, 50],\n",
    "    'Modelo__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'Modelo__n_estimators': [50, 100, 200],\n",
    "    'Modelo__max_depth': [5, 10, 15],\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    \"Modelo__n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"Modelo__weights\": ['uniform', 'distance'],\n",
    "    \"Modelo__metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "\n",
    "cv = 5\n",
    "\n",
    "gs_reg_log = GridSearchCV(LogisticRegression(),\n",
    "                            reg_log_param,\n",
    "                            cv=cv,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "gs_rand_forest = GridSearchCV(RandomForestClassifier(),\n",
    "                            rand_forest_param,\n",
    "                            cv=cv,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "gs_lgb = GridSearchCV(LGBMClassifier(),\n",
    "                        param_grid_lgbm,\n",
    "                        cv=cv,\n",
    "                        scoring=\"accuracy\",\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=Kneighbors_pipeline,\n",
    "                               param_grid=param_grid_knn,\n",
    "                               scoring='accuracy',\n",
    "                               cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe_grids_cat = {\"gs_reg_log\":gs_reg_log,\n",
    "         \"gs_rand_forest\":gs_rand_forest,\n",
    "         \"gs_lgb\":gs_lgb,\n",
    "         \"gs_Knn\":grid_search_knn}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'white'\n\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'red'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[338], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nombre, grid_search \u001b[38;5;129;01min\u001b[39;00m pipe_grids_cat\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    994\u001b[0m     )\n\u001b[1;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'white'\n\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'red'\n"
     ]
    }
   ],
   "source": [
    "for nombre, grid_search in pipe_grids_cat.items():\n",
    "    grid_search.fit(df, y_train_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
