{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "import Toolbox as tb\n",
    "from Toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "data = pd.read_csv(\"../data/wines_dataset.csv\", sep=\"|\")\n",
    "\n",
    "\"\"\"\n",
    "Divisi√≥n de datos en entrenamiento y prueba.\n",
    "\n",
    "Se toma el 80% de los datos para entrenamiento y el 20% restante para prueba.\n",
    "\n",
    "Par√°metros:\n",
    "- test_size (float): Proporci√≥n del conjunto de prueba (0.2 = 20% de los datos).\n",
    "- random_state (int): Semilla para la reproducibilidad de la divisi√≥n.\n",
    "\n",
    "Salida:\n",
    "- train (DataFrame): Conjunto de entrenamiento.\n",
    "- test (DataFrame): Conjunto de prueba.\n",
    "\"\"\"\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "Guardado de los conjuntos de datos en archivos CSV.\n",
    "\n",
    "Los archivos se almacenan en la carpeta \"../data/\" con los nombres:\n",
    "- wines_train.csv ‚Üí Contiene el 80% de los datos para entrenamiento.\n",
    "- wines_test.csv ‚Üí Contiene el 20% de los datos para prueba.\n",
    "\n",
    "index=False evita que se guarde el √≠ndice en los archivos.\n",
    "\"\"\"\n",
    "train.to_csv(os.path.join(\"../data/\", 'wines_train.csv'), index=False)\n",
    "test.to_csv(os.path.join(\"../data/\", 'wines_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.049</td>\n",
       "      <td>38.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99600</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.93</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.74</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.044</td>\n",
       "      <td>44.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.040</td>\n",
       "      <td>10.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.053</td>\n",
       "      <td>37.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99489</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.99604</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.58</td>\n",
       "      <td>11.9</td>\n",
       "      <td>7</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>0.047</td>\n",
       "      <td>60.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.05</td>\n",
       "      <td>0.058</td>\n",
       "      <td>25.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.99856</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.052</td>\n",
       "      <td>30.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.99470</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.032</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.98889</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.35</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.039</td>\n",
       "      <td>50.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.99165</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.3</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.9              0.18         0.40            2.20      0.049   \n",
       "1               7.1              0.18         0.74           15.60      0.044   \n",
       "2               7.6              0.51         0.24            1.20      0.040   \n",
       "3               6.0              0.25         0.28            7.70      0.053   \n",
       "4               9.0              0.38         0.41            2.40      0.103   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "5192            6.4              0.24         0.50           11.60      0.047   \n",
       "5193            6.6              0.22         0.28           12.05      0.058   \n",
       "5194            6.6              0.20         0.38            7.90      0.052   \n",
       "5195            7.3              0.41         0.29            1.80      0.032   \n",
       "5196            5.9              0.18         0.28            5.10      0.039   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    38.0                  67.0  0.99600  3.33       0.93   \n",
       "1                    44.0                 176.0  0.99960  3.38       0.67   \n",
       "2                    10.0                 104.0  0.99200  3.05       0.29   \n",
       "3                    37.0                 132.0  0.99489  3.06       0.50   \n",
       "4                     6.0                  10.0  0.99604  3.13       0.58   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "5192                 60.0                 211.0  0.99660  3.18       0.57   \n",
       "5193                 25.0                 125.0  0.99856  3.45       0.45   \n",
       "5194                 30.0                 145.0  0.99470  3.32       0.56   \n",
       "5195                 26.0                  74.0  0.98889  2.96       0.35   \n",
       "5196                 50.0                 139.0  0.99165  3.16       0.44   \n",
       "\n",
       "      alcohol  quality  class  \n",
       "0        11.3        5    red  \n",
       "1         9.0        6  white  \n",
       "2        10.8        6  white  \n",
       "3         9.4        6  white  \n",
       "4        11.9        7    red  \n",
       "...       ...      ...    ...  \n",
       "5192      9.3        5  white  \n",
       "5193      9.4        5  white  \n",
       "5194     11.0        7  white  \n",
       "5195     13.0        8  white  \n",
       "5196     11.3        6  white  \n",
       "\n",
       "[5197 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de entrenamiento desde el archivo CSV\n",
    "df = pd.read_csv(\"../data/wines_train.csv\")\n",
    "\n",
    "# Mostrar el DataFrame cargado\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.049</td>\n",
       "      <td>38.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99335</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.034</td>\n",
       "      <td>29.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99031</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.026</td>\n",
       "      <td>43.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99040</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.038</td>\n",
       "      <td>58.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.98930</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.063</td>\n",
       "      <td>32.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>11.6</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.147</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99836</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.052</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99458</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.073</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99425</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.036</td>\n",
       "      <td>38.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.99622</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.320         0.27             1.4      0.049   \n",
       "1               6.6             0.340         0.24             3.3      0.034   \n",
       "2               6.4             0.320         0.35             4.8      0.030   \n",
       "3               6.8             0.230         0.32             1.6      0.026   \n",
       "4               6.7             0.340         0.26             1.9      0.038   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1295            7.6             0.285         0.32            14.6      0.063   \n",
       "1296           11.6             0.470         0.44             1.6      0.147   \n",
       "1297           10.2             0.340         0.48             2.1      0.052   \n",
       "1298            6.2             0.460         0.17             1.6      0.073   \n",
       "1299            6.2             0.360         0.14             8.9      0.036   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    38.0                 173.0  0.99335  3.03       0.52   \n",
       "1                    29.0                  99.0  0.99031  3.10       0.40   \n",
       "2                    34.0                 101.0  0.99120  3.36       0.60   \n",
       "3                    43.0                 147.0  0.99040  3.29       0.54   \n",
       "4                    58.0                 138.0  0.98930  3.00       0.47   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1295                 32.0                 201.0  0.99800  3.00       0.45   \n",
       "1296                 36.0                  51.0  0.99836  3.38       0.86   \n",
       "1297                  5.0                   9.0  0.99458  3.20       0.69   \n",
       "1298                  7.0                  11.0  0.99425  3.61       0.54   \n",
       "1299                 38.0                 155.0  0.99622  3.27       0.50   \n",
       "\n",
       "      alcohol  quality  class  \n",
       "0         9.3        5  white  \n",
       "1        12.3        7  white  \n",
       "2        12.5        8  white  \n",
       "3        12.5        6  white  \n",
       "4        12.2        7  white  \n",
       "...       ...      ...    ...  \n",
       "1295      9.2        5  white  \n",
       "1296      9.9        4    red  \n",
       "1297     12.1        7    red  \n",
       "1298     11.4        5    red  \n",
       "1299      9.4        5  white  \n",
       "\n",
       "[1300 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de prueba desde el archivo CSV\n",
    "df_test = pd.read_csv(\"../data/wines_test.csv\")\n",
    "\n",
    "# Mostrar el DataFrame cargado\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COL_N</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>100</td>\n",
       "      <td>177</td>\n",
       "      <td>87</td>\n",
       "      <td>308</td>\n",
       "      <td>194</td>\n",
       "      <td>132</td>\n",
       "      <td>274</td>\n",
       "      <td>951</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COL_N         fixed acidity volatile acidity citric acid residual sugar  \\\n",
       "DATA_TYPE           float64          float64     float64        float64   \n",
       "MISSINGS (%)            0.0              0.0         0.0            0.0   \n",
       "UNIQUE_VALUES           100              177          87            308   \n",
       "CARDIN (%)             0.02             0.03        0.02           0.06   \n",
       "\n",
       "COL_N         chlorides free sulfur dioxide total sulfur dioxide  density  \\\n",
       "DATA_TYPE       float64             float64              float64  float64   \n",
       "MISSINGS (%)        0.0                 0.0                  0.0      0.0   \n",
       "UNIQUE_VALUES       194                 132                  274      951   \n",
       "CARDIN (%)         0.04                0.03                 0.05     0.18   \n",
       "\n",
       "COL_N               pH sulphates  alcohol quality   class  \n",
       "DATA_TYPE      float64   float64  float64   int64  object  \n",
       "MISSINGS (%)       0.0       0.0      0.0     0.0     0.0  \n",
       "UNIQUE_VALUES      106       106      102       7       2  \n",
       "CARDIN (%)        0.02      0.02     0.02     0.0     0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genera un resumen descriptivo del DataFrame utilizando la funci√≥n tb.describe_df(df).\n",
    "# \n",
    "#  Muestra informaci√≥n sobre:\n",
    "#    - DATA_TYPE: Tipo de dato de cada columna (num√©rico, categ√≥rico, etc.).\n",
    "#    - MISSINGS (%): Porcentaje de valores nulos en cada columna.\n",
    "#    - UNIQUE_VALUES: Cantidad de valores √∫nicos en cada columna.\n",
    "#    - CARDIN (%): Cardinalidad relativa (valores √∫nicos / total de filas).\n",
    "# \n",
    "# √ötil para comprender la estructura de los datos antes del preprocesamiento.\n",
    "\n",
    "tb.describe_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de variables objetivo para el an√°lisis:\n",
    "\n",
    "# target_clf = \"quality\" ‚Üí Problema de Clasificaci√≥n\n",
    "#    - La variable `quality` representa la calidad del vino.\n",
    "#    - Es una variable categ√≥rica con 7 valores √∫nicos (multiclase).\n",
    "#    - Se utilizar√°n modelos de clasificaci√≥n, como RandomForestClassifier o XGBoost.\n",
    "#    - Es necesario aplicar OneHotEncoder a variables categ√≥ricas y StandardScaler a las num√©ricas.\n",
    "\n",
    "# target_reg = \"alcohol\" ‚Üí Problema de Regresi√≥n\n",
    "#    - La variable `alcohol` indica el porcentaje de alcohol en el vino.\n",
    "#    - Es una variable num√©rica continua.\n",
    "#    - Se utilizar√°n modelos de regresi√≥n, como RandomForestRegressor o LinearRegression.\n",
    "#    - Requiere escalado de las variables num√©ricas (StandardScaler) y codificaci√≥n de las categ√≥ricas (OneHotEncoder).\n",
    "\n",
    "# üìå Ambos problemas requieren preprocesamiento adecuado seg√∫n el tipo de modelo utilizado.\n",
    "\n",
    "target_clf = \"quality\"\n",
    "target_reg = \"alcohol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de las caracter√≠sticas (features) utilizadas en la clasificaci√≥n:\n",
    "\n",
    "# features_cat_clf ‚Üí Variables categ√≥ricas\n",
    "#    - Contiene solo la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables num√©ricas.\n",
    "\n",
    "# features_num_clf_1 ‚Üí Variables num√©ricas principales\n",
    "#    - Incluye medidas qu√≠micas clave como \"volatile acidity\", \"chlorides\", \"density\", \"pH\", etc.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas caracter√≠sticas.\n",
    "\n",
    "# features_num_clf_2 ‚Üí Variables num√©ricas adicionales\n",
    "#    - Contiene \"fixed acidity\" y \"residual sugar\".\n",
    "#    - Estas caracter√≠sticas pueden ser analizadas por separado o combinadas con las anteriores.\n",
    "\n",
    "features_cat_clf = [\"class\"]\n",
    "features_num_clf_1 = [\"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "                      \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]\n",
    "features_num_clf_2 = [\"fixed acidity\", \"residual sugar\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de caracter√≠sticas (features) para el problema de regresi√≥n:\n",
    "\n",
    "# features_cat_reg ‚Üí Variables categ√≥ricas\n",
    "#    - Contiene \"class\" (tipo de vino: tinto o blanco) y \"quality\" (calidad del vino).\n",
    "#    - Estas variables deben ser transformadas con OneHotEncoder.\n",
    "\n",
    "# features_num_reg ‚Üí Variables num√©ricas\n",
    "#    - Se seleccionan todas las columnas del DataFrame excepto las categ√≥ricas.\n",
    "#    - Esto se logra con una lista por comprensi√≥n, excluyendo las columnas en features_cat_reg.\n",
    "#    - Estas variables deben ser escaladas con StandardScaler.\n",
    "\n",
    "features_cat_reg = [\"class\", \"quality\"]\n",
    "features_num_reg = [col for col in df.columns if col not in features_cat_reg]\n",
    "\n",
    "# Ahora features_num_reg contiene solo las variables num√©ricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                 1.000000\n",
       "density                 0.682345\n",
       "residual sugar          0.357459\n",
       "total sulfur dioxide    0.272970\n",
       "chlorides               0.260508\n",
       "free sulfur dioxide     0.188460\n",
       "pH                      0.116497\n",
       "fixed acidity           0.091964\n",
       "volatile acidity        0.036041\n",
       "citric acid             0.005690\n",
       "sulphates               0.000412\n",
       "Name: alcohol, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudio de correlaciones entre las variables num√©ricas y la variable objetivo de regresi√≥n.\n",
    "\n",
    "# Calculamos la matriz de correlaci√≥n solo para las variables num√©ricas.\n",
    "#    - Se utiliza df[features_num_reg] para excluir las variables categ√≥ricas.\n",
    "#    - numeric_only=\"True\" se usa para evitar advertencias en versiones recientes de pandas.\n",
    "\n",
    "# Extraemos la correlaci√≥n absoluta de cada variable con el target de regresi√≥n (\"alcohol\").\n",
    "#    - np.abs() se usa para obtener la magnitud de la correlaci√≥n sin importar el signo.\n",
    "#    - .sort_values(ascending=False) ordena las variables de mayor a menor correlaci√≥n.\n",
    "\n",
    "corr = df[features_num_reg].corr(numeric_only=\"True\")\n",
    "serie_corr = np.abs(corr[target_reg]).sort_values(ascending=False)\n",
    "serie_corr\n",
    "\n",
    "# Ahora, serie_corr contiene las variables ordenadas seg√∫n su grado de correlaci√≥n con \"alcohol\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecci√≥n de caracter√≠sticas num√©ricas basadas en la correlaci√≥n con el target de regresi√≥n.\n",
    "\n",
    "# Definimos un umbral m√≠nimo de correlaci√≥n.\n",
    "#    - r_min = 0.05 significa que solo seleccionaremos variables con correlaci√≥n mayor a 0.05.\n",
    "\n",
    "r_min = 0.05\n",
    "\n",
    "# Seleccionamos las variables num√©ricas con correlaci√≥n significativa con el target.\n",
    "#    - Tomamos solo las variables con correlaci√≥n absoluta mayor que r_min.\n",
    "#    - Convertimos los nombres de las columnas en una lista.\n",
    "#    - Eliminamos el target (\"alcohol\") de la lista, ya que no es una feature.\n",
    "\n",
    "features_num_reg_1 = serie_corr[serie_corr > r_min].index.to_list()\n",
    "features_num_reg_1.remove(target_reg)\n",
    "\n",
    "# Identificamos las variables num√©ricas con correlaci√≥n baja o nula con el target.\n",
    "#    - Excluimos las variables en features_num_reg_1.\n",
    "#    - Excluimos el target y las variables categ√≥ricas.\n",
    "\n",
    "features_num_reg_2 = [col for col in df.columns if col not in features_num_reg_1 and col != target_reg\n",
    "                       and col not in features_cat_reg]\n",
    "\n",
    "# Ahora:\n",
    "# - features_num_reg_1 contiene las variables m√°s correlacionadas con \"alcohol\".\n",
    "# - features_num_reg_2 contiene las variables menos correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quality'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n del problema de clasificaci√≥n.\n",
    "\n",
    "# target_clf ‚Üí Variable objetivo para clasificaci√≥n.\n",
    "#    - Se ha definido previamente como \"quality\".\n",
    "#    - Representa la calidad del vino en una escala categ√≥rica.\n",
    "#    - Es un problema de clasificaci√≥n **multiclase** (7 categor√≠as posibles).\n",
    "\n",
    "target_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de las caracter√≠sticas categ√≥ricas para el problema de clasificaci√≥n.\n",
    "\n",
    "# features_cat_clf ‚Üí Variables categ√≥ricas a incluir en el modelo de clasificaci√≥n.\n",
    "#    - Contiene la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables num√©ricas.\n",
    "\n",
    "features_cat_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity',\n",
       " 'citric acid',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de caracter√≠sticas num√©ricas principales para clasificaci√≥n.\n",
    "\n",
    "# features_num_clf_1 ‚Üí Variables num√©ricas seleccionadas para el modelo de clasificaci√≥n.\n",
    "#    - Incluye medidas qu√≠micas clave del vino:\n",
    "#      - \"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "#      - \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\".\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas caracter√≠sticas antes del modelado.\n",
    "\n",
    "features_num_clf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alcohol'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n del problema de regresi√≥n.\n",
    "\n",
    "# target_reg ‚Üí Variable objetivo para regresi√≥n.\n",
    "#    - Se ha definido previamente como \"alcohol\".\n",
    "#    - Representa el porcentaje de alcohol en el vino (variable continua).\n",
    "#    - Es un problema de regresi√≥n, ya que el target es num√©rico y continuo.\n",
    "\n",
    "target_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'quality']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de las caracter√≠sticas categ√≥ricas para el problema de regresi√≥n.\n",
    "\n",
    "# features_cat_reg ‚Üí Variables categ√≥ricas a incluir en el modelo de regresi√≥n.\n",
    "#    - Contiene:\n",
    "#      - \"class\" (tipo de vino: tinto o blanco).\n",
    "#      - \"quality\" (calidad del vino en una escala categ√≥rica).\n",
    "#    - Ambas variables deben ser transformadas con OneHotEncoder para su uso en modelos num√©ricos.\n",
    "\n",
    "features_cat_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de caracter√≠sticas num√©ricas principales para regresi√≥n.\n",
    "\n",
    "# features_num_reg_1 ‚Üí Variables num√©ricas con mayor correlaci√≥n con el target de regresi√≥n (\"alcohol\").\n",
    "#    - Se han seleccionado aquellas con correlaci√≥n absoluta > r_min (0.05).\n",
    "#    - Estas variables son las m√°s relevantes para predecir el contenido de alcohol en el vino.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas caracter√≠sticas antes del modelado.\n",
    "\n",
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity', 'residual sugar']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definici√≥n de columnas a incluir y excluir en el modelo de clasificaci√≥n.\n",
    "\n",
    "# columns_to_keep_clf ‚Üí Columnas que se mantendr√°n en el modelo de clasificaci√≥n.\n",
    "#    - Incluye:\n",
    "#      - target_clf (variable objetivo de clasificaci√≥n: \"quality\").\n",
    "#      - features_num_clf_1 (variables num√©ricas relevantes).\n",
    "#      - features_cat_clf (variables categ√≥ricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_clf ‚Üí Columnas que se excluir√°n del modelo de clasificaci√≥n.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_clf.\n",
    "#    - Estas columnas no ser√°n utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_clf = [target_clf] + features_num_clf_1 + features_cat_clf\n",
    "\n",
    "columns_to_exclude_clf = [col for col in df.columns if col not in columns_to_keep_clf]\n",
    "\n",
    "columns_to_exclude_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity', 'citric acid', 'sulphates']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definici√≥n de columnas a incluir y excluir en el modelo de regresi√≥n.\n",
    "\n",
    "# columns_to_keep_reg ‚Üí Columnas que se mantendr√°n en el modelo de regresi√≥n.\n",
    "#    - Incluye:\n",
    "#      - target_reg (variable objetivo de regresi√≥n: \"alcohol\").\n",
    "#      - features_num_reg_1 (variables num√©ricas m√°s correlacionadas con el target).\n",
    "#      - features_cat_reg (variables categ√≥ricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_reg ‚Üí Columnas que se excluir√°n del modelo de regresi√≥n.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_reg.\n",
    "#    - Estas columnas no ser√°n utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_reg = [target_reg] + features_num_reg_1 + features_cat_reg\n",
    "\n",
    "columns_to_exclude_reg = [col for col in df.columns if col not in columns_to_keep_reg]\n",
    "\n",
    "columns_to_exclude_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definici√≥n de Pipelines para preprocesamiento de datos en clasificaci√≥n.\n",
    "\n",
    "# cat_pipeline ‚Üí Preprocesamiento de variables categ√≥ricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor m√°s frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categor√≠as desconocidas.\n",
    "\n",
    "# logaritmica ‚Üí Transformaci√≥n logar√≠tmica de variables num√©ricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las caracter√≠sticas.\n",
    "\n",
    "# num_pipeline ‚Üí Preprocesamiento de variables num√©ricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformaci√≥n logar√≠tmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables num√©ricas.\n",
    "\n",
    "# imputer_step_cat ‚Üí ColumnTransformer para aplicar los Pipelines seg√∫n el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_clf_1 (variables num√©ricas).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_clf (variables categ√≥ricas).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_clf.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_cat ‚Üí Pipeline final que aplica el ColumnTransformer imputer_step_cat.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputaci√≥n con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categor√≠as desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") \n",
    "# Esto le indica al Pipeline que el n√∫mero de caracter√≠sticas no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_cat = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_clf_1), # feature_numericas seleccionadas para clasificaci√≥n\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_clf), # feature_categoriacas seleccionadas para regresi√≥n\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_clf)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_cat = Pipeline([(\"first_stage\", imputer_step_cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definici√≥n de Pipelines para preprocesamiento de datos en regresi√≥n.\n",
    "\n",
    "# cat_pipeline ‚Üí Preprocesamiento de variables categ√≥ricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor m√°s frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categor√≠as desconocidas.\n",
    "\n",
    "# logaritmica ‚Üí Transformaci√≥n logar√≠tmica de variables num√©ricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las caracter√≠sticas.\n",
    "\n",
    "# num_pipeline ‚Üí Preprocesamiento de variables num√©ricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformaci√≥n logar√≠tmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables num√©ricas.\n",
    "\n",
    "# imputer_step_reg ‚Üí ColumnTransformer para aplicar los Pipelines seg√∫n el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_reg_1 (variables num√©ricas seleccionadas para regresi√≥n).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_reg (variables categ√≥ricas seleccionadas para regresi√≥n).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_reg.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_reg ‚Üí Pipeline final que aplica el ColumnTransformer imputer_step_reg.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputaci√≥n con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categor√≠as desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") # Esto le indica al Pipeline que el n√∫mero de caracter√≠sticas no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_reg = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_reg_1), # feature_numericas seleccionadas para clasificaci√≥n\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_reg), # feature_categoriacas seleccionadas para regresi√≥n\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_reg)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_reg = Pipeline([(\"first_stage\", imputer_step_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06561088, -0.27783928, -0.1913355 , ...,  0.        ,\n",
       "         1.        ,  5.        ],\n",
       "       [ 0.061259  , -0.49980343, -0.57998343, ...,  0.        ,\n",
       "         1.        ,  7.        ],\n",
       "       [-0.06561088,  0.2893635 , -0.68457525, ...,  0.        ,\n",
       "         1.        ,  8.        ],\n",
       "       ...,\n",
       "       [ 0.061259  ,  1.14300849, -0.11427313, ...,  1.        ,\n",
       "         0.        ,  7.        ],\n",
       "       [ 0.78484693, -1.03933617,  0.41908799, ...,  1.        ,\n",
       "         0.        ,  5.        ],\n",
       "       [ 0.18624926, -1.28052007, -0.52783916, ...,  0.        ,\n",
       "         1.        ,  5.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicaci√≥n del pipeline de preprocesamiento a los datos de prueba.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df_test)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificaci√≥n.\n",
    "#    - Imputa valores faltantes en variables num√©ricas y categ√≥ricas.\n",
    "#    - Transforma variables categ√≥ricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformaci√≥n logar√≠tmica a las variables num√©ricas.\n",
    "\n",
    "# pipe_df_test ‚Üí Contiene los datos de prueba preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df_test = pipe_missings_cat.fit_transform(df_test)\n",
    "\n",
    "pipe_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05515355,  0.59288805, -0.20549433, ...,  1.        ,\n",
       "         0.        ,  5.        ],\n",
       "       [-1.05515355,  2.5608768 , -0.37024226, ...,  0.        ,\n",
       "         1.        ,  6.        ],\n",
       "       [ 1.11199789, -0.50565223, -0.5026097 , ...,  0.        ,\n",
       "         1.        ,  6.        ],\n",
       "       ...,\n",
       "       [-0.90744764,  0.46264335, -0.10702207, ...,  0.        ,\n",
       "         1.        ,  7.        ],\n",
       "       [ 0.5098244 , -0.14782501, -0.7688788 , ...,  0.        ,\n",
       "         1.        ,  8.        ],\n",
       "       [-1.05515355, -0.21826777, -0.53578111, ...,  0.        ,\n",
       "         1.        ,  6.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicaci√≥n del pipeline de preprocesamiento a los datos de entrenamiento.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificaci√≥n.\n",
    "#    - Imputa valores faltantes en variables num√©ricas y categ√≥ricas.\n",
    "#    - Transforma variables categ√≥ricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformaci√≥n logar√≠tmica a las variables num√©ricas.\n",
    "\n",
    "# pipe_df ‚Üí Contiene los datos de entrenamiento preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df = pipe_missings_cat.fit_transform(df)\n",
    "pipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "      <th>remainder__quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>0.592888</td>\n",
       "      <td>-0.205494</td>\n",
       "      <td>0.603446</td>\n",
       "      <td>-0.505241</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.706744</td>\n",
       "      <td>2.584726</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>2.560877</td>\n",
       "      <td>-0.370242</td>\n",
       "      <td>0.820606</td>\n",
       "      <td>0.855001</td>\n",
       "      <td>1.621578</td>\n",
       "      <td>1.011233</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>-1.312752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.111998</td>\n",
       "      <td>-0.505652</td>\n",
       "      <td>-0.502610</td>\n",
       "      <td>-1.317236</td>\n",
       "      <td>0.112504</td>\n",
       "      <td>-0.901360</td>\n",
       "      <td>-1.066182</td>\n",
       "      <td>-1.830435</td>\n",
       "      <td>0.312635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.548692</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.074260</td>\n",
       "      <td>0.564028</td>\n",
       "      <td>0.448623</td>\n",
       "      <td>0.059153</td>\n",
       "      <td>-1.000780</td>\n",
       "      <td>-0.177558</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320822</td>\n",
       "      <td>0.657314</td>\n",
       "      <td>1.525362</td>\n",
       "      <td>-2.003136</td>\n",
       "      <td>-3.095378</td>\n",
       "      <td>0.440977</td>\n",
       "      <td>-0.547423</td>\n",
       "      <td>0.391872</td>\n",
       "      <td>1.187890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>-0.619281</td>\n",
       "      <td>1.217401</td>\n",
       "      <td>-0.271299</td>\n",
       "      <td>1.282255</td>\n",
       "      <td>1.111562</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>-0.228277</td>\n",
       "      <td>0.322290</td>\n",
       "      <td>-1.022479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>-0.762183</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>0.089083</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>0.371746</td>\n",
       "      <td>1.276901</td>\n",
       "      <td>1.431729</td>\n",
       "      <td>-0.549087</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>-0.907448</td>\n",
       "      <td>0.462643</td>\n",
       "      <td>-0.107022</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.581225</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>0.645425</td>\n",
       "      <td>0.252264</td>\n",
       "      <td>0.477685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0.509824</td>\n",
       "      <td>-0.147825</td>\n",
       "      <td>-0.768879</td>\n",
       "      <td>0.045414</td>\n",
       "      <td>-0.365924</td>\n",
       "      <td>-1.936549</td>\n",
       "      <td>-1.662178</td>\n",
       "      <td>-1.332210</td>\n",
       "      <td>1.991478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.535781</td>\n",
       "      <td>1.010544</td>\n",
       "      <td>0.521557</td>\n",
       "      <td>-1.017779</td>\n",
       "      <td>-0.355475</td>\n",
       "      <td>-0.624929</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -1.055154                      0.592888   \n",
       "1                             -1.055154                      2.560877   \n",
       "2                              1.111998                     -0.505652   \n",
       "3                             -0.548692                     -0.218268   \n",
       "4                              0.320822                      0.657314   \n",
       "...                                 ...                           ...   \n",
       "5192                          -0.619281                      1.217401   \n",
       "5193                          -0.762183                     -0.218268   \n",
       "5194                          -0.907448                      0.462643   \n",
       "5195                           0.509824                     -0.147825   \n",
       "5196                          -1.055154                     -0.218268   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.205494                              0.603446   \n",
       "1                      -0.370242                              0.820606   \n",
       "2                      -0.502610                             -1.317236   \n",
       "3                      -0.074260                              0.564028   \n",
       "4                       1.525362                             -2.003136   \n",
       "...                          ...                                   ...   \n",
       "5192                   -0.271299                              1.282255   \n",
       "5193                    0.089083                             -0.011858   \n",
       "5194                   -0.107022                              0.255061   \n",
       "5195                   -0.768879                              0.045414   \n",
       "5196                   -0.535781                              1.010544   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                 -0.505241                  0.427700   \n",
       "1                                  0.855001                  1.621578   \n",
       "2                                  0.112504                 -0.901360   \n",
       "3                                  0.448623                  0.059153   \n",
       "4                                 -3.095378                  0.440977   \n",
       "...                                     ...                       ...   \n",
       "5192                               1.111562                  0.626829   \n",
       "5193                               0.371746                  1.276901   \n",
       "5194                               0.581225                 -0.003952   \n",
       "5195                              -0.365924                 -1.936549   \n",
       "5196                               0.521557                 -1.017779   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0                0.706744                    2.584726   \n",
       "1                1.011233                    0.998990   \n",
       "2               -1.066182                   -1.830435   \n",
       "3               -1.000780                   -0.177558   \n",
       "4               -0.547423                    0.391872   \n",
       "...                   ...                         ...   \n",
       "5192            -0.228277                    0.322290   \n",
       "5193             1.431729                   -0.549087   \n",
       "5194             0.645425                    0.252264   \n",
       "5195            -1.662178                   -1.332210   \n",
       "5196            -0.355475                   -0.624929   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                     0.720172                             1.0   \n",
       "1                    -1.312752                             0.0   \n",
       "2                     0.312635                             0.0   \n",
       "3                    -0.927596                             0.0   \n",
       "4                     1.187890                             1.0   \n",
       "...                        ...                             ...   \n",
       "5192                 -1.022479                             0.0   \n",
       "5193                 -0.927596                             0.0   \n",
       "5194                  0.477685                             0.0   \n",
       "5195                  1.991478                             0.0   \n",
       "5196                  0.720172                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  remainder__quality  \n",
       "0                                  0.0                 5.0  \n",
       "1                                  1.0                 6.0  \n",
       "2                                  1.0                 6.0  \n",
       "3                                  1.0                 6.0  \n",
       "4                                  0.0                 7.0  \n",
       "...                                ...                 ...  \n",
       "5192                               1.0                 5.0  \n",
       "5193                               1.0                 5.0  \n",
       "5194                               1.0                 7.0  \n",
       "5195                               1.0                 8.0  \n",
       "5196                               1.0                 6.0  \n",
       "\n",
       "[5197 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversi√≥n de los datos preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos preprocesados (pipe_df) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las caracter√≠sticas generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check ‚Üí Contiene los datos de entrenamiento preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check = pd.DataFrame(pipe_df, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "      <th>remainder__quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>-0.277839</td>\n",
       "      <td>-0.191336</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.831639</td>\n",
       "      <td>-0.433274</td>\n",
       "      <td>-1.146519</td>\n",
       "      <td>-0.036117</td>\n",
       "      <td>-1.034552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.499803</td>\n",
       "      <td>-0.579983</td>\n",
       "      <td>0.200694</td>\n",
       "      <td>0.019098</td>\n",
       "      <td>-1.467980</td>\n",
       "      <td>-0.701377</td>\n",
       "      <td>-0.919534</td>\n",
       "      <td>1.489510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>0.289363</td>\n",
       "      <td>-0.684575</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>-1.164893</td>\n",
       "      <td>0.887973</td>\n",
       "      <td>0.514885</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.661389</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>-0.789574</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.594218</td>\n",
       "      <td>-1.437325</td>\n",
       "      <td>0.469593</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.351239</td>\n",
       "      <td>-0.475795</td>\n",
       "      <td>1.255666</td>\n",
       "      <td>0.502182</td>\n",
       "      <td>-1.812097</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.395421</td>\n",
       "      <td>1.414987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>-0.292330</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>0.166421</td>\n",
       "      <td>0.349361</td>\n",
       "      <td>1.050532</td>\n",
       "      <td>1.146368</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.542576</td>\n",
       "      <td>-1.130887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.842435</td>\n",
       "      <td>0.888607</td>\n",
       "      <td>2.218732</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>-0.940203</td>\n",
       "      <td>1.268510</td>\n",
       "      <td>1.006277</td>\n",
       "      <td>2.132366</td>\n",
       "      <td>-0.475482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>1.143008</td>\n",
       "      <td>-0.114273</td>\n",
       "      <td>-2.309748</td>\n",
       "      <td>-3.358761</td>\n",
       "      <td>-0.015075</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>1.102750</td>\n",
       "      <td>1.339897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>0.784847</td>\n",
       "      <td>-1.039336</td>\n",
       "      <td>0.419088</td>\n",
       "      <td>-1.861014</td>\n",
       "      <td>-3.091298</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>2.329225</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>0.797644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>0.186249</td>\n",
       "      <td>-1.280520</td>\n",
       "      <td>-0.527839</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.542123</td>\n",
       "      <td>0.348801</td>\n",
       "      <td>-0.178400</td>\n",
       "      <td>-0.939147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -0.065611                     -0.277839   \n",
       "1                              0.061259                     -0.499803   \n",
       "2                             -0.065611                      0.289363   \n",
       "3                             -0.661389                      0.080702   \n",
       "4                              0.061259                     -0.351239   \n",
       "...                                 ...                           ...   \n",
       "1295                          -0.292330                      0.080702   \n",
       "1296                           0.842435                      0.888607   \n",
       "1297                           0.061259                      1.143008   \n",
       "1298                           0.784847                     -1.039336   \n",
       "1299                           0.186249                     -1.280520   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.191336                              0.609936   \n",
       "1                      -0.579983                              0.200694   \n",
       "2                      -0.684575                              0.441142   \n",
       "3                      -0.789574                              0.798095   \n",
       "4                      -0.475795                              1.255666   \n",
       "...                          ...                                   ...   \n",
       "1295                    0.166421                              0.349361   \n",
       "1296                    2.218732                              0.527821   \n",
       "1297                   -0.114273                             -2.309748   \n",
       "1298                    0.419088                             -1.861014   \n",
       "1299                   -0.527839                              0.609936   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                  0.831639                 -0.433274   \n",
       "1                                  0.019098                 -1.467980   \n",
       "2                                  0.048148                 -1.164893   \n",
       "3                                  0.594218                 -1.437325   \n",
       "4                                  0.502182                 -1.812097   \n",
       "...                                     ...                       ...   \n",
       "1295                               1.050532                  1.146368   \n",
       "1296                              -0.940203                  1.268510   \n",
       "1297                              -3.358761                 -0.015075   \n",
       "1298                              -3.091298                 -0.127250   \n",
       "1299                               0.671446                  0.542123   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0               -1.146519                   -0.036117   \n",
       "1               -0.701377                   -0.919534   \n",
       "2                0.887973                    0.514885   \n",
       "3                0.469593                    0.104306   \n",
       "4               -1.339665                   -0.395421   \n",
       "...                   ...                         ...   \n",
       "1295            -1.339665                   -0.542576   \n",
       "1296             1.006277                    2.132366   \n",
       "1297            -0.078471                    1.102750   \n",
       "1298             2.329225                    0.104306   \n",
       "1299             0.348801                   -0.178400   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                    -1.034552                             0.0   \n",
       "1                     1.489510                             0.0   \n",
       "2                     1.636890                             0.0   \n",
       "3                     1.636890                             0.0   \n",
       "4                     1.414987                             0.0   \n",
       "...                        ...                             ...   \n",
       "1295                 -1.130887                             0.0   \n",
       "1296                 -0.475482                             1.0   \n",
       "1297                  1.339897                             1.0   \n",
       "1298                  0.797644                             1.0   \n",
       "1299                 -0.939147                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  remainder__quality  \n",
       "0                                  1.0                 5.0  \n",
       "1                                  1.0                 7.0  \n",
       "2                                  1.0                 8.0  \n",
       "3                                  1.0                 6.0  \n",
       "4                                  1.0                 7.0  \n",
       "...                                ...                 ...  \n",
       "1295                               1.0                 5.0  \n",
       "1296                               0.0                 4.0  \n",
       "1297                               0.0                 7.0  \n",
       "1298                               0.0                 5.0  \n",
       "1299                               1.0                 5.0  \n",
       "\n",
       "[1300 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversi√≥n de los datos de prueba preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df_test, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos de prueba preprocesados (pipe_df_test) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las caracter√≠sticas generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check_test ‚Üí Contiene los datos de prueba preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check_test = pd.DataFrame(pipe_df_test, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACI√ìN DE MODELOS DE CLASIFICACI√ìN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quality'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_check\n",
    "y_train = df[target_clf]\n",
    "X_test = df_check_test\n",
    "y_test = df_test[target_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelos_clasificacion(X_train_scaled, y_train):\n",
    "    \"\"\"\n",
    "    Entrena y eval√∫a m√∫ltiples modelos de clasificaci√≥n utilizando validaci√≥n cruzada.\n",
    "    \"\"\"\n",
    "    model_names = [\n",
    "        \"Logistic Regression\", \"SVC\", \"Decision Tree\", \"Random Forest\", \"KNN\", \n",
    "        \"Gradient Boosting\", \"AdaBoost\", \"XGBoost\", \"LightGBM\", \"CatBoost\"\n",
    "    ]\n",
    "    model_set = [\n",
    "        LogisticRegression(max_iter=10000),\n",
    "        SVC(),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        KNeighborsClassifier(),\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        LGBMClassifier(random_state=42, verbose=-100),\n",
    "        CatBoostClassifier(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    ]\n",
    "    metricas_cv = {}\n",
    "    valores = []\n",
    "    for nombre, modelo in zip(model_names, model_set):\n",
    "        print(f\"Evaluando modelo: {nombre}...\")\n",
    "        try:\n",
    "            scores = cross_val_score(modelo, X_train_scaled, y_train, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "            metricas_cv[nombre] = scores\n",
    "            valores.append(np.mean(scores))\n",
    "        except Exception as e:\n",
    "            print(f\"Error con el modelo {nombre}: {e}\")\n",
    "            metricas_cv[nombre] = None\n",
    "            valores.append(-np.inf)\n",
    "    ganador = model_names[np.argmax(valores)]\n",
    "    print(f\"\\nEl modelo ganador es: {ganador} con una accuracy media de {np.max(valores):.4f}\\n\")\n",
    "    resultados_df = pd.DataFrame({\n",
    "        \"Modelo\": model_names,\n",
    "        \"Accuracy Media\": valores\n",
    "    }).sort_values(by=\"Accuracy Media\", ascending=False)\n",
    "    print(resultados_df)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=\"Accuracy Media\", y=\"Modelo\", data=resultados_df, palette=\"viridis\", hue=None)\n",
    "    plt.title(\"Comparaci√≥n de Modelos - Accuracy Media\", fontsize=16)\n",
    "    plt.xlabel(\"Accuracy Media\", fontsize=12)\n",
    "    plt.ylabel(\"Modelos\", fontsize=12)\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando modelo: Logistic Regression...\n",
      "Evaluando modelo: SVC...\n",
      "Evaluando modelo: Decision Tree...\n",
      "Evaluando modelo: Random Forest...\n",
      "Evaluando modelo: KNN...\n",
      "Evaluando modelo: Gradient Boosting...\n",
      "Evaluando modelo: AdaBoost...\n",
      "Evaluando modelo: XGBoost...\n",
      "Error con el modelo XGBoost: \n",
      "All the 3 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got [3 4 5 6 7 8 9]\n",
      "\n",
      "Evaluando modelo: LightGBM...\n",
      "Evaluando modelo: CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "2 fits failed out of a total of 3.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: ./catboost_temp_fix\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El modelo ganador es: CatBoost con una accuracy media de nan\n",
      "\n",
      "                Modelo  Accuracy Media\n",
      "2        Decision Tree        1.000000\n",
      "5    Gradient Boosting        1.000000\n",
      "8             LightGBM        0.999038\n",
      "0  Logistic Regression        0.993650\n",
      "3        Random Forest        0.993458\n",
      "1                  SVC        0.993073\n",
      "4                  KNN        0.908986\n",
      "6             AdaBoost        0.771407\n",
      "7              XGBoost            -inf\n",
      "9             CatBoost             NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_10100\\174657.py:41: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"Accuracy Media\", y=\"Modelo\", data=resultados_df, palette=\"viridis\", hue=None)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFwAAAIrCAYAAADSjo2KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACsN0lEQVR4nOzdeVhUZf8/8PeZGVaBQUDZRBE30FwwcM8Vc8/ct3LXntwydytzySV90tJstQStfFyy3HJJTazUFFTQCtQUwwXFDRBFcGbu3x/+mK8jiyyDwz28X9fFdcWcM+d8zvAecD7d574VIYQAERERERERERGZjcrSBRARERERERERWRs2XIiIiIiIiIiIzIwNFyIiIiIiIiIiM2PDhYiIiIiIiIjIzNhwISIiIiIiIiIyMzZciIiIiIiIiIjMjA0XIiIiIiIiIiIzY8OFiIiIiIiIiMjMNJYugIiIiOTz8OFDLF26FFlZWRg/fjzKly9v6ZKIiIiIShWOcCEiIqJCmz59OmbOnAl7e3s2W4iIiIhywYYLERGZ1d69ezFs2DDUrFkTLi4usLOzg7e3N9q3b48PP/wQN27csHSJlIvIyEgoioLWrVs/dd8tW7bgww8/xJgxYzBt2rSSL66ALl68CEVR4O/vX+Lnyn69sr9OnjyZ7/516tQx7jty5MgSrw8A5syZA0VRMGfOHLMcr3Xr1lAUBZGRkWY5XmlVv359KIoCOzs73Lp1y9LlUC4ef+99+OGH+e47duxY477Vq1d/JvXl9fv0Wf6OIqLSgQ0XIiIyi5s3b6J9+/Z48cUXERERgYcPH6JNmzbo1asXgoKCcPjwYUyaNAkBAQE4evSopculIkpISMCwYcPw0ksvYcWKFZYup9RYvXp1ntv++OMP/P3338+wGiqqqKgonDp1CgCQlZWFb7/91sIV0dOEh4fnue3BgwdYt27dM6yGiMgUGy5ERFRsqampaNGiBfbt24fAwED8+uuvSEhIwNatW7Fu3Tr88ssvuH37Nr744gs4OTkhKSnJ0iXTExo1aoS4uDisXbs23/1iYmIwZcoU/O9//4NarX5G1ZVelStXRsWKFbFu3TpkZmbmuk92MyY0NPRZlkZF8PXXXwMAfH19Tb6n0ikkJASnT59GVFRUrtt/+OEHpKSklJr3nq+vL+Li4rB//35Ll0JEzwgbLkREVGzjx4/HmTNn4O/vj0OHDuGFF17IsY+dnR1Gjx6NmJgYBAUFWaBKyo+joyMCAwNRuXLlfPfr0aMH3n77bTg6Oj6jyko3GxsbvPLKK7h9+za2bNmSY/v9+/exfv16+Pr6okOHDs++QCqw+/fv43//+x8A4JtvvoGTk1O+H+bJ8oYPHw4g7xFm2Q2z7P0szcbGBoGBgahWrZqlSyGiZ4QNFyIiKpYLFy4Yh2wvW7YMbm5u+e7v6emJWrVq5Xh8/fr1aNeuHdzc3GBnZ4cqVapg+PDhOHv2bK7H8ff3h6IouHjxInbt2oXWrVtDq9WifPny6Nq1K06fPm3cd926dWjatCmcnZ3h6uqKnj174vz58zmO+fh99/fv38dbb72F6tWrw97eHj4+PhgxYgSuXLmSaz379u3D+PHj0aBBA3h4eMDOzg6VKlVCv3798vzA9vgcG4mJiRgxYgT8/PxgY2ODoUOHGvf74YcfMHLkSDz33HMoX7487O3tUbVqVQwfPhxnzpzJ7+XGL7/8gj59+qBSpUqws7NDhQoVEBoaitmzZ5vMT/G0OVzi4+MxbNgwVKlSBXZ2dnBzc0O7du2wcePGp17bjRs3MHbsWPj5+cHW1hZ+fn4YP348UlJS8q09Lzt27ECrVq3g7OwMrVaLF154AVu3bn3q8+7cuYPZs2ejQYMGcHZ2hqOjI+rWrYv58+fj/v37RaoFyP9D36ZNm3D37l0MHjz4qSOCjh07hr59+8LHxwe2traoWLEiunXrhr179+b5nIyMDMyZMwc1atQwzpc0ZMgQJCYmPrXu48ePY9CgQahcubLxZ9qhQwfs3Lnzqc99kk6nw+eff45mzZpBq9XC3t4eNWrUwIQJE/J8z5w7dw7Dhw9H1apVYWdnBycnJ1SpUgVdunTJ9zaRkrJp0yakpaXhueeeQ5s2bdCvXz8ATx/lcufOHcybNw8hISHQarVwcHBAQEAA+vbti127duXYX6fTYfXq1QgLCzP5XREWFoaPP/7YZN+nzZuT1zw9peV3y+zZs6EoCl577bU8j3Ps2DEoigJfX1/odLp8z/mkTp06wcvLC+vXr8eDBw9MtiUkJODAgQNo2rQpAgMD8z1ORkYGli5diiZNmsDV1RX29vaoVasWpk2blu88PmvXrkVoaCgcHR3h5uaGjh074rfffstz//zmcDl27BimTZuGRo0awcvLC7a2tvD09ES3bt2wb9++/F8IIiq9BBERUTEsX75cABCurq5Cp9MV+vkGg0EMHjxYABAajUa0bdtW9O/fX9SsWVMAEI6OjmLXrl05nlelShUBQMyYMUMoiiKaN28u+vbta3yeq6ur+Oeff8TUqVONx+3du7fw8/MTAISPj4+4ffu2yTEPHDggAIimTZuKJk2aCEdHR9G5c2fRp08f4e3tLQAILy8vcfbs2Rz1VKtWTdja2org4GDx0ksviZ49e4ratWsbr+v777/P8ZzZs2cLAGLgwIHCzc1NeHl5iV69eomePXuKyZMnG/dTq9XC0dFRhISEiJ49e4qXXnpJBAQECACiXLly4tChQ7m+tuPHjxcABADRoEED0b9/f9GpUyfjcw8cOJDj2lu1apXjODt27BD29vYCgKhVq5bo37+/aNu2rVCr1QKAGD58eJ7XNnz4cFGpUiXh6ekpevbsKTp37iy0Wq0AIEJDQ0VWVlautedl2bJlxmtq1KiRGDBggAgJCREAxKRJkwQAUaVKlRzP++uvv4w/e29vb9GxY0fRrVs34enpaXx9UlJSClxH9utVrVo1IYQQjRo1EiqVSiQmJprs98ILLwgA4uzZs8bXZMSIETmO9+WXXwqVSiUAiODgYDFgwADRrFkz47XOmTMnx3Pu3bsnmjRpYsxB165dRZ8+fYSnp6dwd3c3vq9mz56d47kfffSR8XwNGjQQvXv3Fi1atBC2trYCgJg7d26O57Rq1SpHboQQ4sGDByIsLEwAEPb29qJTp06iX79+xtfbw8NDHD9+3OQ5p0+fFi4uLsZM9ezZU/Tp00c0bdpUODk5ifr16z/lJ2B+2T+rZcuWCSGEOHTokAAgtFqtuH//fq7PiYmJEb6+vsb9OnfuLPr16yeaNm0qHBwccryfUlJSRIsWLQQAYWNjI1q1aiUGDBgg2rRpIypUqCCe/Kd5Xq95tuxMPfkzLi2/W5KSkoStra0oV66cuHPnTq7Hys5pbpnLS/a5L126JKZNmyYAiG+//dZkn1mzZgkAYtWqVTner4+7cuWKqFu3rgAg3NzcRFhYmOjRo4fxb4y/v7+4ePFijudNmDBBABAqlUq0bNlS9O/fX9SuXVuoVCrxxhtv5Pr7NCEhIc/fUe3atRMqlUrUrVvX+HenYcOGxmv96KOPCvz6EFHpwYYLEREVy6uvvioAiLZt2xbp+Z999pnxQ9nJkyeNjxsMBuOHBldXV5GcnGzyvOx/DNvZ2Yl9+/YZH9fpdKJPnz4CgHjuueeEu7u7iImJMW6/d++e8YPs/PnzTY6Z/Y9yAKJ69eri33//NW7LyMgQvXr1EgBEkyZNclzHjz/+mKOBk/24RqMR7u7uOT60ZV8fAPHKK6+IBw8e5PoarV+/XqSnp5s8ZjAYxCeffCIAiDp16giDwWCyfcWKFQKAcHd3F7/88kuOYx49etSkOZBXw+XatWvGBsn8+fNNzhMVFSXKly8vAIgvv/wyz2sbOnSoybUlJiYaP6SuW7cu12vOTWxsrFCr1UKlUolNmzaZbPv222+Foii5fpi5f/++qFatmgAg3nnnHZGZmWncdu/ePTFgwAABQAwbNqzAtTz5Ae6LL74QAMS8efOM+5w9e1YAEC1btjR5TZ5suJw6dUpoNBqhKIpYu3atybadO3camyA///yzybYpU6YIACIwMFBcuXLF5Jq6d+9ufP2f/DC+e/duoSiK8PDwEAcPHsxRS6VKlQQAERkZabItrw//06dPN74WCQkJxsezsrLEiBEjBABRtWpVk9d92LBhub4HhXj083qyrpJ25swZYxPk8d81gYGBAkCOn4sQQqSnpxubSoMHDxZ379412Z6SkiL27t1r8ljPnj2NTbXHXyshhHj48KHYsmWLyWPFbbiUht8tgwYNMmlkPe7GjRvCzs5O2NjYiKSkpFxrzM3jDZf4+Pgcf4P0er2oXLmyKFeunEhLS8uz4WIwGETz5s2N78u0tDTjtocPH4rJkycLAKJNmzYmz9uxY4exKfXrr7+abFu4cKGxvsI0XHbu3CmuXr2a4/HDhw8LFxcXYWNjIy5fvlzQl4iISgk2XIiIqFg6duwoAIj+/fsX6fnZH4RXrFiRY5vBYBD16tUTAMSCBQtMtmU3XKZOnZrjeSdOnDD+g/eTTz7JsX3z5s25/iP68YbLkx98hBDi+vXrwtHRUQDI8//85ib7A/1PP/1k8nj2hyI3N7dCja54XNOmTQUA8ddffxkfe/jwofH/lm/evLlAx8mr4fLee+8JAOL555/P9XkffPCBACBq1Khh8nj2tVWqVEncu3cvx/Pef//9PEfH5GXkyJECgOjXr1+u27ObDE9+mMlu6nXt2jXX5929e1dUrFhRaDSaXJtmuXnyA1xqaqpwdHQUAQEBxg+oM2bMEABERESEECLvhkt2U6Jnz565nmvcuHECgGjfvr3xsfv37wtnZ2cBINcRYElJScZRSU9+GG/cuLEAkOuoKyGE2LhxowAgevXqZfJ4bh/+MzIyhJOTkwAgtm3bluNY9+7dM44i+u6774yPd+7cWQAQJ06cyLWGZy27afTkNS9ZsiTX94UQj0YJZY/wKMjovpiYGOMooIJ+cC5uw6U0/G45duyY8XfEk82bRYsWCQBiwIABhart8YaLEEI0b95cKIpibGLt3r3b2OwVIuf7NduuXbuMP8OHDx/mOI9erxfPPfecACBOnz5tfDx7RNf06dNzra9BgwaFbrjkZ+bMmXn+PSOi0o1zuBARkcVcvnzZOJfKkCFDcmxXFAXDhg0DABw4cCDXY3Tu3DnHYzVq1CjQ9qtXr+Z6TFdXV7z00ks5Hq9YsSI6duwIALnOqXD16lWsWrUKkydPxsiRIzF06FAMHToUf/31FwDkOSdCWFgYtFptrtuy/fPPP1i5ciUmTpyIESNGGI99/fr1HMc+fvw4bty4AQ8PD/To0SPf4z5N9nXm9vMBgBEjRgB4NB9Hbq9nu3btcp1gN3vi5Lzm98ivlldeeSXX7XnV+NNPPwGAcU6OJzk5OSEkJAQ6na7IE6S6uLigV69euHDhAiIjI6HX67F27Vo4OzujT58++T43+7oen1vjcdmv8W+//Qa9Xg8AOHHiBO7evQsPDw9jJh/n5eWFF198McfjN2/exLFjx+Dg4IBu3brler7seXwOHz6cb90AEB0djfT0dLi5ueV6PEdHR/Tv3x+A6Xu4UaNGAIDXX38de/bsyTH/xrOk0+mwZs0aADknVx08eDA0Gg1+/fXXHPM+7d69G8Cjn09BVuzK3r9Lly7GVZBKWmn43RIaGoqmTZvi3Llz2LNnj/Fxg8GAzz//HAAwbty4wl6aieHDh0MIYZz7J3s+padNlpv9u6FXr17QaDQ5tqtUKrRs2RLA/70fdDodfv/9dwB5/y4aPHhwEa4CuHXrFtauXYtp06Zh1KhRxp/FwYMHAeT9N4SISq+cv1mIiIgKoUKFCgCA5OTkQj83+8O2u7s7XFxcct0nezWHvD6Y57aqjpOTU77bnZ2dASDPD3nZE/LmpmrVqgAeNYseN3fuXCxYsAAPHz7M9XkAkJaWluf58qLX6zFu3Dh88cUXEEIU6Nj//vsvAKBWrVp5XkdBZb/u2df9JFdXV7i5ueH27du4fPkyfHx8TLbntepR9s+7MB+0s1/zvGrJ6/ELFy4AAF599VW8+uqr+Z7jxo0bBa7nScOHD8c333yD1atX4/79+7h69SpGjhz51BWdnvYaZ78HHjx4gFu3bqFixYrG1yK/7OR2vISEBAghkJGRATs7u3zrKshr8bTagdzfw1OnTsXvv/+Offv2oWPHjrCxsUH9+vXRsmVL9O/fv8DL+N68eRNTpkzJ8XhgYCBmzJhRoGP89NNPuHbtWq4rSXl6eqJz587Ytm0bVq9ejQULFhi3Zb/PnjYha1H3N4fS8rtlwoQJOHLkCFauXGlsEO7YsQP//vsvgoOD0axZswIfKzd9+/bFG2+8gTVr1mD8+PHYunUratSokeuKeY/L/t0wa9YszJo1K999s98Pt27dMv7eKuzvovysWrUKb775Ju7du5fnPnn9DSGi0osNFyIiKpbnn38e33zzDU6cOAG9Xl+g/9NrTipV/oM1n7a9qB7/gPLDDz9gzpw5cHJywsqVK9G2bVv4+PjAwcEBiqLgrbfewqJFi/L8UOPg4JDneZYvX47PP/8cXl5eWLZsGZo1awZPT0/Y29sDAAYOHIj//e9/+X5gsqSSev0Lw2AwAAA6duwIT0/PfPetUqVKkc/TqlUrVKtWDZs3b8a1a9cAlJ7laLNlvxZOTk7o1auXxepwdHTE3r17ERUVhd27d+Pw4cM4fPgwoqOjsWzZMowZMwaffPLJU4+Tnp5uHJ3yuFatWhW44ZK9CtGDBw/QqlWrHNuzG0URERGYN2/eM/8dl5/sn2deSsvvlt69e2PKlCnYtWsXEhISULVqVePPt7ijW4BHee7Tpw/Cw8MxfPhwZGZmGkdH5if79WvRosVTl2quU6dOsevMy/Hjx/Haa69BrVZj8eLF6NatGypXrgxHR0coioIvv/wSr732Wqn9PU9EeWPDhYiIiqVr166YNGkSUlJSsG3btkLdwpI9rP7WrVtIS0vLdZRL9v+BfFZD8IFHS3c+bVulSpWMj2UvjbxgwQKMHj06x3POnTtX5Fqyj/3FF1/keptTbsfOHlVy9uxZCCGKNcrF19cX8fHxxp/Dk1JTU3H79m3jviXJ19cX58+fx8WLF3P98JPXz83Pzw/x8fEYMWIEevfuXWL1KYqCoUOHYtasWdi3bx+CgoLQtGnTpz4v+7ouXLiA5557Lsf27Nfe3t7euOx69mtdkKw+zs/Pz1jr6tWri90Qy64jISEhz33yew+HhoYaR7PodDps2bIFgwcPxqefforevXujTZs2+Z7f39+/WB9Ck5KSjMtg37p1C4cOHcpz36tXr2L37t3o0qULgEfvs7i4OMTHxyMsLOyp58p+X8bHxxe4PltbWwDA3bt3c92ePeKkKJ7l7xaNRoPXX38d77zzDj799FOMGjUKe/fuhZubGwYMGFDka3jc8OHDER4eju3bt0OtVud5i+Hjst8P3bt3z3WkVG7c3d1hZ2eHzMzMQv8uysumTZsghMD48eMxbdq0HNuL8zeEiCzL8v/biYiIpFatWjXjP5gnT55s/PCdl+TkZON96JUqVTL+X8WIiIgc+wohjI8/7YOXOaWkpGD79u05Hr9x44ZxHobseS4AGK85t9ERycnJ2Lt3b5Frye/Yf/31F2JiYnI8HhISAg8PD9y4cQNbtmwp8rmB/7vO3EYRAP83V0KNGjVKvOGSPfrgu+++y3X72rVrc328U6dOAP7vA2ZJGjp0KCpUqAB3d3e89tprBXpO9muc23sA+L/X+IUXXjDOM/H888/DyckJN2/exM8//5zjOdevX8/1cR8fH9SrVw937941Zrk4QkJC4OTkhNu3b2Pbtm05tmdkZGD9+vUAnv4e1mg06N27t/G2ntyybW4RERHQ6/Vo3LgxxKPFJHL9yv4QnD0aBoDx1pjVq1cb59bJT/b+O3fuzHP+qCdlv6fi4uJybLt//36ec1sVxLP+3fLaa6/B3t4eq1evxtKlSyGEwIgRI/IdhVMYLVq0QEhICNzd3dGzZ88ctzfmJvt3Q3bDoyA0Gg2aN28OIO/fRd98800Bq34kv5/FgwcPsHnz5kIdj4hKDzZciIio2D7++GNUr14dCQkJaNGihXFCwcdlZWVh9erVCA4ONvnwkP1/Fd977z3ExsYaHxdCYP78+YiJiYGrqytGjRpV8hfymMmTJ5vM05KZmYmxY8fi3r17aNSokfEf3MD/TQD75ZdfIisry/h4amoqhgwZgtTU1CLXkX3sTz75xOT2gaSkJAwePBg6nS7HczQaDd5++20AwOjRo/Hrr7/m2CcqKirHPDS5GTVqFFxcXHDixAksXLjQ5EPJyZMnMX/+fACP5uQoaePHj4darcbGjRvx448/mmxbv359nh8AR48ejSpVqmDTpk2YPn16rqMFrl27hlWrVhW7xkqVKiE5ORk3b97EG2+8UaDnvPHGG9BoNNiyZQu+/fZbk20///wzvvjiCwAw+T/wDg4OxtFUb775JpKSkozbMjIy8PrrryMjIyPX82X/zIYNG5ZrY1EIgaNHj+basHmSvb09xo4dC+DRe+bxERcPHz7EG2+8gWvXrqFq1aomo4s+/fTTXCcAvXbtGqKjowEU7/augspuZj1tNET2JKg7duwwzuUxcuRIVKpUCSdPnsSoUaNyzL2RlpaGffv2Gb9v0KABunfvjoyMDHTv3h2JiYkm++t0uhxNq+yRM5988onJHDj37t3D6NGjcenSpcJcroln/bvFw8MDAwcOxO3bt/Hll19CpVJhzJgxRa4/N1FRUbh582aBm6vdu3dHaGgojh07hmHDhuU6b9GdO3fw+eefm7weEydOBPDob9+Tk0svWbIEJ06cKFTd2T+LNWvWmPx+evDgAcaMGZPvCDIiKuWe1XJIRERk3a5fvy5at25tXK6zatWqonv37mLAgAGibdu2xqVjXVxcxNGjR43PMxgM4tVXXxUAhEajEe3atRMDBgwQtWrVEgCEg4OD2LlzZ47zZS8Lnb0M6JOy68hNXktzZi8d2rRpU9G4cWPh6OgounbtKvr27St8fHwEAFGxYkURHx9v8rwLFy4IV1dXAUD4+vqKXr16iZdeeklotVrh7e0thg8fnu/SrU8+/rg//vhD2NraCgCievXqom/fvqJjx47CwcFB1KlTR/To0UMAEOHh4SbPMxgM4j//+Y/xdQgODhb9+/cXnTt3FgEBATmWms1rWWghhNi+fbtxieHAwEAxYMAA0a5dO6HRaAQAMWzYsBzPedq15Xe+/GQv0wtANG7cWAwcOFCEhoYKAOLNN9/Mc8nVP//8U/j7+wsAwtXVVbRs2VIMHDhQvPzyy6J27dpCURTh6elZ4DryWmY2P3ktCy2EEF988YVQqVQCgGjYsKEYOHCgcalbAGLOnDk5npOeni4aNWokAAgnJyfRrVs30adPH+Hl5SXc3d3F4MGD8/wZLF++3Pjzq169uujSpYsYOHCgaN++vahYsWKuS97mtUTxgwcPRLt27Yzv186dO4t+/fqJypUrCwDC3d1dREdHmzynfv36xt8T3bp1E4MGDRIvvviicHBwEABE27Ztc12m15wiIyMFAGFnZ1eg5cAbNmwoAIgPPvjA+NiJEyeEl5eXMVddunQR/fr1E82aNRMODg458n379m3RpEkTAUDY2tqK1q1bi4EDB4q2bdsal1t+XFZWlggJCREAhFarFV26dBGdOnUSFSpUEL6+vlL8bnlc9tLYAES3bt2e9pLnKfsY2ctCP01+79crV64Yl3EuV66caNasmejfv7/o2bOnaNCggVCr1QKAyMjIMHne2LFjBQChUqlE69atxYABA0SdOnWESqUSb7zxRqGWhb5z547xb5q7u7t4+eWXRa9evUTFihWFs7Oz8XhDhgwpzMtERKUAGy5ERGRWu3btEoMHDxbVq1cXTk5OwsbGRnh5eYn27duLjz76SNy6dSvX561bt060bt1auLq6ChsbG+Hn5yeGDh2ao7mRrSQbLq1atRLp6eli6tSpomrVqsLW1lZ4enqKoUOHisTExDyPOWjQIFG5cmVhZ2cnqlSpIv7zn/+Ia9eu5fnhpyAfioQQ4tSpU+Kll14S3t7ewt7eXtSoUUNMmzZNpKWliSFDhuT6oSjbrl27RPfu3YWnp6ewsbERFSpUEI0aNRJz5841+Vk8rQHy999/iyFDhohKlSoJGxsb4erqKtq0aSPWr1+f6/4l1XARQoitW7eKFi1aiHLlygknJyfRrFkz8f333+f5c82WlpYmlixZIpo2bWrMmbe3twgNDRVTp04Vhw8fLnAN5m64CPHoA3Dv3r2Fl5eX0Gg0wt3dXXTp0kX8/PPPeR7z3r17YtasWaJatWrGnA4aNEgkJCQ89Wdw+vRpMXr0aFGjRg1hb28vHB0dRUBAgOjQoYNYsWKFuHLlisn+eTVchBDi4cOH4tNPPxVNmjQRzs7OwtbWVlSrVk2MHz9eXL58Ocf+O3bsEK+//roIDg4WFSpUELa2tqJSpUqidevWYs2aNSIrKyvvF9JMshu9vXv3LtD+H330kQAggoKCTB6/ceOGeOedd0TdunVFuXLlhIODgwgICBD9+vUTu3fvznGczMxM8dlnn4kXXnhBuLq6Gq+9ffv24pNPPsmx/507d8S4ceOM7z1fX18xevRocf36dSl+tzwpu0G1Z8+efGvLjzkbLkI8ahp+/vnnok2bNsLd3V1oNBpRsWJF0aBBAzF27Ng8a129erV4/vnnhb29vdBqtSIsLEwcOHAgz99v+f2OunHjhhgzZoyoVq2asLOzEz4+PuKVV14R586dE+Hh4Wy4EElKEYLTXRMREQFAZGQk2rRpg1atWiEyMtLS5RARWZV9+/ahffv2qFWrFuLi4oq9bD0RUWnHOVyIiIiIiKhE6fV6zJ49GwAwadIkNluIqEzgstBERERERFQiwsPD8euvvyI6Ohp//vkn6tati+HDh1u6LCKiZ4IjXIiIiIiIqEQcPHgQERERuHz5Mnr06IEdO3YYlzcnIrJ2nMOFiIiIiIiIiMjMOMKFiIiIiIiIiMjM2HAhIiIiIiIiIjIzNlyIiIiIiIiIiMyMM1aRtAwGA65evQpnZ2cuLUhEREREREQlTgiBu3fvwsfHBypV/mNY2HAhaV29ehV+fn6WLoOIiIiIiIjKmEuXLqFSpUr57sOGC0nL2dkZAJCQkAA3NzcLV0NUeDqdDidPnkRwcDCXyCRpMcckO2aYZMcMk+xky3BaWhr8/PyMn0fzU/qvhigP2bcRubi4wMXFxcLVEBWeTqdDuXLl4OLiIsUfF6LcMMckO2aYZMcMk+xkzXBBprVQhBDiGdRCZHZpaWnQarVISUmBVqu1dDlEhSaEQEZGBhwcHDgPEUmLOSbZMcMkO2aYZCdbhrM/h6ampj71f/zL0z4iykPvppNgo7a1dBlERaKxUUH30GDpMoiKhTkm2THDJDtmmGS37eTHli6hRHBZaJKexoYxJjlpbFQI69eAGSapMcckO2aYZMcMk+w0NipER0dDr9dbuhSz47uSiIiIiIiIiMjM2HAhIiIiIiIiIjIzNlyIiIiIiIiIiMyMqxSRtLJnhw4LGs5Jc0lanOSOrAFzTLJjhkl2zDDJbtvJj6FWq61ulSKOcCH5lf73JFHuFMDe0ZYZJrkxxyQ7ZphkxwyT7BQgKyvL0lWUCDZcSHoaDWNMctJoVGjRrTYzTFJjjkl2zDDJjhkm2Wk0Kpw6dYqrFBERERERERER0dOx4UJEREREREREZGZsuBARWZDuofUNnaSyhzkm2THDJDtmmGSnVqstXUKJ4CpFJC2uUkRERERERCS/nac/s3QJBcZViqhMkWDlMKJcKQrg4e3CDJPUmGOSHTNMsmOGSXaKAqSkpMAax4Kw4VJK+fv746OPPjL7vtZIzRnZSVJqjQoh7aozwyQ15phkxwyT7Jhhkp1ao0J8fDxXKSrrhg4dCkVRoCgKbGxs4Onpifbt22P16tUwGAxmPVdUVBRGjx5t9n2L4vHrzu3L39+/xM5NREREREREJCM2XAqpY8eOSEpKwsWLF7Fr1y60adMGb7zxBrp27QqdTme281SoUAGOjo5m37coli9fjqSkJOMXAISHhxu/j4qKMtk/KyurxGohIiIiIiIikgEbLoVkZ2cHLy8v+Pr6omHDhnjrrbewdetW7Nq1CxEREcb9UlJSMHLkSFSoUAEuLi5o27YtYmNjTY61fft2hIaGwt7eHh4eHujRo4dx2+O3CQkhMGfOHFSuXBl2dnbw8fHBhAkTct0XABITE9G9e3c4OTnBxcUFffv2xfXr143b58yZgwYNGuCbb76Bv78/tFot+vfvj7t37+Z6zVqtFl5eXsYvAHB1dTV+Hxoaivfeew+DBw+Gi4uLcbTN77//jhdeeAEODg7w8/PDhAkTcO/ePeNxMzMzMWXKFPj6+qJcuXJo3LgxIiMjC/XzePT6FPopRKWCEEB66gNmmKTGHJPsmGGSHTNMshMCcHBwgGKFExGx4WIGbdu2Rf369fHDDz8YH+vTpw+Sk5Oxa9cuHD9+HA0bNkS7du1w+/ZtAMBPP/2EHj16oHPnzjh58iT279+PRo0a5Xr8zZs348MPP8QXX3yBc+fOYcuWLahbt26u+xoMBnTv3h23b9/GwYMHsXfvXly4cAH9+vUz2e/8+fPYsmULduzYgR07duDgwYN4//33i/wafPDBB6hfvz5OnjyJWbNm4fz58+jYsSN69eqFU6dOYcOGDfj9998xbtw443PGjRuHI0eOYP369Th16hT69OmDjh074ty5c4U6t15n3tu5iJ4Vvc6A37f/zQyT1Jhjkh0zTLJjhkl2ep0B9evXt8qloTWWLsBaBAYG4tSpUwAejew4duwYkpOTYWdnB+BRQ2LLli34/vvvMXr0aCxYsAD9+/fH3LlzjceoX79+rsdOTEyEl5cXwsLCYGNjg8qVK+fZnNm/fz9Onz6NhIQE+Pn5AQDWrl2LOnXqICoqCqGhoQAeNWYiIiLg7OwMAHj11Vexf/9+LFiwoEjX37ZtW0yePNn4/ciRIzFo0CBMnDgRAFCjRg2sWLECrVq1wmeffYbk5GSEh4cjMTERPj4+AIApU6Zg9+7dCA8Px8KFC3OcIzMzE5mZmcbv09LSAACKyvo6oVQ2KCoFvgFuuHLhNoSB/1uK5MQck+yYYZIdM0yyU1QKkpOT4eHhAZXKusaEWNfVWJAQwjgEKjY2Funp6XB3d4eTk5PxKyEhAefPnwcAxMTEoF27dgU6dp8+fZCRkYGAgACMGjUKP/74Y57zxcTFxcHPz8/YbAGA2rVrw9XVFXFxccbH/P39jc0WAPD29kZycnKhrztbSEiIyfexsbGIiIgwuf4OHTrAYDAgISEBp0+fhl6vR82aNU32OXjwoPE1etKiRYug1WqNX9nXqFaz4UJyUqsVPNekCjNMUmOOSXbMMMmOGSbZqdUKLly4YPaFaEoDjnAxk7i4OFStWhUAkJ6eDm9v71znI3F1dQXw6B61gvLz88OZM2ewb98+7N27F2PGjMF///tfHDx4EDY2NkWq98nnKYpSrICXK1fO5Pv09HS89tprJnPNZKtcuTJOnToFtVqN48eP5xg65uTklOs5Zs6ciUmTJhm/T0tLM2ksEREREREREZUWbLiYwS+//ILTp0/jzTffBAA0bNgQ165dg0ajyXPJ5Hr16mH//v0YNmxYgc7h4OCAbt26oVu3bhg7diwCAwNx+vRpNGzY0GS/oKAgXLp0CZcuXTI2I/7++2+kpKSgdu3aRb/IQmrYsCH+/vtvVK9ePdftwcHB0Ov1SE5OxgsvvFCgY9rZ2Rlv0SIiIiIiIiIqzdhwKaTMzExcu3YNer0e169fx+7du7Fo0SJ07doVgwcPBgCEhYWhadOmePnll7FkyRLUrFkTV69eNU6UGxISgtmzZ6Ndu3aoVq0a+vfvD51Oh507d2L69Ok5zhkREQG9Xo/GjRvD0dER3377LRwcHFClSpUc+4aFhaFu3boYNGgQPvroI+h0OowZMwatWrXKcdtPSZo+fTqaNGmCcePGYeTIkShXrhz+/vtv7N27FytXrkTNmjUxaNAgDB48GEuXLkVwcDBu3LiB/fv3o169eujSpUuBzyUEwAGUJCMhgJtJaVxVgKTGHJPsmGGSHTNMshPi0cq4XKWIsHv3bnh7e8Pf3x8dO3bEgQMHsGLFCmzdutV4a4yiKNi5cydatmyJYcOGoWbNmujfvz/+/fdfeHp6AgBat26NTZs2Ydu2bWjQoAHatm2LY8eO5XpOV1dXrFq1Cs2bN0e9evWwb98+bN++He7u7jn2VRQFW7duRfny5dGyZUuEhYUhICAAGzZsKLkXJRf16tXDwYMHcfbsWbzwwgsIDg7Gu+++a5wgFwDCw8MxePBgTJ48GbVq1cLLL7+MqKgoVK5cuVDn4ozsJCu9zoDo/f8wwyQ15phkxwyT7Jhhkp1eZ0BQUJBVrlKkCMFeKMkpLS0NWq0WL9YZAbVStLlsiCxJpVIQ8JwXLvx5DQauKkCSYo5JdswwyY4ZJtmpVAo+/+kt+Pj4SLFKUfbn0NTUVLi4uOS7b+m/GqKnUHFGdpKUSq2gej1vZpikxhyT7Jhhkh0zTLJTqRVcvnzZKlcpYsOFiIiIiIiIiMjM2HAhIiIiIiIiIjIzNlxIerxXlWRlMAhc/ucWM0xSY45JdswwyY4ZJtkZDAIVKlSQYv6WwuKy0CQ9g17ACie0pjLAoBf4849/LV0GUbEwxyQ7ZphkxwyT7Ax6gWrVqlm6jBJhfS0kKnM4QRjJSqVW8FyTKswwSY05JtkxwyQ7Zphkp1IrOH/+PCfNJSqNVCr+cSE5qVQKKlV3Z4ZJaswxyY4ZJtkxwyQ7lUrBjRs32HAhIiIiIiIiIqKnY8OFiIiIiIiIiMjM2HAh6Rn0nJGd5GTQC/xzKokZJqkxxyQ7ZphkxwyT7Ax6gUqVKnGVIqLSyGDgKkUkJ4Ph0T+QiGTGHJPsmGGSHTNMsjMYHjVcrJH1tZCozFFrGGOSk1qjQki76swwSY05JtkxwyQ7Zphkp9aoEBcXB71eb+lSzE4RQnDsGUkpLS0NWq0Wt27dgpubm6XLISo0nU6H6OhohISEQKPhgEOSE3NMsmOGSXbMMMlOtgxnfw5NTU2Fi4tLvvuyDUpEREREREREZGZsuBARERERERERmRkbLiQ9a5zNmsoGlUqFgIAAZpikxhyT7Jhhkh0zTLKz5gxzDheSVmHunSMiIiIiIiIqLs7hQmWKNc5mTWWDXq9HbGwsM0xSY45JdswwyY4ZJtlZc4bZcCHpcZAWyUoIgYyMDGaYpMYck+yYYZIdM0yys+YMs+FCRERERERERGRmbLgQEREREREREZkZGy4kPbVabekSiIpErVYjMDCQGSapMcckO2aYZMcMk+ysOcMaSxdAVFx9ei2AjcbO0mUQERERERFREfy0+z1Ll1AiOMKFpKdWM8YkJ7VGhXbtA6DWMMMkL+aYZMcMk+yYYZKdWqNCVFQUdDqdpUsxO74riYgsSMN/HJEVYI5JdswwyY4ZJtlZ45LQABsuRERERERERERmx4YLEREREREREZGZseFC0tPrDZYugahI9DoDfv8tEXodM0zyYo5JdswwyY4ZJtnpdQbUq1fPKlcpYsOFiMiCHjywvsnBqOxhjkl2zDDJjhkm2dna2lq6hBLBhgtJj6sUkazUGhXCuKoASY45JtkxwyQ7Zphkp9aoEB0dbZUT5/JdSURERERERERkZmy4EBERERERERGZGRsuRERERERERERmpgghhKWLICqKtLQ0aLVatG83FTYaO0uXQ1Qkao2KqwqQ9Jhjkh0zTLJjhkl2W3fMhlqthqIoli7lqbI/h6ampsLFxSXffTnChYjIguztNZYugajYmGOSHTNMsmOGSXZZWVmWLqFEsOHyFEOHDsXLL79s/L5169aYOHGixeoprebMmYMGDRpY5NxcpYhkpdao0OKFylxVgKTGHJPsmGGSHTNMslNrVDh16hRXKbK0a9eu4Y033kD16tVhb28PT09PNG/eHJ999hnu37//TGr44Ycf8N5775n1mE82dfLbT1EU45e7uzs6duyIU6dOmbWep1EUBVu2bDF5bMqUKdi/f/8zrYOIiIiIiIiotJKm4XLhwgUEBwfj559/xsKFC3Hy5EkcOXIE06ZNw44dO7Bv3748n/vw4UOz1eHm5gZnZ2ezHa+wOnbsiKSkJCQlJWH//v3QaDTo2rWrxerJ5uTkBHd3d0uXQURERERERFQqSNNwGTNmDDQaDaKjo9G3b18EBQUhICAA3bt3x08//YRu3boZ91UUBZ999hleeukllCtXDgsWLIBer8eIESNQtWpVODg4oFatWli+fLnJOfR6PSZNmgRXV1e4u7tj2rRpeHJO4SdvKcrMzMSUKVPg6+uLcuXKoXHjxoiMjDRuj4iIgKurK/bs2YOgoCA4OTkZmybAo1tx1qxZg61btxpHrjz+/CfZ2dnBy8sLXl5eaNCgAWbMmIFLly7hxo0bxn1Onz6Ntm3bwsHBAe7u7hg9ejTS09ON2w0GA+bNm4dKlSrBzs4ODRo0wO7du43bs7KyMG7cOHh7e8Pe3h5VqlTBokWLAAD+/v4AgB49ekBRFOP3T95SlD1q54MPPoC3tzfc3d0xduxYk+ZXUlISunTpAgcHB1StWhXr1q2Dv78/Pvroozyvn8ja6DjBHVkB5phkxwyT7Jhhkp1arbZ0CSVCiobLrVu38PPPP2Ps2LEoV65crvs8OZvxnDlz0KNHD5w+fRrDhw+HwWBApUqVsGnTJvz9999499138dZbb2Hjxo3G5yxduhQRERFYvXo1fv/9d9y+fRs//vhjvrWNGzcOR44cwfr163Hq1Cn06dMHHTt2xLlz54z73L9/Hx988AG++eYb/Prrr0hMTMSUKVMAPLoVp2/fviYjV5o1a1ag1yU9PR3ffvstqlevbhxdcu/ePXTo0AHly5dHVFQUNm3ahH379mHcuHHG5y1fvhxLly7FBx98gFOnTqFDhw546aWXjDWvWLEC27Ztw8aNG3HmzBl89913xsZKVFQUACA8PBxJSUnG73Nz4MABnD9/HgcOHMCaNWsQERGBiIgI4/bBgwfj6tWriIyMxObNm/Hll18iOTk5z+NlZmYiLS3N5AsA9Hr+gSE56XUG7N97gasKkNSYY5IdM0yyY4ZJdnqdAaGhodBorG/yZymu6J9//oEQArVq1TJ53MPDAw8ePAAAjB07FosXLzZuGzhwIIYNG2ay/9y5c43/XbVqVRw5cgQbN25E3759AQAfffQRZs6ciZ49ewIAPv/8c+zZsyfPuhITExEeHo7ExET4+PgAeNRA2b17N8LDw7Fw4UIAj25p+vzzz1GtWjUAj5o08+bNA/DoVhwHBwdkZmbCy8vrqa/Fjh074OTkBOBRc8Xb2xs7duyASvWod7Zu3To8ePAAa9euNTanVq5ciW7dumHx4sXw9PTEBx98gOnTp6N///4AgMWLF+PAgQP46KOP8MknnyAxMRE1atRAixYtoCgKqlSpYjx/hQoVAACurq5Prbd8+fJYuXIl1Go1AgMD0aVLF+zfvx+jRo1CfHw89u3bh6ioKISEhAAAvvrqK9SoUSPP4y1atMjkZ5hNgpXDiHKlKICbuyNu37qPJwbTEUmDOSbZMcMkO2aYZKcoQEpKCrRarRTLQheGFCNc8nLs2DHExMSgTp06yMzMNNmW/SH+cZ988gmef/55VKhQAU5OTvjyyy+RmJgIAEhNTUVSUhIaN25s3F+j0eR6nGynT5+GXq9HzZo14eTkZPw6ePAgzp8/b9zP0dHR2GwBAG9v73xHcuSnTZs2iImJQUxMDI4dO4YOHTqgU6dO+PfffwEAcXFxqF+/vslIoObNm8NgMODMmTNIS0vD1atX0bx5c5PjNm/eHHFxcQAe3Q4UExODWrVqYcKECfj555+LVGudOnVMhoY9ft1nzpyBRqNBw4YNjdurV6+O8uXL53m8mTNnIjU11fh16dIlADA2m4hko1KrEBLqAxVX2iKJMcckO2aYZMcMk+xUahXi4+OtcpUiKUa4VK9eHYqi4MyZMyaPBwQEAAAcHBxyPOfJW4/Wr1+PKVOmYOnSpWjatCmcnZ3x3//+F0ePHi1yXenp6VCr1Th+/HiOe86yR6EAgI2Njck2RVFyzA1TUOXKlUP16tWN33/11VfQarVYtWoV5s+fX6RjPqlhw4ZISEjArl27sG/fPvTt2xdhYWH4/vvvC3Wc3K7bYCj6UEc7OzvY2dkV+flEREREREREz4oUbVB3d3e0b98eK1euxL1794p0jEOHDqFZs2YYM2YMgoODUb16dZNRKFqtFt7e3iYNGJ1Oh+PHj+d5zODgYOj1eiQnJ6N69eomXwW5PSibra1tkbt5iqJApVIhIyMDABAUFITY2FiT1+nQoUNQqVSoVasWXFxc4OPjg0OHDpkc59ChQ6hdu7bxexcXF/Tr1w+rVq3Chg0bsHnzZty+fRvAo0ZKcbuPtWrVgk6nw8mTJ42P/fPPP7hz506xjktERERERERUGkjRcAGATz/9FDqdDiEhIdiwYQPi4uJw5swZfPvtt4iPj3/qrMY1atRAdHQ09uzZg7Nnz2LWrFk5Jnx944038P7772PLli2Ij4/HmDFjkJKSkucxa9asiUGDBmHw4MH44YcfkJCQgGPHjmHRokX46aefCnxt/v7+OHXqFM6cOYObN2/mu4x1ZmYmrl27hmvXriEuLg7jx49Henq6cZWmQYMGwd7eHkOGDMGff/6JAwcOYPz48Xj11Vfh6ekJAJg6dSoWL16MDRs24MyZM5gxYwZiYmLwxhtvAACWLVuG//3vf4iPj8fZs2exadMmeHl5wdXV1Vjv/v37ce3atSI3SAIDAxEWFobRo0fj2LFjOHnyJEaPHg0HB4fC37fHm1VJVkIgPT2LGSa5McckO2aYZMcMk+yEKNrnQAlIcUsRAFSrVg0nT57EwoULMXPmTFy+fBl2dnaoXbs2pkyZgjFjxuT7/Ndeew0nT55Ev379oCgKBgwYgDFjxmDXrl3GfSZPnoykpCQMGTIEKpUKw4cPR48ePZCamprnccPDwzF//nxMnjwZV65cgYeHB5o0aYKuXbsW+NpGjRqFyMhIhISEID09HQcOHEDr1q1z3Xf37t3w9vYGADg7OyMwMBCbNm0y7u/o6Ig9e/bgjTfeQGhoKBwdHdGrVy8sW7bMeIwJEyYgNTUVkydPRnJyMmrXro1t27YZJ6x1dnbGkiVLcO7cOajVaoSGhmLnzp3GuVKWLl2KSZMmYdWqVfD19cXFixcLfK2PW7t2LUaMGIGWLVvCy8sLixYtwl9//QV7e/tCHUdvEOA0LiQjvV7g0G+Jli6DqFiYY5IdM0yyY4ZJdnq9QP369S1dRolQRFEnEyEys8uXL8PPzw/79u1Du3btnrp/WloatFotXgybCo2ac7uQfBQF8PF1wdUrafyfUiQt5phkxwyT7Jhhkp2iAKvXjIeHh4cUC6Jkfw5NTU2Fi4tLvvuW/qshq/XLL79g27ZtSEhIwOHDh9G/f3/4+/ujZcuWhTqODG9Kotyo1Co8V7ciVxUgqTHHJDtmmGTHDJPsVGoVLly4UKwFVkoraW4pIuvz8OFDvPXWW7hw4QKcnZ3RrFkzfPfddzlWNyIiIiIiIiKSDRsuZDEdOnRAhw4dLF0GERERERERkdlx3BnJjzerkqyEwM2b95lhkhtzTLJjhkl2zDDJTghotVquUkRUGnGVIpKVXi9wPOqqpcsgKhbmmGTHDJPsmGGSnV4vEBQUZOkySgQ/ppL0rLETSmWDolJQrYYbFBUzTPJijkl2zDDJjhkm2SkqBZcvX7bKSXPZcCHpqfjHhSSlUimoXt2NGSapMcckO2aYZMcMk+xUbLgQEREREREREVFBseFCRERERERERGRmbLiQ9ISBM7KTnIRB4PLlNGaYpMYck+yYYZIdM0yyEwaBChUqQGWFK6FwlSKSnkEIqC1dBFERGAwCf51OtnQZRMXCHJPsmGGSHTNMsjMYBKpVq2bpMkqE9bWQqMxRcZUikpRKpaBO3Yqc5I6kxhyT7Jhhkh0zTLJTqRScP3/eKifNVYQQHHtGUkpLS4NWq8WtW7fg5uZm6XKICk2n0yE6OhohISHQaDjgkOTEHJPsmGGSHTNMspMtw9mfQ1NTU+Hi4pLvvhzhQkRERERERERkZmy4EBERERERERGZGRsuJD1rnM2aygaVSoVKlSoxwyQ15phkxwyT7Jhhkp01Z5hzuJC0CnPvHBEREREREVFxcQ4XKlP0er2lSyAqEr1ej7i4OGaYpMYck+yYYZIdM0yys+YMs+FC0uMgLZKVEAKpqanMMEmNOSbZMcMkO2aYZGfNGWbDhYiIiIiIiIjIzNhwISIiIiIiIiIyM06aS9LKnqyodd+3oNbYW7ocokJTFKBSRSdcTk4HfxOTrJhjkh0zTLJjhkl2P3/zNm7evAkPDw8pVioqzKS5mmdUE1GJ4R8WkpUQwKXr6ZYug6hYmGOSHTNMsmOGSXYqlQoVK1a0dBklovS3j4ieQq0oli6BqEjUKgWtGvpArWKGSV7MMcmOGSbZMcMkO71ej9jYWK5SRFQasd9CslIUwNnRlhkmqTHHJDtmmGTHDJPshBDIyMjgKkVERERERERERPR0bLgQEREREREREZkZGy4kPb0VDj2jskFvEDj653XoDcwwyYs5JtkxwyQ7Zphkp1arERgYCLVabelSzI6rFJH02G8hWQkB3EjJsHQZRMXCHJPsmGGSHTNMslMUBa6urpYuo0RwhAtJT8MZ2UlSGrWCjk0rQ6NmhklezDHJjhkm2THDJDudToeoqCjodDpLl2J2bLgQEVmQRs1fwyQ/5phkxwyT7Jhhkp01LgkNsOFCRERERERERGR2bLgQEREREREREZkZGy4kPR1nZCdJ6fQCkSeuQKdnhklezDHJjhkm2THDJDu1Wo169epZ5SpFbLhIRlEUbNmypcD7R0ZGQlEUpKSklFhNRFR0DzKtb3IwKnuYY5IdM0yyY4ZJdra2tpYuoUSw4VIKDR06FC+//HKu25KSktCpUyeznm/OnDlo0KBBrttOnjyJfv36wdvbG3Z2dqhSpQq6du2K7du3Q/z/9ZgvXrwIRVGMX7a2tqhevTrmz59v3Cf7PIqioGPHjjnO89///heKoqB169aFrp+rFJGsHq0qUIWrCpDUmGOSHTNMsmOGSXZ6vR7R0dFWOXEuGy6S8fLygp2d3TM519atW9GkSROkp6djzZo1iIuLw+7du9GjRw+88847SE1NNdl/3759SEpKwrlz5zB37lwsWLAAq1evNtnH29sbBw4cwOXLl00eX716NSpXrlzi10RERERERET0LLDhIpknbyk6fPgwGjRoAHt7e4SEhGDLli1QFAUxMTEmzzt+/DhCQkLg6OiIZs2a4cyZMwCAiIgIzJ07F7GxscYRKhEREbh37x5GjBiBLl264KeffsKLL76IgIAABAUFYcSIEYiNjYVWqzU5h7u7O7y8vFClShUMGjQIzZs3x4kTJ0z2qVixIl588UWsWbPG5Bpu3ryJLl26mPfFIiIiIiIiIrIQNlwklpaWhm7duqFu3bo4ceIE3nvvPUyfPj3Xfd9++20sXboU0dHR0Gg0GD58OACgX79+mDx5MurUqYOkpCQkJSWhX79++Pnnn3Hr1i1MmzYtz/MrSt7DFqOjo3H8+HE0btw4x7bhw4cjIiLC+P3q1asxaNCgp963l5mZibS0NJMvIiIiIiIiotKIDReJrVu3DoqiYNWqVahduzY6deqEqVOn5rrvggUL0KpVK9SuXRszZszA4cOH8eDBAzg4OMDJyQkajQZeXl7w8vKCg4MDzp49CwCoVauW8RhRUVFwcnIyfu3YscPkHM2aNYOTkxNsbW0RGhqKvn37YvDgwTlq6dq1K9LS0vDrr7/i3r172Lhxo7EBlJ9FixZBq9Uav/z8/ABwlSKSl04vsPvIv1xVgKTGHJPsmGGSHTNMslOr1QgJCeEqRVS6nDlzBvXq1YO9vb3xsUaNGuW6b7169Yz/7e3tDQBITk4u1Pnq1auHmJgYxMTE4N69e9DpTGdD37BhA2JiYhAbG4uNGzdi69atmDFjRo7j2NjY4JVXXkF4eDg2bdqEmjVrmtSXl5kzZyI1NdX4denSpULVT1Qa2dtpLF0CUbExxyQ7ZphkxwyT7LKysixdQolgw6WMsLGxMf539q1ABoMhz/1r1KgBAMa5XgDAzs4O1atXR/Xq1XN9jp+fH6pXr46goCD06dMHEydOxNKlS/HgwYMc+w4fPhybNm3CJ598UqDRLdnnd3FxMfkCuEoRyUujVtC6oS9XFSCpMcckO2aYZMcMk+z0ej1OnTrFVYqodKlVqxZOnz6NzMxM42NRUVGFPo6trW2OcL/44otwc3PD4sWLi1yfWq2GTqfLtVtZp04d1KlTB3/++ScGDhxY5HMQERERERERlUYce1ZKpaam5lhpyN3d3eT7gQMH4u2338bo0aMxY8YMJCYm4oMPPgCQ/4S2T/L390dCQgJiYmJQqVIlODs7w8nJCV999RX69euHLl26YMKECahRowbS09Oxe/duAMhxj92tW7dw7do16HQ6nD59GsuXL0ebNm2MI1Ge9Msvv+Dhw4dwdXUtcK1EREREREREMmDDpZSKjIxEcHCwyWMjRoww+d7FxQXbt2/H66+/jgYNGqBu3bp49913MXDgQJN5XZ6mV69e+OGHH9CmTRukpKQgPDwcQ4cORY8ePXD48GEsXrwYgwcPxu3bt6HVahESEoL169eja9euJscJCwsD8KgR4+3tjc6dO2PBggV5nrdcuXIFrpHIWun0ed/aRyQL5phkxwyT7Jhhkp01TpgLAIoQgtNZW5HvvvsOw4YNQ2pqKhwcHCxdTolKS0uDVqtFqz5vQWNT8AYTERERERERlQ77vptl6RIKJftzaGpqap53c2TjHC6SW7t2LX7//XckJCRgy5YtmD59Ovr27Wv1zZbHFeLuKaJSRVGACq4OzDBJjTkm2THDJDtmmGQnhEBKSgqscSwIGy6Su3btGl555RUEBQXhzTffRJ8+ffDll19auqxnSs2/LiQptUpB4+c8oeZKWyQx5phkxwyT7Jhhkp1er0d8fLxVrlLEOVwkN23aNEybNs3SZRARERERERHRYzjChYiIiIiIiIjIzNhwIelZ4a1+VEYIAdy9n8UMk9SYY5IdM0yyY4ZJdoqiwMHBAYoVThXBW4pIenohGGSSkt4gcPDEVUuXQVQszDHJjhkm2THDJDu1Wo369etbuowSwREuJD0rbIRSGaEogJ+nEzNMUmOOSXbMMMmOGSbZGQwGJCcnw2AwWLoUs2PDhaTHVYpIVmqVgvo1PLiqAEmNOSbZMcMkO2aYZGcwGHDhwgU2XIiIiIiIiIiI6OnYcCEiIiIiIiIiMjM2XEh6nJGdZCUEcONOBjNMUmOOSXbMMMmOGSbZKYoCrVbLVYqISiOuUkSy0hsEjv513dJlEBULc0yyY4ZJdswwyU6tViMoKMjSZZQIfk4l6W35cipcXV0tXQZRoRkMBly9ehU+Pj5QqTjgkOTEHJPsmGGSHTNMsrPmDFvX1VCZZI2zWVPZYDAYcPnyZWaYpMYck+yYYZIdM0yys+YMs+FCRERERERERGRmbLgQEREREREREZkZGy4kPWu7z4/KDpVKhQoVKjDDJDXmmGTHDJPsmGGSnTVnWBGCC4iRnNLS0qDVapGamgoXFxdLl0NERERERERWrjCfQ62vhURljjVOrkRlg8FgwPnz55lhkhpzTLJjhkl2zDDJzpozzIYLSc8a35hUNhgMBty4cYMZJqkxxyQ7ZphkxwyT7Kw5w2y4EBERERERERGZmcbSBRAVV9e3lgEaO0uXQVRoGpWC7vWqYNq6fdAZOJ0WyYk5JtkxwyQ7ZphkcnjlLEuX8ExxhAtJz8B5n0lSBiHw97UUZpikxhyT7Jhhkh0zTLJTqVSoVKmSVa5SxBEuJD2DYOeQ5GQQQNy1FEuXQVQszDHJjhkm2THDJLvshos14udUkp5apVi6BKIiUasUtKjmyQyT1Jhjkh0zTLJjhkl2er0ecXFx0Ov1li7F7NhwIenxTwvJSgHg6ezADJPUmGOSHTNMsmOGSXZCCKSmpkJY4W1xbLgQEREREREREZkZGy5ERERERERERGbGhgtJT2+FQ8+obNALgeOJN5lhkhpzTLJjhkl2zDDJTqVSISAggKsUEZVG/NtCshICuHg73dJlEBULc0yyY4ZJdswwyU6lUqFixYqWLqNEWF8LicoczshOslKrFLQP9GGGSWrMMcmOGSbZMcMkO71ej9jYWK5SRFQa8U8LyUoB4GJvywyT1Jhjkh0zTLJjhkl2QghkZGRwlSIiIiIiIiIiIno6NlyIiIiIiIiIiMyszDVc/P398dFHHxX5+REREXB1dTVbPdakuK9tUekN1jf0jMoGvUHg9/PXmWGSGnNMsmOGSXbMMMlOrVYjMDAQarXa0qWYXalquAwdOhQvv/xyiZ4jKioKo0ePLtC+uTUQ+vXrh7Nnzxb5/BEREVAUBYqiQKVSwdvbG/369UNiYmKRj1laFOa1NSf+aSFZCQDX72YwwyQ15phkxwyT7Jhhkp2iKHB1dYWiWN9MRKWq4fIsVKhQAY6OjkV+voODQ7GXrHJxcUFSUhKuXLmCzZs348yZM+jTp0+xjlkQDx8+LNHjF/e1LSoNZ2QnSWlUCrrXrcwMk9SYY5IdM0yyY4ZJdjqdDlFRUdDpdJYuxeykargcPHgQjRo1gp2dHby9vTFjxgyTH8rdu3cxaNAglCtXDt7e3vjwww/RunVrTJw40bjP46NWhBCYM2cOKleuDDs7O/j4+GDChAkAgNatW+Pff//Fm2++aRyRAuR+S9H27dsRGhoKe3t7eHh4oEePHvleh6Io8PLygre3N5o1a4YRI0bg2LFjSEtLM+6zdetWNGzYEPb29ggICMDcuXNNrjU+Ph4tWrSAvb09ateujX379kFRFGzZsgUAcPHiRSiKgg0bNqBVq1awt7fHd999BwD46quvEBQUBHt7ewQGBuLTTz81HjcrKwvjxo2Dt7c37O3tUaVKFSxatOipr9eTry0AJCYmonv37nBycoKLiwv69u2L69evG7fPmTMHDRo0wDfffAN/f39otVr0798fd+/ezff1I7ImGrVUv4aJcsUck+yYYZIdM0yys8YloQFAY+kCCurKlSvo3Lkzhg4dirVr1yI+Ph6jRo2Cvb095syZAwCYNGkSDh06hG3btsHT0xPvvvsuTpw4gQYNGuR6zM2bN+PDDz/E+vXrUadOHVy7dg2xsbEAgB9++AH169fH6NGjMWrUqDzr+umnn9CjRw+8/fbbWLt2LbKysrBz584CX1dycjJ+/PFHqNVq4z1rv/32GwYPHowVK1bghRdewPnz54236syePRt6vR4vv/wyKleujKNHj+Lu3buYPHlyrsefMWMGli5diuDgYGPT5d1338XKlSsRHByMkydPYtSoUShXrhyGDBmCFStWYNu2bdi4cSMqV66MS5cu4dKlS099vZ5kMBiMzZaDBw9Cp9Nh7Nix6NevHyIjI437nT9/Hlu2bMGOHTtw584d9O3bF++//z4WLFiQ45iZmZnIzMw0fv94g4qIiIiIiIioNJGm4fLpp5/Cz88PK1euhKIoCAwMxNWrVzF9+nS8++67uHfvHtasWYN169ahXbt2AIDw8HD4+PjkeczExER4eXkhLCwMNjY2qFy5Mho1agQAcHNzg1qthrOzM7y8vPI8xoIFC9C/f3/MnTvX+Fj9+vXzvZbU1FQ4OTlBCIH79+8DACZMmIBy5coBAObOnYsZM2ZgyJAhAICAgAC89957mDZtGmbPno29e/fi/PnziIyMNNa2YMECtG/fPse5Jk6ciJ49exq/nz17NpYuXWp8rGrVqvj777/xxRdfYMiQIUhMTESNGjXQokULKIqCKlWqFOj1etL+/ftx+vRpJCQkwM/PDwCwdu1a1KlTB1FRUQgNDQXwqDETEREBZ2dnAMCrr76K/fv359pwWbRokcnrTERERERERFRaSTP2LC4uDk2bNjWZSKd58+ZIT0/H5cuXceHCBTx8+NCkAaDValGrVq08j9mnTx9kZGQgICAAo0aNwo8//ljo+8ZiYmKMDZ6CcnZ2RkxMDKKjo7F06VI0bNjQpMEQGxuLefPmwcnJyfg1atQoJCUl4f79+zhz5gz8/PxMGkF5NT5CQkKM/33v3j2cP38eI0aMMDn2/Pnzcf78eQCPJi6OiYlBrVq1MGHCBPz888/G5xfm9YqLi4Ofn5+x2QIAtWvXhqurK+Li4oyP+fv7G5stAODt7Y3k5ORcjzlz5kykpqYav7JH3ug4IztJSmcQ+Dn+CjNMUmOOSXbMMMmOGSbZqdVq1KtXzypXKZJmhEtJ8PPzw5kzZ7Bv3z7s3bsXY8aMwX//+18cPHgQNjY2BTqGg4NDoc+rUqlQvXp1AEBQUBDOnz+P119/Hd988w0AID09HXPnzjUZmZLN3t6+UOfKHjWTfVwAWLVqFRo3bmyyX3a4GzZsiISEBOzatQv79u1D3759ERYWhu+//94sr9eTnnyeoigwGAy57mtnZwc7O7sinYeotMrIsr7JwajsYY5JdswwyY4ZJtnZ2tpauoQSIc0Il6CgIBw5cgRC/F/n9tChQ3B2dkalSpUQEBAAGxsbREVFGbenpqY+dQlnBwcHdOvWDStWrEBkZCSOHDmC06dPA3j0Q3/a5D316tXD/v37i3Flj+ZZ2bBhA06cOAHgUdPjzJkzqF69eo4vlUqFWrVq4dKlSyYT0D5+3Xnx9PSEj48PLly4kOO4VatWNe7n4uKCfv36YdWqVdiwYQM2b96M27dvA8j/9XpcUFCQyfwvAPD3338jJSUFtWvXLvJrlRvOyE6y0qgUdK9XhRkmqTHHJDtmmGTHDJPs9Ho9oqOjrXLi3FI3wiU1NRUxMTEmj7m7u2PMmDH46KOPMH78eIwbNw5nzpzB7NmzMWnSJKhUKjg7O2PIkCGYOnUq3NzcULFiRcyePRsqlSrP9bwjIiKg1+vRuHFjODo64ttvv4WDg4Nx3hJ/f3/8+uuv6N+/P+zs7ODh4ZHjGLNnz0a7du1QrVo19O/fHzqdDjt37sT06dMLfM1+fn7o0aMH3n33XezYsQPvvvsuunbtisqVK6N3795QqVSIjY3Fn3/+ifnz56N9+/aoVq0ahgwZgiVLluDu3bt45513AOCpa5fPnTsXEyZMgFarRceOHZGZmYno6GjcuXMHkyZNwrJly+Dt7Y3g4GCoVCps2rQJXl5ecHV1ferr9biwsDDUrVsXgwYNwkcffQSdTocxY8agVatWJrc5EREREREREVmjUjfCJTIyEsHBwSZfc+fOha+vL3bu3Iljx46hfv36+M9//oMRI0YYGw0AsGzZMjRt2hRdu3ZFWFgYmjdvblz+ODeurq5YtWoVmjdvjnr16mHfvn3Yvn073N3dAQDz5s3DxYsXUa1aNVSoUCHXY7Ru3RqbNm3Ctm3b0KBBA7Rt2xbHjh0r9HW/+eab+Omnn3Ds2DF06NABO3bswM8//4zQ0FA0adIEH374obGxoVarsWXLFqSnpyM0NBQjR47E22+/DeDptxyNHDkSX331FcLDw1G3bl20atUKERERxhEuzs7OWLJkCUJCQhAaGoqLFy9i586dUKlUT329HqcoCrZu3Yry5cujZcuWCAsLQ0BAADZs2FDo14aIiIiIiIhINop4/B4dK3Pv3j34+vpi6dKlGDFihKXLKVGHDh1CixYt8M8//6BatWqWLueZSEtLg1arRdPX3gY0nNuF5JM9BHjrqX850R1Jizkm2THDJDtmmGRyeOWsHI/pdDpER0cjJCQEGk2puwknh+zPoampqXBxccl339J/NYVw8uRJxMfHo1GjRkhNTcW8efMAAN27d7dwZeb3448/wsnJCTVq1MA///yDN954A82bNy8zzZbH6QzCuoJMZYbOIPiPI5Iec0yyY4ZJdswwyU6tViMkJISrFMnggw8+wJkzZ2Bra4vnn38ev/32W65zr8ju7t27mD59OhITE+Hh4YGwsDAsXbrU0mURUSE52Gpw98FDS5dBVCzMMcmOGSbZMcMku6ysrCKtAFzalbo5XIojODgYx48fR3p6Om7fvo29e/eibt26li6rRAwePBhnz57FgwcPcPnyZUREROQ6l0pZwBnZSVYalYIXA32ZYZIac0yyY4ZJdswwyU6v1+PUqVNWuUqRVTVciIiIiIiIiIhKAzZciIiIiIiIiIjMjA0XIiIL0ukNli6BqNiYY5IdM0yyY4ZJdtY4YS5ghZPmUtnDVYpIVjqDwNbTiZYug6hYmGOSHTNMsmOGSXYajQahoaGWLqNEcIQLSY/Tg5GsFACezg7MMEmNOSbZMcMkO2aYZCeEQEpKCoSwvqXN2XAh6ak5IztJSq1S0KKaJzNMUmOOSXbMMMmOGSbZ6fV6xMfHc5UiIiIiIiIiIiJ6OjZciIiIiIiIiIjMjA0Xkp713elHZYUAkPYgixkmqTHHJDtmmGTHDJPsFEWBg4MDFMX6botThDXOTENlQlpaGrRaLVJTU+Hi4mLpcoiIiIiIiMjKFeZzKEe4kPQMBoOlSyAqEoPBgOTkZGaYpMYck+yYYZIdM0yys+YMs+FC0rPGNyaVDQaDARcuXGCGSWrMMcmOGSbZMcMkO2vOMBsuRERERERERERmxoYLEREREREREZGZseFC0rPG2aypbFAUBVqtlhkmqTHHJDtmmGTHDJPsrDnDXKWIpMVVioiIiIiIiOhZ4ipFVKZY4+RKVDYYDAZcvnyZGSapMcckO2aYZMcMk+ysOcNsuJD0rPGNSWWDNf9xobKDOSbZMcMkO2aYZGfNGdZYugCi4nrx/aUQNnaWLoOo0DQqBb2rVcEbP+2FzsC7O0lOzDHJjhkm2THDJJPjC961dAnPFEe4EBERERERERGZGRsuJD028klWBgFcSEtnhklqzDHJjhkm2THDJDuVSoUKFSpApbK+9gRvKSLpGYSA2tJFEBWBQQgcu37T0mUQFQtzTLJjhkl2zDDJTqVSoVq1apYuo0RYXwuJyhyVFa7XTmWDSlHQyNODGSapMcckO2aYZMcMk+wMBgPOnz9vlZPmsuFC0lPxbwtJSqUAAS5OzDBJjTkm2THDJDtmmGRnMBhw48YNNlyIiIiIiIiIiOjp2HAhIiIiIiIiIjIzNlxIegbBKdlJTgYh8OftFGaYpMYck+yYYZIdM0yyU6lUqFSpElcpIiqNDAJcpYikZBDAn7dSLF0GUbEwxyQ7ZphkxwyT7LIbLtbI+lpIVOaoOSM7SUqtKGjt68kMk9SYY5IdM0yyY4ZJdnq9HnFxcdDr9ZYuxeyK1XCJiYnB//73P5PH9uzZg5YtW6Jx48ZYvnx5sYojKgj+bSFZKQrg5ejADJPUmGOSHTNMsmOGSXZCCKSmpkJY4W1xxWq4TJs2DRs2bDB+n5CQgB49eiAhIQEAMGnSJHz55ZfFq5CIiIiIiIiISDLFarjExsaiRYsWxu/Xrl0LtVqNkydP4ujRo+jduzc+//zzYhdprRRFwZYtWyxdBhERERERERGZWbEaLqmpqXB3dzd+v3PnTrRv3x4eHh4AgPbt2+Off/4pXoUlaOjQoVAUBYqiwMbGBlWrVsW0adPw4MEDS5dWoh6/7se/LPmzGjp0KF5++eUiPVdvsL6hZ1Q26A0Cx67fZIZJaswxyY4ZJtkxwyQ7lUqFgIAArlL0JG9vb8TFxQEAkpKScPz4cQwbNsy4PT09vdS/aB07dkR4eDgePnyI48ePY8iQIVAUBYsXL7Z0aSUq+7ofV6FChSIdKysrC7a2tuYoq0j4p4VkJQBcSEu3dBlExcIck+yYYZIdM0yyU6lUqFixoqXLKBHF6oZ0794dH3/8MSZMmICXX34ZdnZ26NGjh3F7bGwsAgICil1kSbKzs4OXlxf8/Pzw8ssvIywsDHv37jVuv3XrFgYMGABfX184Ojqibt26OSYKbt26NSZMmIBp06bBzc0NXl5emDNnjsk+586dQ8uWLWFvb4/atWubnCPb6dOn0bZtWzg4OMDd3R2jR49Gevr//fLMHgWycOFCeHp6wtXVFfPmzYNOp8PUqVPh5uaGSpUq5Wik5Hfdj3+p1Y8WVz548CAaNWoEOzs7eHt7Y8aMGdDpdCbXO27cOEycOBEeHh7o0KEDAODPP/9Ep06d4OTkBE9PT7z66qu4efOm8Xnff/896tata7y+sLAw3Lt3D3PmzMGaNWuwdetW42ibyMjIp15DNs7ITrJSKwo6VfFlhklqzDHJjhkm2THDJDu9Xo/Y2FiuUvSk+fPno2fPnvjmm2+QnJyMiIgIeHp6AgDS0tLw/fff48UXXzRLoc/Cn3/+icOHD5uM1njw4AGef/55/PTTT/jzzz8xevRovPrqqzh27JjJc9esWYNy5crh6NGjWLJkCebNm2dsqhgMBvTs2RO2trY4evQoPv/8c0yfPt3k+ffu3UOHDh1Qvnx5REVFYdOmTdi3bx/GjRtnst8vv/yCq1ev4tdff8WyZcswe/ZsdO3aFeXLl8fRo0fxn//8B6+99houX75cpNfgypUr6Ny5M0JDQxEbG4vPPvsMX3/9NebPn5/jem1tbXHo0CF8/vnnSElJQdu2bREcHIzo6Gjs3r0b169fR9++fQE8GgE1YMAADB8+HHFxcYiMjETPnj0hhMCUKVPQt29fdOzYEUlJSUhKSkKzZs0KXDP/tpCsFAXQ2towwyQ15phkxwyT7Jhhkp0QAhkZGVa5SlGxbilycnLCd999l+e2y5cvw9HRsTinKHE7duyAk5MTdDodMjMzoVKpsHLlSuN2X19fTJkyxfj9+PHjsWfPHmzcuBGNGjUyPl6vXj3Mnj0bAFCjRg2sXLkS+/fvR/v27bFv3z7Ex8djz5498PHxAQAsXLgQnTp1Mj5/3bp1ePDgAdauXYty5coBAFauXIlu3bph8eLFxkaWm5sbVqxYAZVKhVq1amHJkiW4f/8+3nrrLQDAzJkz8f777+P3339H//79n3rd2Tp16oRNmzbh008/hZ+fH1auXAlFURAYGIirV69i+vTpePfdd423iNWoUQNLliwxPn/+/PkIDg7GwoULjY+tXr0afn5+OHv2LNLT06HT6dCzZ09UqVIFAFC3bl3jvg4ODsjMzISXl1eeNWdmZiIzM9P4fVpaWp77EhEREREREVlSsRouT8rIyADw6MOzSqWCVqs15+FLRJs2bfDZZ5/h3r17+PDDD6HRaNCrVy/jdr1ej4ULF2Ljxo24cuUKsrKykJmZmaORVK9ePZPvvb29kZycDACIi4uDn5+fsdkCAE2bNjXZPy4uDvXr1zc2WwCgefPmMBgMOHPmjLHhUqdOHZN5cTw9PfHcc88Zv1er1XB3dzee+2nXnS37vHFxcWjatCmUx1rkzZs3R3p6Oi5fvozKlSsDAJ5//nmT48XGxuLAgQMmTZxs58+fx4svvoh27dqhbt266NChA1588UX07t0b5cuXz7fOxy1atAhz584t8P5EREREREREllLsGW0TExMxbNgweHp6wsnJyTh/x/Dhw/Hvv/+ao8YSVa5cOVSvXh3169fH6tWrcfToUXz99dfG7f/973+xfPlyTJ8+HQcOHEBMTAw6dOiArKwsk+PY2NiYfK8oCgwGg9nrze08RTl39nVnf3l7exeqjscbQ8CjCZK7deuGmJgYk6/suWvUajX27t2LXbt2oXbt2vj4449Rq1YtJCQkFPicM2fORGpqqvHr0qVLALhKEclLbxCIvHKdGSapMcckO2aYZMcMk+zUajUCAwONc4pak2KNcImPj0eLFi2QkpKC9u3bIygoyPj42rVrsX37dvz++++oVauWWYotaSqVCm+99RYmTZqEgQMHwsHBAYcOHUL37t3xyiuvAHg0H8vZs2dRu3btAh83KCgIly5dQlJSkrGx8ccff+TYJyIiAvfu3TM2Mw4dOmS8dehZCQoKwubNmyGEMI5yOXToEJydnVGpUqU8n9ewYUNs3rwZ/v7+0Ghyj5WiKGjevDmaN2+Od999F1WqVMGPP/6ISZMmwdbW9qmTJNnZ2cHOzi7H4/zTQrISAK7dz7B0GUTFwhyT7Jhhkh0zTLJTFAWurq6WLqNEFGuEy4wZM6BSqXDy5Ens2rULy5Ytw7Jly7Bz507ExMRApVJhxowZ5qr1mejTpw/UajU++eQTAI/mKtm7dy8OHz6MuLg4vPbaa7h+/XqhjhkWFoaaNWtiyJAhiI2NxW+//Ya3337bZJ9BgwbB3t4eQ4YMwZ9//okDBw5g/PjxePXVV423Ez0LY8aMwaVLlzB+/HjEx8dj69atmD17NiZNmpTvEt9jx47F7du3MWDAAERFReH8+fPYs2cPhg0bBr1ej6NHj2LhwoWIjo5GYmIifvjhB9y4ccPYpPP398epU6dw5swZ3Lx5Ew8fPixwzRoVZwgjOWlUCnpVq8IMk9SYY5IdM0yyY4ZJdjqdDlFRUSYr41qLYjVcDh48iAkTJphMfprtueeew7hx4wq1vG9poNFoMG7cOCxZsgT37t3DO++8g4YNG6JDhw5o3bo1vLy88PLLLxfqmCqVCj/++CMyMjLQqFEjjBw5EgsWLDDZx9HREXv27MHt27cRGhqK3r17o127diYT+D4Lvr6+2LlzJ44dO4b69evjP//5D0aMGIF33nkn3+f5+Pjg0KFD0Ov1ePHFF1G3bl1MnDgRrq6uUKlUcHFxwa+//orOnTujZs2aeOedd7B06VLjxMGjRo1CrVq1EBISggoVKuDQoUPP4nKJLM6G/zgiK8Ack+yYYZIdM0yys8YloQFAEcVYe8nJyQlz587F5MmTc92+dOlSzJ49G+np6UUukCgvaWlp0Gq1eH7qWxA2OW81IirtNCoFvatVwffn/4WO912TpJhjkh0zTLJjhkkmxxe8m+MxnU6H6OhohISE5Dk9RWmS/Tk0NTUVLi4u+e5brBEuwcHB+Oqrr5CampprEV9//TUaNmxYnFMQEREREREREUmnWO2juXPnomPHjggMDMSwYcNQs2ZNAMCZM2ewZs0a3Lp1yzgXClFJ0RkErG8+ayoLdAaBnf9e4f+NIqkxxyQ7ZphkxwyT7NRqNerVq8dVip7Utm1b7Ny5E1OnTsX7779vsq1Bgwb45ptv0KZNm2IVSERkze5b4eRgVPYwxyQ7ZphkxwyT7GxtbS1dQoko1i1FwKMVeE6ePImrV6/iyJEjOHLkCK5evYoTJ06gXbt25qiRKF+ckZ1klX3PNTNMMmOOSXbMMMmOGSbZ6fV6REdHW+XEuWabkcbLywteXl7mOhwRERERERERkbQK1XBZu3ZtkU4yePDgIj2PiIiIiIiIiEhGhWq4DB06tNAnUBSFDRciIiIiIiIiKlMK1XBJSEgoqTqIioyrFJGsdAaB78//y1UFSGrMMcmOGSbZMcMkO7VajZCQEK5SVKVKlZKqg4ioTHLUaJCW9dDSZRAVC3NMsmOGSXbMMMkuKysLDg4Oli7D7Iq9ShEAZGZm4siRI9i6dStu3rxpjkMSFRhnZCdZaVQKOlfxZYZJaswxyY4ZJtkxwyQ7vV6PU6dOWeUqRcVuuKxYsQLe3t5o0aIFevbsiVOnTgEAbt68CQ8PD6xevbrYRRIRERERERERyaRYDZfw8HBMnDgRHTt2xNdffw0h/u++QQ8PD7Rt2xbr168vdpFERERERERERDIp1BwuT1q6dCm6d++OdevW4datWzm2P//881ixYkVxTkH0VD/PmAw3NzdLl0FUaDqdDidPnsSbrwyERlOsX8dEFsMck+yYYZIdM0zWwBonzAWKOcLln3/+QadOnfLc7ubmlmsjhsic+IeFZKXRaBAaGsoMk9SYY5IdM0yyY4ZJdtac4WI1XFxdXfOdJPfvv/+Gl5dXcU5B9FSP38pGJBMhBFJSUphhkhpzTLJjhkl2zDDJzpozXKyGS+fOnfHll18iJSUlx7a//voLq1atwksvvVScUxA9lTXOZk1lg16vR3x8PDNMUmOOSXbMMMmOGSbZWXOGi9VwmT9/PvR6PZ577jm88847UBQFa9aswSuvvIKQkBBUrFgR7777rrlqJSIiIiIiIiKSQrEaLj4+Pjh+/Dg6duyIDRs2QAiBb775Btu3b8eAAQPwxx9/wMPDw1y1EhERERERERFJodiz0lSsWBFfffUVvvrqK9y4cQMGgwEVKlSASlWsXg5RgSmKYukSiIpEURQ4ODgwwyQ15phkxwyT7Jhhkp01Z1gR1jgzDZUJaWlp0Gq1SE1NhYuLi6XLISIiIiIiIitXmM+hhRrhMm/evEIXoygKZs2aVejnERWUwWCwdAlERWIwGHDz5k14eHhwVCBJizkm2THDJDtmmGRnzRku1AiX3C4+e9jPk4dRFAVCCCiKYpWzDZPlZXcWG8yfAYOdraXLISo0G0VBX68AbLx2AQ852JAkxRyT7Jhhkh0zTDKJnTI3x2M6nQ7R0dEICQmBRlPsWU9KXGFGuBSqfWQwGEy+Ll26hLp162LAgAE4duwYUlNTkZqaiqNHj6J///6oX78+Ll26VKyLISIiIiIiIiKSTbHG64wdOxY1atTAt99+i5CQEDg7O8PZ2RmhoaH47rvvUK1aNYwdO9ZctRIRERERERERSaFYDZdffvkFbdu2zXN7u3btsH///uKcguipOHCSZCUAJGXeZ4ZJaswxyY4ZJtkxwyQ7RVGg1WqtcpWiYjVc7O3tceTIkTy3Hz58GPb29sU5BdFT6XivKklKJwR+uZ3EDJPUmGOSHTNMsmOGSXZqtRpBQUFQq9WWLsXsitVwGTRoEL777jtMmDAB586dM87tcu7cOYwfPx7r1q3DoEGDzFUrUa6sax5rKktUAOo6l2eGSWrMMcmOGSbZMcMkO4PBgMuXL1vl6rPFmgJ48eLFuHnzJlauXIlPPvnEuIqRwWCAEAIDBgzA4sWLzVIoUV7UigLre2tSWaBWFNRzckN8egoM/L9SJCnmmGTHDJPsmGGSXXbDxcvLy+qWhS5Ww8XW1hbffPMNpk6dip9++gmJiYkAgCpVqqBTp06oX7++WYokIiIiIiIiIpKJWRa5rlevHurVq2eOQxERERERERERSc8sDZeEhATs2rUL//77LwDA398fHTt2RNWqVc1xeKJ8GThykiRlEMA/99OYYZIac0yyY4ZJdswwyU6lUqFChQpWdzsRYIaGy+TJk7F8+fIcE9yoVCpMnDgRH3zwQXFPQZQvPQSsbz5rKgv0EDiaesPSZRAVC3NMsmOGSXbMMMlOpVKhWrVqli6jRBSrhbR06VJ8+OGH6NmzJ44cOYKUlBSkpKTgyJEj6N27Nz788EN8+OGH5qqVKFdqWN967VQ2qKGgsbYCM0xSY45JdswwyY4ZJtkZDAacP3/eKlcpKlbDZdWqVXjppZewceNGNG7cGC4uLnBxcUHjxo2xfv16dOvWDV988YW5aiXKlYp/W0hSKgWo7ujCDJPUmGOSHTNMsmOGSXYGgwE3btxgw+VJFy9eRIcOHfLc3qFDB1y8eLE4pyAiIiIiIiIikk6xGi4VK1ZEbGxsnttjY2NRoUKF4pyCSpkbN27g9ddfR+XKlWFnZwcvLy906NABBw8ehIeHB95///1cn/fee+/B09MTDx8+BABkZWVhyZIlqF+/PhwdHeHh4YHmzZsjPDzcuA8RERERERGRrIo1aW6fPn2wfPly+Pv7Y/z48ShXrhwA4N69e1i5ciW++uorTJw40Rx1UinRq1cvZGVlYc2aNQgICMD169exf/9+pKam4pVXXkF4eDhmzJhh8hwhBCIiIjB48GDY2NggKysLHTp0QGxsLN577z00b94cLi4u+OOPP/DBBx8gODgYDRo0KHBNeiF4xypJSS8ETqXfhl5wWQGSF3NMsmOGSXbMMMlOpVKhUqVKVrlKkSJE0d+Z9+/fR7du3XDgwAFoNBr4+PgAAK5evQqdToc2bdpg+/btcHR0NFvBZDkpKSkoX748IiMj0apVqxzbT58+jXr16uG3335DixYtjI9HRkaiTZs2iIuLQ2BgIJYsWYKZM2ciOjoawcHBJsd4+PAhsrKyjM27/KSlpUGr1aLOe9Ohtrcr/gUSERERERFRiYmdMtfSJRRb9ufQ1NRUuLi45LtvsVpIjo6O2L9/P3788UcMGzYMQUFBCAoKwvDhw7Flyxbs27ePzRYr4uTkBCcnJ2zZsgWZmZk5ttetWxehoaFYvXq1yePh4eFo1qwZAgMDAQDfffcdwsLCcjRbAMDGxqZAzZbHaRSObyE5aRQFbd28mWGSGnNMsmOGSXbMMMlOr9cjLi4Oer3e0qWYXbFuKcrWvXt3dO/e3RyHolJMo9EgIiICo0aNwueff46GDRuiVatW6N+/P+rVqwcAGDFiBKZMmYIVK1bAyckJd+/exffff48VK1YYj3Pu3Dm0bt260OfPzMw0afSkpaUBABQAHEBJMlIAeNs58pY4khpzTLJjhkl2zDDJTgiB1NRUFOPmm1Kr0A2Xl156qVD7K4qCrVu3FvY0VEr16tULXbp0wW+//YY//vgDu3btwpIlS/DVV19h6NChGDBgAN58801s3LgRw4cPx4YNG6BSqdCvXz/jMYr6Rlq0aBHmzpV/CBoRERERERFZv0I3XHbs2AF7e3t4eXkV6IOzwqFtVsfe3h7t27dH+/btMWvWLIwcORKzZ8/G0KFD4eLigt69eyM8PBzDhw9HeHg4+vbtCycnJ+Pza9asifj4+EKfd+bMmZg0aZLx+7S0NPj5+ZnlmoiIiIiIiIjMqdANF19fX1y5cgUeHh4YOHAg+vfvDy8vr5KojSRRu3ZtbNmyxfj9iBEj0Lp1a+zYsQOHDx/Gf//7X5P9Bw4ciLfeegsnT54s1KS5dnZ2sLPLOTkuVykiWemFwB+pyVxVgKTGHJPsmGGSHTNMslOpVAgICLDKVYoKfUWXLl3CgQMHEBwcjPfeew9+fn4ICwtDeHg47t69WxI1Uilx69YttG3bFt9++y1OnTqFhIQEbNq0CUuWLDGZw6dly5aoXr06Bg8ejMDAQDRr1szkOBMnTkTz5s3Rrl07fPLJJ4iNjcWFCxewceNGNGnSBOfOnStUXQazXB3Rs2cAcP7+XWaYpMYck+yYYZIdM0yyU6lUqFixIhsu2Vq1aoUvvvgC165dw/fffw93d3eMGzcOFStWRM+ePfH999/nuooNyc3JyQmNGzfGhx9+iJYtW+K5557DrFmzMGrUKKxcudK4n6IoGD58OO7cuYPhw4fnOI6dnR327t2LadOm4YsvvkCTJk0QGhqKFStWYMKECXjuuecKVRdnZCdZaRQFXSv4McMkNeaYZMcMk+yYYZKdXq9HbGysVa5SpAgzTQWcnp6OH374AZ9//jmOHj2KOXPmYNasWeY4NFGustc/bzB/Bgx2tpYuh6jQbBQFfb0CsPHaBTzkMGCSFHNMsmOGSXbMMMkkdkrORVB0Oh2io6MREhICjcYsCymXqOzPoampqXBxccl3X7OM2cnMzMSePXuwdetWnDx5Evb29vD39zfHoYmIiIiIiIiIpFPkhovBYMCePXswdOhQeHp6YsCAAcjIyMCqVauQnJyMV1991Zx1EhERERERERFJo9DjdQ4fPox169Zh06ZNuHXrFpo0aYKFCxeib9++8PDwKIkaifKlE8I8Q7WInjGdEPjl9lXoOPyXJMYck+yYYZIdM0yyU6vVCAwMhFqttnQpZlfohkuLFi3g4OCAzp07Y8CAAcZbhxITE5GYmJjrcxo2bFisIonywz8tJCsBICkzw9JlEBULc0yyY4ZJdswwyU5RFLi6ulq6jBJRpBlpMjIysHnzZvzwww/57ieEgKIoVjnbMJUeNorCZfBISjaKgh6e/vjx+kVOckfSYo5JdswwyY4ZJtnpdDqcPHkSwcHBUkyaWxiFvprw8PCSqIOIqEyyUXhDHMmPOSbZMcMkO2aYZGetgzQK3XAZMmRISdRBRERERERERGQ12AolIiIiIiIiIjIzNlxIepyRnWSlEwI7biQywyQ15phkxwyT7Jhhkp1arUa9evWscpUiNlxIevzTQrISAO7rdcwwSY05JtkxwyQ7Zpisga2traVLKBFsuJD0bBTF0iUQFYmNoqCvVwAzTFJjjkl2zDDJjhkm2en1ekRHR1vlxLlsuBARERERERERmZkiBG/2IzmlpaVBq9Xi1q1bcHNzs3Q5RIWm0+kQHR2NkJAQaDSFXjSOqFRgjkl2zDDJjhkm2cmW4ezPoampqXBxccl3X45wISIiIiIiIiIyM45wIWlldxZTUlKg1WotXQ5RoQkhoNfroVarofC+a5IUc0yyY4ZJdswwyU62DHOECxGRJLKysixdAlGxMcckO2aYZMcMk+ysNcNsuJD0rHE2ayob9Ho9Tp06xQyT1Jhjkh0zTLJjhkl21pxhNlyIiIiIiIiIiMyMDRciIiIiIiIiIjNjw4WIyILUarWlSyAqNuaYZMcMk+yYYZKdtWaYqxSRtAozOzQRERERERFRcXGVIipT2DMkWQkhkJKSwgyT1Jhjkh0zTLJjhkl21pxhjaULICquLusWAA42li6DqNA0UKFbuWrYfu88dDBYuhyiImGOSXbMMMmOGba834cusHQJUtPr9YiPj0dISAg0GutqUXCECxERERERERGRmbHhQkRERERERERkZmy4kPQErO9ePyobBATuGrKYYZIac0yyY4ZJdswwyU5RFDg4OEBRFEuXYnbWdYMUlUl6CAaZpKSHwL6Mfy1dBlGxMMckO2aYZMcMk+zUajXq169v6TJKBEe4kPSsrw9KZYUCwF/jwgyT1Jhjkh0zTLJjhkl2BoMBycnJMBisb9JnNlxIemrGmCSlhgrBdp7MMEmNOSbZMcMkO2aYZGcwGHDhwgU2XIiIiIiIiIiI6OnYcCEiIiIiIiIiMjM2XEh6nJGdZCUgkKy/zwyT1Jhjkh0zTLJjhkl2iqJAq9VylSKi0oirFJGs9BA49OCKpcsgKhbmmGTHDJPsmGGSnVqtRlBQkKXLKBEc4ULSU3FOdpKUCgqCbNyZYZIac0yyY4ZJdswwyc5gMODy5cucNJeoNOIfF5KVCgoCbd2YYZIac0yyY4ZJdswwyY4NFyIiIiIiIiIiKjA2XKhAhg4dipdfftnkse+//x729vZYunQphg4dCkVR8P7775vss2XLFpPJjyIjI6EoCurUqQO9Xm+yr6urKyIiIkrqEoiIiIiIiIieGTZcqEi++uorDBo0CJ999hkmT54MALC3t8fixYtx586dpz7/woULWLt2rVlqMXBGdpKUAQL/6tKYYZIac0yyY4ZJdswwyU6lUqFChQpQqayvPWF9V0QlbsmSJRg/fjzWr1+PYcOGGR8PCwuDl5cXFi1a9NRjjB8/HrNnz0ZmZmax6+EfF5KVAQInMq8zwyQ15phkxwyT7Jhhkp1KpUK1atXYcCGaPn063nvvPezYsQM9evQw2aZWq7Fw4UJ8/PHHuHz5cr7HmThxInQ6HT7++OMCnzszMxNpaWkmXwAnzSV5qaCgoZ0nM0xSY45JdswwyY4ZJtkZDAacP3+ek+ZS2bZr1y4sWbIEW7duRbt27XLdp0ePHmjQoAFmz56d77EcHR0xe/ZsLFq0CKmpqQU6/6JFi6DVao1ffn5+ANhwIXmpoKCKxoUZJqkxxyQ7ZphkxwyT7AwGA27cuMGGC5Vt9erVg7+/P2bPno309PQ891u8eDHWrFmDuLi4fI83YsQIuLu7Y/HixQU6/8yZM5Gammr8unTpUqHqJyIiIiIiInpW2HChAvP19UVkZCSuXLmCjh074u7du7nu17JlS3To0AEzZ87M93gajQYLFizA8uXLcfXq1aee387ODi4uLiZfRERERERERKURGy5UKFWqVMHBgwdx7dq1fJsu77//PrZv344jR47ke7w+ffqgTp06mDt3bpFr4gRhJCsDBOKzbjPDJDXmmGTHDJPsmGGSnUqlQqVKlThpLhEA+Pn5ITIyEsnJyejQoYNx8trH1a1bF4MGDcKKFSueerz3338fq1evxr1794pUD/+4kKwMEIh7eIsZJqkxxyQ7ZphkxwyT7NhwIXpCpUqVEBkZiZs3b+bZdJk3b16BJj5q27Yt2rZtC51OV6Ra1JwgjCSlhoLm9r7MMEmNOSbZMcMkO2aYZKfX6xEXFwe9Xm/pUsxOY+kCSA4RERE5HvP19cXZs2fzfI6/vz8yMzNNHmvdujWEyNl937NnT5FrU/jHhSSlQEFFteP/zzD/rxTJiTkm2THDJDtmmGQnhEBqamqunxNlxxEuRERERERERERmxoYLEREREREREZGZseFC0tPj6fPEEJVGehhwMvM6M0xSY45JdswwyY4ZJtmpVCoEBARY5aS5nMOFpGd9d/pRWSEAXNTlnHCaSCbMMcmOGSbZMcMkO5VKhYoVK1q6jBJhfS0kKnM4IzvJSg0FYQ5VmGGSGnNMsmOGSXbMMMlOr9cjNjbWKlcpYsOFpMdVikhWChQ4q2yZYZIac0yyY4ZJdswwyU4IgYyMDK5SRERERERERERET8eGCxERERERERGRmbHhQtLjjOwkKz0MOPTgCjNMUmOOSXbMMMmOGSbZqdVqBAYGQq1WW7oUs+MqRSQ967vTj8oKASBZf9/SZRAVC3NMsmOGSXbMMMlOURS4urpauowSwREuJD0NY0yS0kCFbuWqMcMkNeaYZMcMk+yYYZKdTqdDVFQUdDqdpUsxO74riYgsiP84ImvAHJPsmGGSHTNMsrPGJaEBQBHWuPYSlQlpaWnQarW4desW3NzcLF0OUaHpdDpER0cjJCQEGg3v8CQ5McckO2aYZMcMk+xky3D259DU1FS4uLjkuy9boUREREREREREZsYRLiSt7M5iSkoKtFqtpcshKjQhBDIyMuDg4ABFUSxdDlGRMMckO2aYZMcMk+xkyzBHuBARScLW1tbSJRAVG3NMsmOGSXbMMMnOWjPMhgtJz1onWCLrp9frER0dzQyT1Jhjkh0zTLJjhkl21pxhNlyIiIiIiIiIiMyMDRciIiIiIiIiIjNjw4WIiIiIiIiIyMy4ShFJi6sUkeyEENDr9VCr1VLMyE6UG+aYZMcMk+yYYZKdbBkuzCpFmmdUE1GJGbP3LdiWs7N0GUSFJwAH2CEDmUDp/9tClDvmmGTHDFMJC++0rMTPkZWVBQcHhxI/D1FJsdYM85Yikp6aMSZJqaFCfV0NZpikxhyT7Jhhkp1er8epU6escoUXKhusOcP8y0JEREREREREZGZsuBARERERERERmRkbLkREFqRXrG/oJJU9zDHJjhkm2anVakuXQFQs1pphTppL0tMrBljn25OsnV4xIEoTZ+kyiIqFOSbZMcMkO41Gg9DQUEuXQVRk1pxhjnAh+XFhc5KVALQGJ2aY5MYck+yYYZKcEAIpKSkQgiEmOVlzhtlwIelxVQGSlRoqBOn9mWGSGnNMsmOGSXZ6vR7x8fFWucILlQ3WnGH+ZSEiIiIiIiIiMjM2XIiIiIiIiIiIzIwNF5Ke4E3XJCkBgfvKA2aYpMYck+yYYZKdoihwcHCAoiiWLoWoSKw5w1yliKRnUPgPJJKTQRE4pfnH0mUQFQtzTLJjhkl2arUa9evXt3QZREVmzRnmCBeSHvstJCtFABUM5ZlhkhpzTLJjhkl2BoMBycnJMBgMli6FqEisOcNsuFiROXPmoEGDBpYu45lTMcYkKRVUqKb3ZYZJaswxyY4ZJtkZDAZcuHDBKj+sUtlgzRnmX5ZS7siRI1Cr1ejSpUuJHN/f3x+KokBRFKjVavj4+GDEiBG4c+dOiZwvN5GRkVAUBSkpKc/snEREREREREQliQ2XUu7rr7/G+PHj8euvv+Lq1aslco558+YhKSkJiYmJ+O677/Drr79iwoQJJXIuIiIiIiIiorKADZdSLD09HRs2bMDrr7+OLl26ICIiwmT7+++/D09PTzg7O2PEiBF48OCByfaoqCi0b98eHh4e0Gq1aNWqFU6cOJHjPM7OzvDy8oKvry/atGmDIUOG5Nhv8+bNqFOnDuzs7ODv74+lS5eabL9z5w4GDx6M8uXLw9HREZ06dcK5c+eM2//9919069YN5cuXR7ly5VCnTh3s3LkTFy9eRJs2bQAA5cuXh6IoGDp0aKFeJ64qQLISEEhR0plhkhpzTLJjhkl2iqJAq9Va5QovVDZYc4bZcCnFNm7ciMDAQNSqVQuvvPIKVq9eDSGEcducOXOwcOFCREdHw9vbG59++qnJ8+/evYshQ4bg999/xx9//IEaNWqgc+fOuHv3bp7nvHLlCrZv347GjRsbHzt+/Dj69u2L/v374/Tp05gzZw5mzZpl0gAaOnQooqOjsW3bNhw5cgRCCHTu3BkPHz4EAIwdOxaZmZn49ddfcfr0aSxevBhOTk7w8/PD5s2bAQBnzpxBUlISli9fnmttmZmZSEtLM/kCuEoRycugCMRrLjLDJDXmmGTHDJPs1Go1goKCoFarLV0KUZFYc4YVkf0Jnkqd5s2bo2/fvnjjjTeg0+ng7e2NTZs2oXXr1mjWrBmCg4PxySefGPdv0qQJHjx4gJiYmFyPZzAY4OrqinXr1qFr164AHs3hkpSUBBsbG+j1ejx48ACNGzfG7t274erqCgAYNGgQbty4gZ9//tl4rGnTpuGnn37CX3/9hXPnzqFmzZo4dOgQmjVrBgC4desW/Pz8sGbNGvTp0wf16tVDr169MHv27Bx1RUZGok2bNrhz547xnLmZM2cO5s6dm+PxQZvGwqac7dNeTqJSRxEKfA0VcEV1A4L/0CdJMcckO2aYSlp4p2UlenyDwYCrV6/Cx8cHKhX/fzrJR7YMp6WlQavVIjU1FS4uLvnuW/qvpow6c+YMjh07hgEDBgAANBoN+vXrh6+//hoAEBcXZzIKBQCaNm1q8v3169cxatQo1KhRA1qtFi4uLkhPT0diYqLJflOnTkVMTAxOnTqF/fv3AwC6dOkCvV5vPFfz5s1NntO8eXOcO3cOer0ecXFx0Gg0JvW4u7ujVq1aiIuLAwBMmDAB8+fPR/PmzTF79mycOnWq0K/JzJkzkZqaavy6dOkSAEAF6xt6RmWDCgoqGSoywyQ15phkxwyT7AwGAy5fvmyVK7xQ2WDNGWbDpZT6+uuvodPp4OPjA41GA41Gg88++wybN29GampqgY4xZMgQxMTEYPny5Th8+DBiYmLg7u6OrKwsk/08PDxQvXp11KhRA23btsVHH32Ew4cP48CBA2a7npEjR+LChQt49dVXcfr0aYSEhODjjz8u1DHs7Ozg4uJi8kVERERERERUGrHhUgrpdDqsXbsWS5cuRUxMjPErNjYWPj4++N///oegoCAcPXrU5Hl//PGHyfeHDh3ChAkT0LlzZ+OEtzdv3nzq+bPvncvIyAAABAUF4dChQzmOXbNmTeP9djqdzqSeW7du4cyZM6hdu7bxMT8/P/znP//BDz/8gMmTJ2PVqlUAAFvbR7cDZY+oISIiIiIiIpKdxtIFUE47duzAnTt3MGLECGi1WpNtvXr1wtdff40pU6Zg6NChCAkJQfPmzfHdd9/hr7/+QkBAgHHfGjVq4JtvvkFISAjS0tIwdepUODg45Djf3bt3ce3aNQghcOnSJUybNg0VKlQwzscyefJkhIaG4r333kO/fv1w5MgRrFy50jhJb40aNdC9e3eMGjUKX3zxBZydnTFjxgz4+vqie/fuAICJEyeiU6dOqFmzJu7cuYMDBw4gKCgIAFClShUoioIdO3agc+fOcHBwgJOTU4FfLwMErG96JSoLDBBIVt2BgStjkMSYY5IdM0yyU6lUqFChghRzXxDlxpozbH1XZAW+/vprhIWF5Wi2AI8aLtHR0QgKCsKsWbMwbdo0PP/88/j333/x+uuv5zjOnTt30LBhQ7z66quYMGECKlasmOOY7777Lry9veHj44OuXbuiXLly+Pnnn+Hu7g4AaNiwITZu3Ij169fjueeew7vvvot58+aZLN8cHh6O559/Hl27dkXTpk0hhMDOnTthY2MD4NHolbFjxyIoKAgdO3ZEzZo1jQ0bX19fzJ07FzNmzICnpyfGjRtXqNeLE9yRrIQicEF9hRkmqTHHJDtmmGSnUqlQrVo1q/ywSmWDNWeYqxSRtLJnh+YqRSQrRSioavBBguoq/6FP0mKOSXbMMJW0Z7FKUUJCAqpWrWqVH1jJ+smWYa5SRGUKVxUgWamgoKKhPDNMUmOOSXbMMMnOYDDgxo0bVrnCC5UN1pxhNlyIiIiIiIiIiMyMDRciIiIiIiIiIjNjw4Wkx1UFSFYGCFxWJTPDJDXmmGTHDJPsVCoVKlWqJMXcF0S5seYMc1lokh4nuCNZCUXgsjrZ0mUQFQtzTLJjhkl22R9WiWRlzRm2vhYSlTkqwUnuSE4qoSBQ588Mk9SYY5IdM0yy0+v1iIuLg16vt3QpREVizRlmw4Wkp3BVAZKUAgWuwokZJqkxxyQ7ZphkJ4RAamoqhOCob5KTNWeYDRciIiIiIiIiIjNjw4WIiIiIiIiIyMzYcCHpGWCwdAlERWKAAefVV5hhkhpzTLJjhkl2KpUKAQEBVrnCC5UN1pxhrlJE0uMcdyQroQA3lDuWLoOoWJhjkh0zTLJTqVSoWLGipcsgKjJrzrD1tZCozOGqAiQrlVBQT1edGSapMcckO2aYZKfX6xEbG2uVK7xQ2WDNGeYIF5Le8rbz4ObmZukyiApNp9MhOjoa40NGQ6Phr2OSE3NMsmOGSXZCCGRkZFjlCi9UNlhzhjnChYiIiIiIiIjIzNhwISIiIiIiIiIyMzZcSHpqtdrSJRAViVqtRmBgIDNMUmOOSXbMMMmOGSbZWXOGeaMqSU9ROMkdyUlRFLi6ulq6DKJiYY5JdswwyY4ZJtlZc4Y5woWkp9PpLF0CUZHodDpERUUxwyQ15phkxwyT7Jhhkp01Z5gNFyIiC7LG5e+o7GGOSXbMMMmOGSbZWWuG2XAhIiIiIiIiIjIzNlyIiIiIiIiIiMxMEUIISxdBVBRpaWnQarVISUmBVqu1dDlEhSaEQEZGBhwcHDj5M0mLOSbZMcMkO2aYZCdbhrM/h6ampsLFxSXffTnChYjIgmxtbS1dAlGxMcckO2aYZMcMk+ysNcNsuJD0rHWCJbJ+er0e0dHRzDBJjTkm2THDJDtmmGRnzRlmw4WIiIiIiIiIyMzYcCEiIiIiIiIiMjM2XIiIiIiIiIiIzIyrFJG0uEoRyU4IAb1eD7VaLcWM7ES5YY5JdswwyY4ZJtnJlmGuUkREJImsrCxLl0BUbMwxyY4ZJtkxwyQ7a80wGy4kPWuczZrKBr1ej1OnTjHDJDXmmGTHDJPsmGGSnTVnmA0XIiIiIiIiIiIzY8OFiIiIiIiIiMjM2HAhIrIgtVpt6RKIio05JtkxwyQ7ZphkZ60Z5ipFJK3CzA5NREREREREVFxcpYjKFPYMSVZCCKSkpDDDJDXmmGTHDJPsmGGSnTVnmA0Xiej1ejRr1gw9e/Y0eTw1NRV+fn54++23jY9t3rwZbdu2Rfny5eHg4IBatWph+PDhOHnypHGfiIgIKIpi/HJycsLzzz+PH3744ZldEwC0bt0aEydOLPLzrXE2ayob9Ho94uPjmWGSGnNMsmOGSXbMMMnOmjPMhotE1Go1IiIisHv3bnz33XfGx8ePHw83NzfMnj0bADB9+nT069cPDRo0wLZt23DmzBmsW7cOAQEBmDlzpskxXVxckJSUhKSkJJw8eRIdOnRA3759cebMmWd6bURERERERETWhA0XydSsWRPvv/8+xo8fj6SkJGzduhXr16/H2rVrYWtriz/++ANLlizBsmXLsGzZMrzwwguoXLkynn/+ebzzzjvYtWuXyfEURYGXlxe8vLxQo0YNzJ8/HyqVCqdOnTLuc+fOHQwePBjly5eHo6MjOnXqhHPnzpkc5/+1d+/xPdf9H8ef352HbU4bw3LY5lCYKzlLVLiIuHJYck2LKyGSU7gqIypJLmcrl9DVWFehhEgOESJn1RRmznJqTlvM9/v5/dHP92ptw2Y27+8e99vte7vZ5/v+fL6vz+f2HPba5/N+L1iwQPfdd5+8vb1VoUIFvfPOO+nenz59usLDw+Xj46NSpUqpY8eOkqTo6Gh9/fXXmjRpkvNOm6SkpDtz8QAAAAAAyCMe+V0Asq9fv35atGiRoqKitGfPHo0YMUIRERGSpPnz56tIkSLq06dPpvvabLYsj2u32/XBBx9Iku6//37n9ujoaO3bt0+LFy+Wv7+/hg4dqtatW+vHH3+Up6entm3bps6dO2vkyJGKjIzUxo0b1adPH5UoUULR0dHaunWrXnjhBf3nP/9Rw4YNde7cOa1fv16SNGnSJP3888+qXr26XnvtNUlSYGBgpvVduXJFV65ccX594cKFm54TcDez2Wzy9fUlwzAaOYbpyDBMR4ZhOlfOMKsUGWrv3r2qVq2aatSooe3bt8vD4/feWatWrXT8+HHt2rXLOXbChAkaMWKE8+tjx44pICBAc+bM0TPPPKPChQtLklJTU+Xp6anY2FhFR0dLkvbt26fKlStrw4YNatiwoSTp7NmzCgkJ0dy5c9WpUyd17dpVp0+f1pdffun8jJdeeklLly7VDz/8oIULF+qZZ57R0aNH5efnl+FcmjZtqlq1amnixIk3POeRI0dq1KhRGbazShEAAAAAIC+wSlEB8P7776tQoUI6ePCgjh49esOx3bt3186dO/Xuu+/q8uXL6WZ/9vPz086dO7Vz507t2LFDb7zxhnr16qXPP/9ckpSQkCAPDw/Vq1fPuU+JEiVUpUoVJSQkOMc0atQo3Wc2atRI+/btk91uV/PmzVW+fHlVqlRJUVFRiouLU0pKSrbPefjw4Tp//rzzdeTIEUmSw+HI9rGAu4HD4dCpU6fIMIxGjmE6MgzTkWGYzpUzTMPFQBs3btS//vUvLVmyRHXr1lWPHj2cTZTw8HAlJiYqLS3NOb5o0aIKCwtT2bJlMxzLzc1NYWFhCgsLU82aNTVw4EA1bdpUb731Vq7V6+fnp+3bt2v+/PkKDg52PgKVnJycreN4e3vL398/3Uui4QJzORwOJSYmkmEYjRzDdGQYpiPDMJ0rZ5iGi2FSUlIUHR2t3r17q1mzZpo1a5a2bNmi2NhYSVKXLl106dIlTZ8+Pcef4e7urtTUVElStWrVdO3aNW3evNn5/tmzZ/XTTz/p3nvvdY7ZsGFDumNs2LBBlStXlru7uyTJw8NDjz76qMaNG6fdu3crKSlJq1evliR5eXm55BJgAAAAAICCi0lzDTN8+HBZlqWxY8dKkipUqKDx48dr8ODBatWqlRo0aKBBgwZp0KBBOnTokJ544gmFhIToxIkTmjVrlmw2m9zc/tdnsyxLJ0+elPT7HC4rV67UihUrnHO+hIeHq127dnr22Wf17rvvys/PT8OGDVPZsmXVrl07SdKgQYNUp04djR49WpGRkdq0aZOmTp3qbPosWbJEiYmJatKkiYoVK6Zly5bJ4XCoSpUqznPYvHmzkpKSVKRIERUvXjxdjQAAAAAAmIafag3y9ddfa9q0aZo9e7YKFSrk3P7cc8+pYcOGzkeLxo8fr3nz5mnHjh1q06aNwsPD1alTJzkcDm3atCndxD4XLlxQcHCwgoODVa1aNb3zzjt67bXX9PLLLzvHzJ49W7Vr11abNm3UoEEDWZalZcuWydPTU9LvKxr997//VXx8vKpXr64RI0botddec068W7RoUS1cuFAPP/ywqlWrptjYWM2fP1/33XefJGnw4MFyd3fXvffeq8DAQB0+fDhb18UVZ7NGwWCz2RQQEECGYTRyDNORYZiODMN0rpxhVimCsbIzOzQAAAAAALeLVYpQoLji5EooGBwOh44ePUqGYTRyDNORYZiODMN0rpxhGi4wnit+Y6JgcOV/XFBwkGOYjgzDdGQYpnPlDNNwAQAAAAAAyGU0XAAAAAAAAHIZDRcYjyWkYSo3NzcFBgaSYRiNHMN0ZBimI8MwnStnmFWKYCxWKQIAAAAA5CVWKUKB4oqTK6FgcDgcOnDgABmG0cgxTEeGYToyDNO5coZpuMB4rviNiYLB4XDo9OnTZBhGI8cwHRmG6cgwTOfKGabhAgAAAAAAkMtouAAAAAAAAOQyGi4wnivOZo2Cwc3NTeXKlSPDMBo5hunIMExHhmE6V84wqxTBWKxSBAAAAADIS6xShALFbrfndwlAjtjtdiUkJJBhGI0cw3RkGKYjwzCdK2eYhguMx01aMJVlWTp//jwZhtHIMUxHhmE6MgzTuXKGabgAAAAAAADkMhouAAAAAAAAuYyGC4znirNZo2Bwc3NTpUqVyDCMRo5hOjIM05FhmM6VM8wqRTAWqxQBAAAAAPISqxShQHHF2axRMNjtdu3atYsMw2jkGKYjwzAdGYbpXDnDNFxgPG7Sgqksy1JqaioZhtHIMUxHhmE6MgzTuXKGabgAAAAAAADkMhouAAAAAAAAuYyGC4zn7u6e3yUAOeLu7q6qVauSYRiNHMN0ZBimI8MwnStn2CO/CwBul81my+8SgByx2WwqWrRofpcB3BZyDNORYZiODMN0rpxh7nCB8a5du5bfJQA5cu3aNX333XdkGEYjxzAdGYbpyDBM58oZpuECAPnIFZe/Q8FDjmE6MgzTkWGYzlUzTMMFAAAAAAAgl9FwAQAAAAAAyGU2y7Ks/C4CyIkLFy4oICBAycnJCggIyO9ygGyzLEupqany9fVl8mcYixzDdGQYpiPDMJ1pGb7+c+j58+fl7+9/w7Hc4QIA+cjLyyu/SwBuGzmG6cgwTEeGYTpXzTANFxjPVSdYguuz2+3aunUrGYbRyDFMR4ZhOjIM07lyhmm4AAAAAAAA5DIaLgAAAAAAALmMhgsAAAAAAEAuY5UiGItVimA6y7Jkt9vl7u5uxIzsQGbIMUxHhmE6MgzTmZZhVilyQSdPnlS/fv1UqVIleXt7KyQkRG3bttWqVatuaf85c+aoaNGiGbY3bdpUNpvN+SpVqpQ6deqkQ4cO5fIZZC0pKUk2m007d+7Ms88E7hZXr17N7xKA20aOYToyDNORYZjOVTNMw8UASUlJql27tlavXq23335be/bs0fLly9WsWTM9//zzt338Z599VidOnNDx48f12Wef6ciRI/r73/+eC5XnDVeczRoFg91u1+7du8kwjEaOYToyDNORYZjOlTNMw8UAffr0kc1m05YtW9ShQwdVrlxZ9913nwYOHKhvv/1WkjRhwgTVqFFDhQsXVkhIiPr06aNLly5JktauXatnnnlG58+fd97JMnLkSOfxCxUqpNKlSys4OFj169dX3759tX379nQ1fP3116pbt668vb0VHBysYcOG6dq1a873r1y5ohdeeEFBQUHy8fFR48aN9d133znf//XXX9W1a1cFBgbK19dX4eHhmj17tiSpYsWKkqS//OUvstlsatq06Z24jAAAAAAA5BkaLne5c+fOafny5Xr++edVuHDhDO9ff0zIzc1NkydP1g8//KC5c+dq9erVeumllyRJDRs21MSJE+Xv768TJ07oxIkTGjx4cJaf99///lf16tVzbjt27Jhat26tOnXqaNeuXZoxY4ZmzZqlMWPGOMe89NJLWrBggebOnavt27crLCxMLVu21Llz5yRJr776qn788Ud98cUXSkhI0IwZM1SyZElJ0pYtWyRJX331lU6cOKGFCxfe/oUDAAAAACAfeeR3Abix/fv3y7IsVa1a9YbjXnzxReefK1SooDFjxqhXr16aPn26vLy8FBAQIJvNptKlS2fYd/r06fr3v/8ty7KUkpKiypUra8WKFeneDwkJ0dSpU2Wz2VS1alUdP35cQ4cO1YgRI5SamqoZM2Zozpw5atWqlSRp5syZWrlypWbNmqUhQ4bo8OHD+stf/qIHHnjAWeN1gYGBkqQSJUpkWt91V65c0ZUrV5xfX7hw4YbXBDCBu7t7fpcA3DZyDNORYZiODMN0rpph7nC5y93qIlJfffWVHnnkEZUtW1Z+fn6KiorS2bNnlZKSctN9u3btqp07d2rXrl365ptvFBYWphYtWujixYuSpISEBDVo0CDdjNGNGjXSpUuXdPToUR04cEBpaWlq1KiR831PT0/VrVtXCQkJkqTevXsrPj5etWrV0ksvvaSNGzdm5zJIkt58800FBAQ4XyEhIZIkDw/6hjCTh4eH6tSpQ4ZhNHIM05FhmI4Mw3SunGEaLne58PBw2Ww27d27N8sxSUlJatOmjWrWrKkFCxZo27ZtmjZtmqRbm+05ICBAYWFhCgsLU6NGjTRr1izt27dPH330Ua6dR6tWrXTo0CENGDBAx48f1yOPPJLlY01ZGT58uM6fP+98HTlyRNKtN6WAu41lWUpOTibDMBo5hunIMExHhmE6V84wDZe7XPHixdWyZUtNmzZNly9fzvB+cnKytm3bJofDoXfeeUf169dX5cqVdfz48XTjvLy8bnnW5+u3c6WmpkqSqlWrpk2bNqX7BtiwYYP8/PxUrlw5hYaGysvLSxs2bHC+n5aWpu+++0733nuvc1tgYKCefvppffjhh5o4caLee+89Z23SzVcb8vb2lr+/f7rXrewH3K3sdrv27t1LhmE0cgzTkWGYjgzDdK6cYRouBpg2bZrsdrvq1q2rBQsWaN++fUpISNDkyZPVoEEDhYWFKS0tTVOmTFFiYqL+85//KDY2Nt0xKlSooEuXLmnVqlU6c+ZMukeNUlJSdPLkSZ08eVK7du1S79695ePjoxYtWkj6fZWkI0eOqF+/ftq7d68+++wzxcTEaODAgXJzc1PhwoXVu3dvDRkyRMuXL9ePP/6oZ599VikpKerRo4ckacSIEfrss8+0f/9+/fDDD1qyZImqVasmSQoKCpKvr6+WL1+uX375RefPn8+jKwsAAAAAwJ1Bw8UAlSpV0vbt29WsWTMNGjRI1atXV/PmzbVq1SrNmDFDERERmjBhgt566y1Vr15dcXFxevPNN9Mdo2HDhurVq5ciIyMVGBiocePGOd+bOXOmgoODFRwcrGbNmunMmTNatmyZqlSpIkkqW7asli1bpi1btigiIkK9evVSjx499MorrziPMXbsWHXo0EFRUVG6//77tX//fq1YsULFihWT9PtdLMOHD1fNmjXVpEkTubu7Kz4+XtLvz+xNnjxZ7777rsqUKaN27drd6UsKAAAAAMAdZbNc8UEpFAgXLlxQQECAzp0752zsACax2+36/vvvVb16dZedmR2ujxzDdGQYpiPDMJ1pGb7+c+j58+ed01xkhYYLjJWdoAMAAAAAcLuy83MojxTBeA6HI79LAHLE4XDo1KlTZBhGI8cwHRmG6cgwTOfKGabhAuO54jcmCgaHw6HExEQyDKORY5iODMN0ZBimc+UM03ABAAAAAADIZTRcAAAAAAAAchkNFxjPZrPldwlAjthsNgUEBJBhGI0cw3RkGKYjwzCdK2eYVYpgLFYpAgAAAADkJVYpQoHiipMroWBwOBw6evQoGYbRyDFMR4ZhOjIM07lyhmm4wHiu+I2JgsGV/3FBwUGOYToyDNORYZjOlTNMwwUAAAAAACCX0XABAAAAAADIZTRcYDw3N2IMM7m5uSkwMJAMw2jkGKYjwzAdGYbpXDnDrFIEY7FKEQAAAAAgL7FKEQoUV5xcCQWDw+HQgQMHyDCMRo5hOjIM05FhmM6VM0zDBcZzxW9MFAwOh0OnT58mwzAaOYbpyDBMR4ZhOlfOMA0XAAAAAACAXOaR3wUAOXV9+qELFy7Iw4MowzzXrl3T5cuXyTCMRo5hOjIM05FhmM60DF+4cEHS/34evZG7/2yALJw9e1aSVLFixXyuBAAAAABQkFy8eFEBAQE3HEPDBcYqXry4JOnw4cM3DTpwN7pw4YJCQkJ05MgRVtqCscgxTEeGYToyDNOZlmHLsnTx4kWVKVPmpmNpuMBY19dpDwgIMOIbE8iKv78/GYbxyDFMR4ZhOjIM05mU4Vv9hT+T5gIAAAAAAOQyGi4AAAAAAAC5jIYLjOXt7a2YmBh5e3vndylAjpBhuAJyDNORYZiODMN0rpxhm3UraxkBAAAAAADglnGHCwAAAAAAQC6j4QIAAAAAAJDLaLgAAAAAAADkMhouAAAAAAAAuYyGC+5q06ZNU4UKFeTj46N69eppy5YtNxz/8ccfq2rVqvLx8VGNGjW0bNmyPKoUyFx2Mjxz5kw9+OCDKlasmIoVK6ZHH330ppkH8kJ2/y6+Lj4+XjabTe3bt7+zBQI3kd0MJycn6/nnn1dwcLC8vb1VuXJl/k+BfJXdDE+cOFFVqlSRr6+vQkJCNGDAAP322295VC2Q3rp169S2bVuVKVNGNptNn3766U33Wbt2re6//355e3srLCxMc+bMueN13gk0XHDX+uijjzRw4EDFxMRo+/btioiIUMuWLXXq1KlMx2/cuFFdunRRjx49tGPHDrVv317t27fX999/n8eVA7/LbobXrl2rLl26aM2aNdq0aZNCQkLUokULHTt2LI8rB/4nuzm+LikpSYMHD9aDDz6YR5UCmctuhq9evarmzZsrKSlJn3zyiX766SfNnDlTZcuWzePKgd9lN8Pz5s3TsGHDFBMTo4SEBM2aNUsfffSR/vnPf+Zx5cDvLl++rIiICE2bNu2Wxh88eFCPPfaYmjVrpp07d+rFF1/UP/7xD61YseIOV5r7WBYad6169eqpTp06mjp1qiTJ4XAoJCRE/fr107BhwzKMj4yM1OXLl7VkyRLntvr166tWrVqKjY3Ns7qB67Kb4T+z2+0qVqyYpk6dqm7dut3pcoFM5STHdrtdTZo0Uffu3bV+/XolJyff0m+zgDshuxmOjY3V22+/rb1798rT0zOvywUyyG6G+/btq4SEBK1atcq5bdCgQdq8ebO++eabPKsbyIzNZtOiRYtuePfr0KFDtXTp0nS/OH/yySeVnJys5cuX50GVuYc7XHBXunr1qrZt26ZHH33Uuc3NzU2PPvqoNm3alOk+mzZtSjdeklq2bJnleOBOykmG/ywlJUVpaWkqXrz4nSoTuKGc5vi1115TUFCQevTokRdlAlnKSYYXL16sBg0a6Pnnn1epUqVUvXp1vfHGG7Lb7XlVNuCUkww3bNhQ27Ztcz52lJiYqGXLlql169Z5UjNwu1zp5zqP/C4AyMyZM2dkt9tVqlSpdNtLlSqlvXv3ZrrPyZMnMx1/8uTJO1YnkJWcZPjPhg4dqjJlymT4BwfIKznJ8TfffKNZs2Zp586deVAhcGM5yXBiYqJWr16trl27atmyZdq/f7/69OmjtLQ0xcTE5EXZgFNOMvzUU0/pzJkzaty4sSzL0rVr19SrVy8eKYIxsvq57sKFC0pNTZWvr28+VZZ93OECAHehsWPHKj4+XosWLZKPj09+lwPckosXLyoqKkozZ85UyZIl87scIEccDoeCgoL03nvvqXbt2oqMjNTLL7/M48kwxtq1a/XGG29o+vTp2r59uxYuXKilS5dq9OjR+V0aUOBwhwvuSiVLlpS7u7t++eWXdNt/+eUXlS5dOtN9Spcuna3xwJ2UkwxfN378eI0dO1ZfffWVataseSfLBG4ouzk+cOCAkpKS1LZtW+c2h8MhSfLw8NBPP/2k0NDQO1s08Ac5+bs4ODhYnp6ecnd3d26rVq2aTp48qatXr8rLy+uO1gz8UU4y/OqrryoqKkr/+Mc/JEk1atTQ5cuX1bNnT7388styc+N37ri7ZfVznb+/v1F3t0jc4YK7lJeXl2rXrp1usi+Hw6FVq1apQYMGme7ToEGDdOMlaeXKlVmOB+6knGRYksaNG6fRo0dr+fLleuCBB/KiVCBL2c1x1apVtWfPHu3cudP5evzxx52rDISEhORl+UCO/i5u1KiR9u/f72wWStLPP/+s4OBgmi3IcznJcEpKSoamyvUGIuulwAQu9XOdBdyl4uPjLW9vb2vOnDnWjz/+aPXs2dMqWrSodfLkScuyLCsqKsoaNmyYc/yGDRssDw8Pa/z48VZCQoIVExNjeXp6Wnv27MmvU0ABl90Mjx071vLy8rI++eQT68SJE87XxYsX8+sUgGzn+M+efvppq127dnlULZBRdjN8+PBhy8/Pz+rbt6/1008/WUuWLLGCgoKsMWPG5NcpoIDLboZjYmIsPz8/a/78+VZiYqL15ZdfWqGhoVbnzp3z6xRQwF28eNHasWOHtWPHDkuSNWHCBGvHjh3WoUOHLMuyrGHDhllRUVHO8YmJiVahQoWsIUOGWAkJCda0adMsd3d3a/ny5fl1CjnGI0W4a0VGRur06dMaMWKETp48qVq1amn58uXOCZQOHz6crnvfsGFDzZs3T6+88or++c9/Kjw8XJ9++qmqV6+eX6eAAi67GZ4xY4auXr2qjh07pjtOTEyMRo4cmZelA07ZzTFwt8luhkNCQrRixQoNGDBANWvWVNmyZdW/f38NHTo0v04BBVx2M/zKK6/IZrPplVde0bFjxxQYGKi2bdvq9ddfz69TQAG3detWNWvWzPn1wIEDJUlPP/205syZoxMnTujw4cPO9ytWrKilS5dqwIABmjRpksqVK6d///vfatmyZZ7XfrtslsV9ZQAAAAAAALmJX0kBAAAAAADkMhouAAAAAAAAuYyGCwAAAAAAQC6j4QIAAAAAAJDLaLgAAAAAAADkMhouAAAAAAAAuYyGCwAAAAAAQC6j4QIAAADjNG3aVE2bNnV+nZSUJJvNpjlz5uRbTQAA/BENFwAAUOBNnz5dNptN9erVy+9SjLJ27VrZbDbZbDZ9+OGHmY5p1KiRbDabqlevnsfVAQCQv2i4AACAAi8uLk4VKlTQli1btH///vwuxzg+Pj6aN29ehu1JSUnauHGjfHx87ngN5cuXV2pqqqKiou74ZwEAcCtouAAAgALt4MGD2rhxoyZMmKDAwEDFxcXld0lZunz5cn6XkKnWrVtr5cqVOnPmTLrt8+bNU6lSpfTAAw/c8RpsNpt8fHzk7u5+xz8LAIBbQcMFAAAUaHFxcSpWrJgee+wxdezYMcuGS3JysgYMGKAKFSrI29tb5cqVU7du3dI1GX777TeNHDlSlStXlo+Pj4KDg/XEE0/owIEDkv73CM7atWvTHTuz+Ueio6NVpEgRHThwQK1bt5afn5+6du0qSVq/fr06deqke+65R97e3goJCdGAAQOUmpqaoe69e/eqc+fOCgwMlK+vr6pUqaKXX35ZkrRmzRrZbDYtWrQow37z5s2TzWbTpk2bbnoN27VrJ29vb3388ccZjtG5c+csmyAffvihateuLV9fXxUvXlxPPvmkjhw5kmHce++9p9DQUPn6+qpu3bpav359hjGZXcPdu3crOjpalSpVko+Pj0qXLq3u3bvr7NmzNz0nAABuFw0XAABQoMXFxemJJ56Ql5eXunTpon379um7775LN+bSpUt68MEHNWXKFLVo0UKTJk1Sr169tHfvXh09elSSZLfb1aZNG40aNUq1a9fWO++8o/79++v8+fP6/vvvc1TbtWvX1LJlSwUFBWn8+PHq0KGDJOnjjz9WSkqKevfurSlTpqhly5aaMmWKunXrlm7/3bt3q169elq9erWeffZZTZo0Se3bt9fnn38u6feJZ0NCQjJtMsXFxSk0NFQNGjS4aZ2FChVSu3btNH/+fOe2Xbt26YcfftBTTz2V6T6vv/66unXrpvDwcE2YMEEvvviiVq1apSZNmig5Odk5btasWXruuedUunRpjRs3To0aNdLjjz+eaWPmz1auXKnExEQ988wzmjJlip588knFx8erdevWsizrpvsDAHBbLAAAgAJq69atliRr5cqVlmVZlsPhsMqVK2f1798/3bgRI0ZYkqyFCxdmOIbD4bAsy7Lef/99S5I1YcKELMesWbPGkmStWbMm3fsHDx60JFmzZ892bnv66actSdawYcMyHC8lJSXDtjfffNOy2WzWoUOHnNuaNGli+fn5pdv2x3osy7KGDx9ueXt7W8nJyc5tp06dsjw8PKyYmJgMn/NH18/n448/tpYsWWLZbDbr8OHDlmVZ1pAhQ6xKlSpZlmVZDz30kHXfffc590tKSrLc3d2t119/Pd3x9uzZY3l4eDi3X7161QoKCrJq1aplXblyxTnuvffesyRZDz30kHNbZtcws+s0f/58S5K1bt26G54bAAC3iztcAABAgRUXF6dSpUqpWbNmkn6fByQyMlLx8fGy2+3OcQsWLFBERIT+9re/ZTiGzWZzjilZsqT69euX5Zic6N27d4Ztvr6+zj9fvnxZZ86cUcOGDWVZlnbs2CFJOn36tNatW6fu3bvrnnvuybKebt266cqVK/rkk0+c2z766CNdu3ZNf//732+5zhYtWqh48eKKj4+XZVmKj49Xly5dMh27cOFCORwOde7cWWfOnHG+SpcurfDwcK1Zs0aStHXrVp06dUq9evWSl5eXc//o6GgFBATctKY/XqfffvtNZ86cUf369SVJ27dvv+VzAwAgJ2i4AACAAslutys+Pl7NmjXTwYMHtX//fu3fv1/16tXTL7/8olWrVjnHHjhw4KbLGh84cEBVqlSRh4dHrtXo4eGhcuXKZdh++PBhRUdHq3jx4ipSpIgCAwP10EMPSZLOnz8vSUpMTJSkm9ZdtWpV1alTJ91jRXFxcapfv77CwsJuuVZPT0916tRJ8+bN07p163TkyJEsHyfat2+fLMtSeHi4AgMD070SEhJ06tQpSdKhQ4ckSeHh4Rk+q1KlSjet6dy5c+rfv79KlSolX19fBQYGqmLFipL+d50AALhTcu9/BAAAAAZZvXq1Tpw4ofj4eMXHx2d4Py4uTi1atMjVz8zqTpc/3k3zR97e3nJzc8swtnnz5jp37pyGDh2qqlWrqnDhwjp27Jiio6PlcDiyXVe3bt3Uv39/HT16VFeuXNG3336rqVOnZvs4Tz31lGJjYzVy5EhFRETo3nvvzXScw+GQzWbTF198kemEukWKFMn2Z2emc+fO2rhxo4YMGaJatWqpSJEicjgc+utf/5qj6wQAQHbQcAEAAAVSXFycgoKCNG3atAzvLVy4UIsWLVJsbKx8fX0VGhp604lvQ0NDtXnzZqWlpcnT0zPTMcWKFZOkdJPCSv+7k+NW7NmzRz///LPmzp2bbpLclStXpht3/Q6QW5mw98knn9TAgQM1f/58paamytPTU5GRkbdc03WNGzfWPffco7Vr1+qtt97KclxoaKgsy1LFihVVuXLlLMeVL19e0u93xDz88MPO7WlpaTp48KAiIiKy3PfXX3/VqlWrNGrUKI0YMcK5fd++fdk5JQAAcoxHigAAQIGTmpqqhQsXqk2bNurYsWOGV9++fXXx4kUtXrxYktShQwft2rUr0+WTrf9f7aZDhw46c+ZMpneGXB9Tvnx5ubu7a926denenz59+i3Xfv2OEOsPq+xYlqVJkyalGxcYGKgmTZro/fff1+HDhzOt57qSJUuqVatW+vDDDxUXF6e//vWvKlmy5C3XdJ3NZtPkyZMVExOjqKioLMc98cQTcnd316hRozLUYlmWc9nmBx54QIGBgYqNjdXVq1edY+bMmZOhafVnmV0nSZo4cWI2zggAgJzjDhcAAFDgLF68WBcvXtTjjz+e6fv169dXYGCg4uLiFBkZqSFDhuiTTz5Rp06d1L17d9WuXVvnzp3T4sWLFRsbq4iICHXr1k0ffPCBBg4cqC1btujBBx/U5cuX9dVXX6lPnz5q166dAgIC1KlTJ02ZMkU2m02hoaFasmSJc86SW1G1alWFhoZq8ODBOnbsmPz9/bVgwQL9+uuvGcZOnjxZjRs31v3336+ePXuqYsWKSkpK0tKlS7Vz5850Y7t166aOHTtKkkaPHn3rF/NP2rVrp3bt2t1wTGhoqMaMGaPhw4crKSlJ7du3l5+fnw4ePKhFixapZ8+eGjx4sDw9PTVmzBg999xzevjhhxUZGamDBw9q9uzZN53Dxd/fX02aNNG4ceOUlpamsmXL6ssvv9TBgwdzfG4AAGQHDRcAAFDgxMXFycfHR82bN8/0fTc3Nz322GOKi4vT2bNnVaJECa1fv14xMTFatGiR5s6dq6CgID3yyCPOSW3d3d21bNkyvf7665o3b54WLFigEiVKqHHjxqpRo4bz2FOmTFFaWppiY2Pl7e2tzp076+23377p5LbXeXp66vPPP9cLL7ygN998Uz4+Pvrb3/6mvn37ZnjEJiIiQt9++61effVVzZgxQ7/99pvKly+vzp07Zzhu27ZtVaxYMTkcjiwbUblp2LBhqly5sv71r39p1KhRkqSQkBC1aNEi3ef37NlTdrtdb7/9toYMGaIaNWpo8eLFevXVV2/6GfPmzVO/fv00bdo0WZalFi1a6IsvvlCZMmXu2HkBAHCdzfrzfZYAAAAocK5du6YyZcqobdu2mjVrVn6XAwCA8ZjDBQAAAPr00091+vTpdBPxAgCAnOMOFwAAgAJs8+bN2r17t0aPHq2SJUtq+/bt+V0SAAAugTtcAAAACrAZM2aod+/eCgoK0gcffJDf5QAA4DK4wwUAAAAAACCXcYcLAAAAAABALqPhAgAAAAAAkMtouAAAAAAAAOQyGi4AAAAAAAC5jIYLAAAAAABALqPhAgAAAAAAkMtouAAAAAAAAOQyGi4AAAAAAAC5jIYLAAAAAABALvs/KNHxFfFg+p0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.999038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.993650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.993458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.993073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.908986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.771407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Modelo  Accuracy Media\n",
       "2        Decision Tree        1.000000\n",
       "5    Gradient Boosting        1.000000\n",
       "8             LightGBM        0.999038\n",
       "0  Logistic Regression        0.993650\n",
       "3        Random Forest        0.993458\n",
       "1                  SVC        0.993073\n",
       "4                  KNN        0.908986\n",
       "6             AdaBoost        0.771407\n",
       "7              XGBoost            -inf\n",
       "9             CatBoost             NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelos_clasificacion(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACION DE MODELOS DE REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelos_regresion(X_train_scaled, y_train):\n",
    "    \"\"\"\n",
    "    Entrena y eval√∫a m√∫ltiples modelos de regresi√≥n utilizando validaci√≥n cruzada.\n",
    "    \"\"\"\n",
    "    model_names = [\n",
    "        \"Linear Regression\", \"Ridge\", \"Lasso\", \"SVR\", \"Decision Tree\", \"Random Forest\", \n",
    "        \"KNN\", \"Gradient Boosting\", \"AdaBoost\", \"XGBoost\", \"LightGBM\", \"CatBoost\"\n",
    "    ]\n",
    "    model_set = [\n",
    "        LinearRegression(),\n",
    "        Ridge(alpha=1.0),\n",
    "        Lasso(alpha=0.1),\n",
    "        SVR(),\n",
    "        DecisionTreeRegressor(random_state=42),\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        KNeighborsRegressor(),\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        AdaBoostRegressor(random_state=42),\n",
    "        XGBRegressor(random_state=42, eval_metric=\"rmse\"),\n",
    "        LGBMRegressor(random_state=42, verbose=-100),\n",
    "        CatBoostRegressor(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    ]\n",
    "    metricas_cv = {}\n",
    "    valores = []\n",
    "    for nombre, modelo in zip(model_names, model_set):\n",
    "        print(f\"Evaluando modelo: {nombre}...\")\n",
    "        try:\n",
    "            scores = cross_val_score(modelo, X_train_scaled, y_train, cv=3, scoring=\"r2\", n_jobs=-1)\n",
    "            metricas_cv[nombre] = scores\n",
    "            valores.append(np.mean(scores))\n",
    "        except Exception as e:\n",
    "            print(f\"Error con el modelo {nombre}: {e}\")\n",
    "            metricas_cv[nombre] = None\n",
    "            valores.append(-np.inf)\n",
    "    ganador = model_names[np.argmax(valores)]\n",
    "    print(f\"\\nEl modelo ganador es: {ganador} con un R^2 medio de {np.max(valores):.4f}\\n\")\n",
    "    resultados_df = pd.DataFrame({\n",
    "        \"Modelo\": model_names,\n",
    "        \"R^2 Medio\": valores\n",
    "    }).sort_values(by=\"R^2 Medio\", ascending=False)\n",
    "    print(resultados_df)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=\"R^2 Medio\", y=\"Modelo\", data=resultados_df, palette=\"viridis\", hue=None)\n",
    "    plt.title(\"Comparaci√≥n de Modelos de Regresi√≥n - R^2 Medio\", fontsize=16)\n",
    "    plt.xlabel(\"R^2 Medio\", fontsize=12)\n",
    "    plt.ylabel(\"Modelos\", fontsize=12)\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARGUMENTOS A METER EN EL PIPELINE: TIPO_MODELO, CV, TOP_N (numero de modelos a los que quiero ahcer grid search) (podr√≠amos tbn hacer una √∫ltima funci√≥n que hicera un grid_search mas extenso del ganador, con param_grids mas largos y cv mayor) (podriamos a√±adir alguna forma de obviar esta funci√≥n y ir directamente a la √∫ltima del grid_search largo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se si cambiaria la metrica de la regresion al rmse, mse o mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entiendo algunos parametros de XGBoost y CatBoost: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\") \n",
    "\"CatBoost\": CatBoostClassifier(random_state=42, verbose=False, train_dir='./catboost_temp_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def top_grid_search(df_resultados, X_train, y_train, tipo_modelo=\"clasificacion\", top_n=3, cv=5):\n",
    "    \"\"\"\n",
    "    Extrae los n mejores modelos obtenidos en cross-validation, les realiza GridSearchCV y devuelve el mejor modelo optimizado.\n",
    "\n",
    "    Parametros:\n",
    "    - df_resultados: DataFrame con los modelos y sus metricas.\n",
    "    - X_train, y_train: Datos de entrenamiento.\n",
    "    - tipo_modelo: \"clasificacion\" o \"regresion\".\n",
    "    - top_n: Numero de mejores modelos a seleccionar para el GridSearch.\n",
    "    - cv: N√∫mero de folds para la validaci√≥n cruzada.\n",
    "\n",
    "    DEvuelve el nombre del mejor modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    metrica = \"Accuracy Media\" if tipo_modelo == \"clasificacion\" else \"R^2 Medio\"\n",
    "\n",
    "    modelos_clf = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "        \"SVC\": SVC(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        \"LightGBM\": LGBMClassifier(random_state=42, verbose=-100),\n",
    "        \"CatBoost\": CatBoostClassifier(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    }\n",
    "\n",
    "    modelos_reg = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"Lasso\": Lasso(alpha=0.1),\n",
    "        \"SVR\": SVR(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"KNN\": KNeighborsRegressor(),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "        \"AdaBoost\": AdaBoostRegressor(random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42, eval_metric=\"rmse\"),\n",
    "        \"LightGBM\": LGBMRegressor(random_state=42, verbose=-100),\n",
    "        \"CatBoost\": CatBoostRegressor(random_state=42, verbose=False, train_dir='./catboost_temp_fix')\n",
    "    }\n",
    "\n",
    "    param_grids_clf = {\n",
    "        \"Logistic Regression\": {\"C\": [0.01, 0.1, 1, 10, 100], \"solver\": [\"liblinear\", \"lbfgs\"]},\n",
    "        \"SVC\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]},\n",
    "        \"Decision Tree\": {\"max_depth\": [3, 5, 10, None], \"min_samples_split\": [2, 5, 10], \"min_samples_leaf\": [1, 2, 5]},\n",
    "        \"Random Forest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, None], \"min_samples_split\": [2, 5, 10]},\n",
    "        \"KNN\": {\"n_neighbors\": [3, 5, 10], \"weights\": [\"uniform\", \"distance\"]},\n",
    "        \"Gradient Boosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2], \"max_depth\": [3, 5, 7]},\n",
    "        \"AdaBoost\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "        \"XGBoost\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"LightGBM\": {\"n_estimators\": [50, 100, 200], \"num_leaves\": [31, 50, 100], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"CatBoost\": {\"iterations\": [50, 100, 200], \"depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]}\n",
    "    }\n",
    "\n",
    "    param_grids_reg = {\n",
    "        \"Linear Regression\": {},\n",
    "        \"Ridge\": {\"alpha\": [0.01, 0.1, 1, 10, 100]},\n",
    "        \"Lasso\": {\"alpha\": [0.01, 0.1, 1, 10, 100]},\n",
    "        \"SVR\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]},\n",
    "        \"Decision Tree\": {\"max_depth\": [3, 5, 10, None], \"min_samples_split\": [2, 5, 10], \"min_samples_leaf\": [1, 2, 5]},\n",
    "        \"Random Forest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, None], \"min_samples_split\": [2, 5, 10]},\n",
    "        \"KNN\": {\"n_neighbors\": [3, 5, 10], \"weights\": [\"uniform\", \"distance\"]},\n",
    "        \"Gradient Boosting\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2], \"max_depth\": [3, 5, 7]},\n",
    "        \"AdaBoost\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 1]},\n",
    "        \"XGBoost\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"LightGBM\": {\"n_estimators\": [50, 100, 200], \"num_leaves\": [31, 50, 100], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
    "        \"CatBoost\": {\"iterations\": [50, 100, 200], \"depth\": [3, 5, 7], \"learning_rate\": [0.01, 0.1, 0.2]}\n",
    "    }\n",
    "\n",
    "    modelos = modelos_clf if tipo_modelo == \"clasificacion\" else modelos_reg\n",
    "    param_grids = param_grids_clf if tipo_modelo == \"clasificacion\" else param_grids_reg\n",
    "\n",
    "    top_modelos = df_resultados.nlargest(top_n, metrica)[\"Modelo\"].values\n",
    "\n",
    "    for i, modelo_nombre in enumerate(top_modelos):\n",
    "        modelo = modelos[modelo_nombre]\n",
    "        param_grid = param_grids[modelo_nombre]\n",
    "\n",
    "        grid_search = GridSearchCV(modelo, param_grid, cv=cv, scoring=\"accuracy\" if tipo_modelo == \"clasificacion\" else \"r2\", n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        if i == 0 or grid_search.best_score_ > mejor_puntaje:\n",
    "            mejor_modelo = modelo_nombre\n",
    "            mejor_puntaje = grid_search.best_score_\n",
    "            mejor_params = grid_search.best_params_\n",
    "\n",
    "    print(mejor_modelo)\n",
    "    print(mejor_puntaje)\n",
    "    print(mejor_params)\n",
    "\n",
    "    return mejor_modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
