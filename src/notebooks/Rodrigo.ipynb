{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../utils/\")\n",
    "import Toolbox as tb\n",
    "from Toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "data = pd.read_csv(\"../data/wines_dataset.csv\", sep=\"|\")\n",
    "\n",
    "\"\"\"\n",
    "División de datos en entrenamiento y prueba.\n",
    "\n",
    "Se toma el 80% de los datos para entrenamiento y el 20% restante para prueba.\n",
    "\n",
    "Parámetros:\n",
    "- test_size (float): Proporción del conjunto de prueba (0.2 = 20% de los datos).\n",
    "- random_state (int): Semilla para la reproducibilidad de la división.\n",
    "\n",
    "Salida:\n",
    "- train (DataFrame): Conjunto de entrenamiento.\n",
    "- test (DataFrame): Conjunto de prueba.\n",
    "\"\"\"\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "Guardado de los conjuntos de datos en archivos CSV.\n",
    "\n",
    "Los archivos se almacenan en la carpeta \"../data/\" con los nombres:\n",
    "- wines_train.csv → Contiene el 80% de los datos para entrenamiento.\n",
    "- wines_test.csv → Contiene el 20% de los datos para prueba.\n",
    "\n",
    "index=False evita que se guarde el índice en los archivos.\n",
    "\"\"\"\n",
    "train.to_csv(os.path.join(\"../data/\", 'wines_train.csv'), index=False)\n",
    "test.to_csv(os.path.join(\"../data/\", 'wines_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos de entrenamiento desde el archivo CSV\n",
    "df = pd.read_csv(\"../data/wines_train.csv\")\n",
    "y_train_cat = df[\"quality\"]\n",
    "y_train_reg = df[\"alcohol\"]\n",
    "# Mostrar el DataFrame cargado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.049</td>\n",
       "      <td>38.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99335</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.034</td>\n",
       "      <td>29.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99031</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.026</td>\n",
       "      <td>43.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99040</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.038</td>\n",
       "      <td>58.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.98930</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.063</td>\n",
       "      <td>32.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>11.6</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.147</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99836</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.052</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99458</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.073</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99425</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.036</td>\n",
       "      <td>38.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.99622</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.320         0.27             1.4      0.049   \n",
       "1               6.6             0.340         0.24             3.3      0.034   \n",
       "2               6.4             0.320         0.35             4.8      0.030   \n",
       "3               6.8             0.230         0.32             1.6      0.026   \n",
       "4               6.7             0.340         0.26             1.9      0.038   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1295            7.6             0.285         0.32            14.6      0.063   \n",
       "1296           11.6             0.470         0.44             1.6      0.147   \n",
       "1297           10.2             0.340         0.48             2.1      0.052   \n",
       "1298            6.2             0.460         0.17             1.6      0.073   \n",
       "1299            6.2             0.360         0.14             8.9      0.036   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    38.0                 173.0  0.99335  3.03       0.52   \n",
       "1                    29.0                  99.0  0.99031  3.10       0.40   \n",
       "2                    34.0                 101.0  0.99120  3.36       0.60   \n",
       "3                    43.0                 147.0  0.99040  3.29       0.54   \n",
       "4                    58.0                 138.0  0.98930  3.00       0.47   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1295                 32.0                 201.0  0.99800  3.00       0.45   \n",
       "1296                 36.0                  51.0  0.99836  3.38       0.86   \n",
       "1297                  5.0                   9.0  0.99458  3.20       0.69   \n",
       "1298                  7.0                  11.0  0.99425  3.61       0.54   \n",
       "1299                 38.0                 155.0  0.99622  3.27       0.50   \n",
       "\n",
       "      alcohol  quality  class  \n",
       "0         9.3        5  white  \n",
       "1        12.3        7  white  \n",
       "2        12.5        8  white  \n",
       "3        12.5        6  white  \n",
       "4        12.2        7  white  \n",
       "...       ...      ...    ...  \n",
       "1295      9.2        5  white  \n",
       "1296      9.9        4    red  \n",
       "1297     12.1        7    red  \n",
       "1298     11.4        5    red  \n",
       "1299      9.4        5  white  \n",
       "\n",
       "[1300 rows x 13 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos de prueba desde el archivo CSV\n",
    "df_test = pd.read_csv(\"../data/wines_test.csv\")\n",
    "y_test = df_test[\"quality\"]\n",
    "# Mostrar el DataFrame cargado\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COL_N</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>100</td>\n",
       "      <td>177</td>\n",
       "      <td>87</td>\n",
       "      <td>308</td>\n",
       "      <td>194</td>\n",
       "      <td>132</td>\n",
       "      <td>274</td>\n",
       "      <td>951</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COL_N         fixed acidity volatile acidity citric acid residual sugar  \\\n",
       "DATA_TYPE           float64          float64     float64        float64   \n",
       "MISSINGS (%)            0.0              0.0         0.0            0.0   \n",
       "UNIQUE_VALUES           100              177          87            308   \n",
       "CARDIN (%)             0.02             0.03        0.02           0.06   \n",
       "\n",
       "COL_N         chlorides free sulfur dioxide total sulfur dioxide  density  \\\n",
       "DATA_TYPE       float64             float64              float64  float64   \n",
       "MISSINGS (%)        0.0                 0.0                  0.0      0.0   \n",
       "UNIQUE_VALUES       194                 132                  274      951   \n",
       "CARDIN (%)         0.04                0.03                 0.05     0.18   \n",
       "\n",
       "COL_N               pH sulphates  alcohol quality   class  \n",
       "DATA_TYPE      float64   float64  float64   int64  object  \n",
       "MISSINGS (%)       0.0       0.0      0.0     0.0     0.0  \n",
       "UNIQUE_VALUES      106       106      102       7       2  \n",
       "CARDIN (%)        0.02      0.02     0.02     0.0     0.0  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Genera un resumen descriptivo del DataFrame utilizando la función tb.describe_df(df).\n",
    "# \n",
    "#  Muestra información sobre:\n",
    "#    - DATA_TYPE: Tipo de dato de cada columna (numérico, categórico, etc.).\n",
    "#    - MISSINGS (%): Porcentaje de valores nulos en cada columna.\n",
    "#    - UNIQUE_VALUES: Cantidad de valores únicos en cada columna.\n",
    "#    - CARDIN (%): Cardinalidad relativa (valores únicos / total de filas).\n",
    "# \n",
    "# Útil para comprender la estructura de los datos antes del preprocesamiento.\n",
    "\n",
    "tb.describe_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variables objetivo para el análisis:\n",
    "\n",
    "# target_clf = \"quality\" → Problema de Clasificación\n",
    "#    - La variable `quality` representa la calidad del vino.\n",
    "#    - Es una variable categórica con 7 valores únicos (multiclase).\n",
    "#    - Se utilizarán modelos de clasificación, como RandomForestClassifier o XGBoost.\n",
    "#    - Es necesario aplicar OneHotEncoder a variables categóricas y StandardScaler a las numéricas.\n",
    "\n",
    "# target_reg = \"alcohol\" → Problema de Regresión\n",
    "#    - La variable `alcohol` indica el porcentaje de alcohol en el vino.\n",
    "#    - Es una variable numérica continua.\n",
    "#    - Se utilizarán modelos de regresión, como RandomForestRegressor o LinearRegression.\n",
    "#    - Requiere escalado de las variables numéricas (StandardScaler) y codificación de las categóricas (OneHotEncoder).\n",
    "\n",
    "# 📌 Ambos problemas requieren preprocesamiento adecuado según el tipo de modelo utilizado.\n",
    "\n",
    "target_clf = \"quality\"\n",
    "target_reg = \"alcohol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las características (features) utilizadas en la clasificación:\n",
    "\n",
    "# features_cat_clf → Variables categóricas\n",
    "#    - Contiene solo la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables numéricas.\n",
    "\n",
    "# features_num_clf_1 → Variables numéricas principales\n",
    "#    - Incluye medidas químicas clave como \"volatile acidity\", \"chlorides\", \"density\", \"pH\", etc.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas características.\n",
    "\n",
    "# features_num_clf_2 → Variables numéricas adicionales\n",
    "#    - Contiene \"fixed acidity\" y \"residual sugar\".\n",
    "#    - Estas características pueden ser analizadas por separado o combinadas con las anteriores.\n",
    "\n",
    "features_cat_clf = [\"class\"]\n",
    "features_num_clf_1 = [\"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "                      \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]\n",
    "features_num_clf_2 = [\"fixed acidity\", \"residual sugar\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de características (features) para el problema de regresión:\n",
    "\n",
    "# features_cat_reg → Variables categóricas\n",
    "#    - Contiene \"class\" (tipo de vino: tinto o blanco) y \"quality\" (calidad del vino).\n",
    "#    - Estas variables deben ser transformadas con OneHotEncoder.\n",
    "\n",
    "# features_num_reg → Variables numéricas\n",
    "#    - Se seleccionan todas las columnas del DataFrame excepto las categóricas.\n",
    "#    - Esto se logra con una lista por comprensión, excluyendo las columnas en features_cat_reg.\n",
    "#    - Estas variables deben ser escaladas con StandardScaler.\n",
    "\n",
    "features_cat_reg = [\"class\", \"quality\"]\n",
    "features_num_reg = [col for col in df.columns if col not in features_cat_reg]\n",
    "\n",
    "# Ahora features_num_reg contiene solo las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                 1.000000\n",
       "density                 0.682345\n",
       "residual sugar          0.357459\n",
       "total sulfur dioxide    0.272970\n",
       "chlorides               0.260508\n",
       "free sulfur dioxide     0.188460\n",
       "pH                      0.116497\n",
       "fixed acidity           0.091964\n",
       "volatile acidity        0.036041\n",
       "citric acid             0.005690\n",
       "sulphates               0.000412\n",
       "Name: alcohol, dtype: float64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudio de correlaciones entre las variables numéricas y la variable objetivo de regresión.\n",
    "\n",
    "# Calculamos la matriz de correlación solo para las variables numéricas.\n",
    "#    - Se utiliza df[features_num_reg] para excluir las variables categóricas.\n",
    "#    - numeric_only=\"True\" se usa para evitar advertencias en versiones recientes de pandas.\n",
    "\n",
    "# Extraemos la correlación absoluta de cada variable con el target de regresión (\"alcohol\").\n",
    "#    - np.abs() se usa para obtener la magnitud de la correlación sin importar el signo.\n",
    "#    - .sort_values(ascending=False) ordena las variables de mayor a menor correlación.\n",
    "\n",
    "corr = df[features_num_reg].corr(numeric_only=\"True\")\n",
    "serie_corr = np.abs(corr[target_reg]).sort_values(ascending=False)\n",
    "serie_corr\n",
    "\n",
    "# Ahora, serie_corr contiene las variables ordenadas según su grado de correlación con \"alcohol\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características numéricas basadas en la correlación con el target de regresión.\n",
    "\n",
    "# Definimos un umbral mínimo de correlación.\n",
    "#    - r_min = 0.05 significa que solo seleccionaremos variables con correlación mayor a 0.05.\n",
    "\n",
    "r_min = 0.05\n",
    "\n",
    "# Seleccionamos las variables numéricas con correlación significativa con el target.\n",
    "#    - Tomamos solo las variables con correlación absoluta mayor que r_min.\n",
    "#    - Convertimos los nombres de las columnas en una lista.\n",
    "#    - Eliminamos el target (\"alcohol\") de la lista, ya que no es una feature.\n",
    "\n",
    "features_num_reg_1 = serie_corr[serie_corr > r_min].index.to_list()\n",
    "features_num_reg_1.remove(target_reg)\n",
    "\n",
    "# Identificamos las variables numéricas con correlación baja o nula con el target.\n",
    "#    - Excluimos las variables en features_num_reg_1.\n",
    "#    - Excluimos el target y las variables categóricas.\n",
    "\n",
    "features_num_reg_2 = [col for col in df.columns if col not in features_num_reg_1 and col != target_reg\n",
    "                       and col not in features_cat_reg]\n",
    "\n",
    "# Ahora:\n",
    "# - features_num_reg_1 contiene las variables más correlacionadas con \"alcohol\".\n",
    "# - features_num_reg_2 contiene las variables menos correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quality'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición del problema de clasificación.\n",
    "\n",
    "# target_clf → Variable objetivo para clasificación.\n",
    "#    - Se ha definido previamente como \"quality\".\n",
    "#    - Representa la calidad del vino en una escala categórica.\n",
    "#    - Es un problema de clasificación **multiclase** (7 categorías posibles).\n",
    "\n",
    "target_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de las características categóricas para el problema de clasificación.\n",
    "\n",
    "# features_cat_clf → Variables categóricas a incluir en el modelo de clasificación.\n",
    "#    - Contiene la variable \"class\" (tipo de vino: tinto o blanco).\n",
    "#    - Se debe transformar con OneHotEncoder para convertirla en variables numéricas.\n",
    "\n",
    "features_cat_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity',\n",
       " 'citric acid',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de características numéricas principales para clasificación.\n",
    "\n",
    "# features_num_clf_1 → Variables numéricas seleccionadas para el modelo de clasificación.\n",
    "#    - Incluye medidas químicas clave del vino:\n",
    "#      - \"volatile acidity\", \"citric acid\", \"chlorides\", \"free sulfur dioxide\",\n",
    "#      - \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\".\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas características antes del modelado.\n",
    "\n",
    "features_num_clf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alcohol'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición del problema de regresión.\n",
    "\n",
    "# target_reg → Variable objetivo para regresión.\n",
    "#    - Se ha definido previamente como \"alcohol\".\n",
    "#    - Representa el porcentaje de alcohol en el vino (variable continua).\n",
    "#    - Es un problema de regresión, ya que el target es numérico y continuo.\n",
    "\n",
    "target_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'quality']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de las características categóricas para el problema de regresión.\n",
    "\n",
    "# features_cat_reg → Variables categóricas a incluir en el modelo de regresión.\n",
    "#    - Contiene:\n",
    "#      - \"class\" (tipo de vino: tinto o blanco).\n",
    "#      - \"quality\" (calidad del vino en una escala categórica).\n",
    "#    - Ambas variables deben ser transformadas con OneHotEncoder para su uso en modelos numéricos.\n",
    "\n",
    "features_cat_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'residual sugar',\n",
       " 'total sulfur dioxide',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'fixed acidity']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de características numéricas principales para regresión.\n",
    "\n",
    "# features_num_reg_1 → Variables numéricas con mayor correlación con el target de regresión (\"alcohol\").\n",
    "#    - Se han seleccionado aquellas con correlación absoluta > r_min (0.05).\n",
    "#    - Estas variables son las más relevantes para predecir el contenido de alcohol en el vino.\n",
    "#    - Se recomienda aplicar StandardScaler para normalizar estas características antes del modelado.\n",
    "\n",
    "features_num_reg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity', 'residual sugar', 'quality', 'quality']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definición de columnas a incluir y excluir en el modelo de clasificación.\n",
    "\n",
    "# columns_to_keep_clf → Columnas que se mantendrán en el modelo de clasificación.\n",
    "#    - Incluye:\n",
    "#      - target_clf (variable objetivo de clasificación: \"quality\").\n",
    "#      - features_num_clf_1 (variables numéricas relevantes).\n",
    "#      - features_cat_clf (variables categóricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_clf → Columnas que se excluirán del modelo de clasificación.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_clf.\n",
    "#    - Estas columnas no serán utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_clf =   features_num_clf_1 + features_cat_clf\n",
    "\n",
    "columns_to_exclude_clf = [col for col in df.columns if col not in columns_to_keep_clf] + [target_clf] \n",
    "\n",
    "columns_to_exclude_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity', 'citric acid', 'sulphates', 'alcohol']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de columnas a incluir y excluir en el modelo de regresión.\n",
    "\n",
    "# columns_to_keep_reg → Columnas que se mantendrán en el modelo de regresión.\n",
    "#    - Incluye:\n",
    "#      - target_reg (variable objetivo de regresión: \"alcohol\").\n",
    "#      - features_num_reg_1 (variables numéricas más correlacionadas con el target).\n",
    "#      - features_cat_reg (variables categóricas a transformar con OneHotEncoder).\n",
    "\n",
    "# columns_to_exclude_reg → Columnas que se excluirán del modelo de regresión.\n",
    "#    - Se obtienen eliminando de df.columns las variables incluidas en columns_to_keep_reg.\n",
    "#    - Estas columnas no serán utilizadas en el modelo.\n",
    "\n",
    "columns_to_keep_reg = features_num_reg_1 + features_cat_reg\n",
    "\n",
    "columns_to_exclude_reg = [col for col in df.columns if col not in columns_to_keep_reg]\n",
    "\n",
    "columns_to_exclude_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definición de Pipelines para preprocesamiento de datos en clasificación.\n",
    "\n",
    "# cat_pipeline → Preprocesamiento de variables categóricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor más frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categorías desconocidas.\n",
    "\n",
    "# logaritmica → Transformación logarítmica de variables numéricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las características.\n",
    "\n",
    "# num_pipeline → Preprocesamiento de variables numéricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformación logarítmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables numéricas.\n",
    "\n",
    "# imputer_step_cat → ColumnTransformer para aplicar los Pipelines según el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_clf_1 (variables numéricas).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_clf (variables categóricas).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_clf.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_cat → Pipeline final que aplica el ColumnTransformer imputer_step_cat.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputación con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categorías desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") # Esto le indica al Pipeline que el número de características no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_cat = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_clf_1), # feature_numericas seleccionadas para clasificación\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_clf), # feature_categoriacas seleccionadas para regresión\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_clf)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_cat = Pipeline([(\"first_stage\", imputer_step_cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Definición de Pipelines para preprocesamiento de datos en regresión.\n",
    "\n",
    "# cat_pipeline → Preprocesamiento de variables categóricas.\n",
    "#    - \"Impute_Mode\": Imputa valores faltantes con la moda (valor más frecuente).\n",
    "#    - \"OHEncoder\": Aplica OneHotEncoder, ignorando categorías desconocidas.\n",
    "\n",
    "# logaritmica → Transformación logarítmica de variables numéricas.\n",
    "#    - Usa FunctionTransformer con np.log1p para estabilizar distribuciones sesgadas.\n",
    "#    - feature_names_out=\"one-to-one\" mantiene los nombres originales de las características.\n",
    "\n",
    "# num_pipeline → Preprocesamiento de variables numéricas.\n",
    "#    - \"Impute_Mean\": Imputa valores faltantes con la media.\n",
    "#    - \"logaritmo\": Aplica la transformación logarítmica definida antes.\n",
    "#    - \"SScaler\": Aplica StandardScaler para normalizar las variables numéricas.\n",
    "\n",
    "# imputer_step_reg → ColumnTransformer para aplicar los Pipelines según el tipo de variable.\n",
    "#    - \"Process_Numeric\": Aplica num_pipeline a features_num_reg_1 (variables numéricas seleccionadas para regresión).\n",
    "#    - \"Process_Categorical\": Aplica cat_pipeline a features_cat_reg (variables categóricas seleccionadas para regresión).\n",
    "#    - \"Exclude\": Elimina las columnas en columns_to_exclude_reg.\n",
    "#    - remainder=\"passthrough\": Mantiene cualquier otra columna sin modificar.\n",
    "\n",
    "# pipe_missings_reg → Pipeline final que aplica el ColumnTransformer imputer_step_reg.\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"Impute_Mode\", SimpleImputer(strategy=\"most_frequent\")),  # Imputación con la moda\n",
    "     (\"OHEncoder\", OneHotEncoder(handle_unknown='ignore'))  # Manejar categorías desconocidas\n",
    "    ]\n",
    ")\n",
    "\n",
    "logaritmica = FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\") # Esto le indica al Pipeline que el número de características no cambia y que puede usar los nombres originales.\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"Impute_Mean\", SimpleImputer(strategy = \"mean\")), # prevision que en el futuro lleguen datos faltantes\n",
    "     (\"logaritmo\", logaritmica),\n",
    "     (\"SScaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_step_reg = ColumnTransformer(\n",
    "    [(\"Process_Numeric\", num_pipeline,features_num_reg_1), # feature_numericas seleccionadas para clasificación\n",
    "     (\"Process_Categorical\", cat_pipeline, features_cat_reg), # feature_categoriacas seleccionadas para regresión\n",
    "     (\"Exclude\", \"drop\", columns_to_exclude_reg)\n",
    "    ], remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "pipe_missings_reg = Pipeline([(\"first_stage\", imputer_step_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06561088, -0.27783928, -0.1913355 , ..., -1.03455179,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.061259  , -0.49980343, -0.57998343, ...,  1.48951019,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.06561088,  0.2893635 , -0.68457525, ...,  1.63689007,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 0.061259  ,  1.14300849, -0.11427313, ...,  1.33989719,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.78484693, -1.03933617,  0.41908799, ...,  0.79764424,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.18624926, -1.28052007, -0.52783916, ..., -0.93914749,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicación del pipeline de preprocesamiento a los datos de prueba.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df_test)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificación.\n",
    "#    - Imputa valores faltantes en variables numéricas y categóricas.\n",
    "#    - Transforma variables categóricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformación logarítmica a las variables numéricas.\n",
    "\n",
    "# pipe_df_test → Contiene los datos de prueba preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df_test = pipe_missings_cat.fit_transform(df_test)\n",
    "\n",
    "pipe_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05515355,  0.59288805, -0.20549433, ...,  0.72017181,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.05515355,  2.5608768 , -0.37024226, ..., -1.3127524 ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.11199789, -0.50565223, -0.5026097 , ...,  0.31263542,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.90744764,  0.46264335, -0.10702207, ...,  0.47768498,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.5098244 , -0.14782501, -0.7688788 , ...,  1.99147821,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.05515355, -0.21826777, -0.53578111, ...,  0.72017181,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicación del pipeline de preprocesamiento a los datos de entrenamiento.\n",
    "\n",
    "# pipe_missings_cat.fit_transform(df)\n",
    "#    - Aplica el pipeline de preprocesamiento definido para clasificación.\n",
    "#    - Imputa valores faltantes en variables numéricas y categóricas.\n",
    "#    - Transforma variables categóricas con OneHotEncoder.\n",
    "#    - Aplica escalado y transformación logarítmica a las variables numéricas.\n",
    "\n",
    "# pipe_df → Contiene los datos de entrenamiento preprocesados y listos para el modelo.\n",
    "\n",
    "pipe_df = pipe_missings_cat.fit_transform(df)\n",
    "pipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>0.592888</td>\n",
       "      <td>-0.205494</td>\n",
       "      <td>0.603446</td>\n",
       "      <td>-0.505241</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.706744</td>\n",
       "      <td>2.584726</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>2.560877</td>\n",
       "      <td>-0.370242</td>\n",
       "      <td>0.820606</td>\n",
       "      <td>0.855001</td>\n",
       "      <td>1.621578</td>\n",
       "      <td>1.011233</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>-1.312752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.111998</td>\n",
       "      <td>-0.505652</td>\n",
       "      <td>-0.502610</td>\n",
       "      <td>-1.317236</td>\n",
       "      <td>0.112504</td>\n",
       "      <td>-0.901360</td>\n",
       "      <td>-1.066182</td>\n",
       "      <td>-1.830435</td>\n",
       "      <td>0.312635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.548692</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.074260</td>\n",
       "      <td>0.564028</td>\n",
       "      <td>0.448623</td>\n",
       "      <td>0.059153</td>\n",
       "      <td>-1.000780</td>\n",
       "      <td>-0.177558</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320822</td>\n",
       "      <td>0.657314</td>\n",
       "      <td>1.525362</td>\n",
       "      <td>-2.003136</td>\n",
       "      <td>-3.095378</td>\n",
       "      <td>0.440977</td>\n",
       "      <td>-0.547423</td>\n",
       "      <td>0.391872</td>\n",
       "      <td>1.187890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>-0.619281</td>\n",
       "      <td>1.217401</td>\n",
       "      <td>-0.271299</td>\n",
       "      <td>1.282255</td>\n",
       "      <td>1.111562</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>-0.228277</td>\n",
       "      <td>0.322290</td>\n",
       "      <td>-1.022479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>-0.762183</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>0.089083</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>0.371746</td>\n",
       "      <td>1.276901</td>\n",
       "      <td>1.431729</td>\n",
       "      <td>-0.549087</td>\n",
       "      <td>-0.927596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>-0.907448</td>\n",
       "      <td>0.462643</td>\n",
       "      <td>-0.107022</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.581225</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>0.645425</td>\n",
       "      <td>0.252264</td>\n",
       "      <td>0.477685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0.509824</td>\n",
       "      <td>-0.147825</td>\n",
       "      <td>-0.768879</td>\n",
       "      <td>0.045414</td>\n",
       "      <td>-0.365924</td>\n",
       "      <td>-1.936549</td>\n",
       "      <td>-1.662178</td>\n",
       "      <td>-1.332210</td>\n",
       "      <td>1.991478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>-1.055154</td>\n",
       "      <td>-0.218268</td>\n",
       "      <td>-0.535781</td>\n",
       "      <td>1.010544</td>\n",
       "      <td>0.521557</td>\n",
       "      <td>-1.017779</td>\n",
       "      <td>-0.355475</td>\n",
       "      <td>-0.624929</td>\n",
       "      <td>0.720172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -1.055154                      0.592888   \n",
       "1                             -1.055154                      2.560877   \n",
       "2                              1.111998                     -0.505652   \n",
       "3                             -0.548692                     -0.218268   \n",
       "4                              0.320822                      0.657314   \n",
       "...                                 ...                           ...   \n",
       "5192                          -0.619281                      1.217401   \n",
       "5193                          -0.762183                     -0.218268   \n",
       "5194                          -0.907448                      0.462643   \n",
       "5195                           0.509824                     -0.147825   \n",
       "5196                          -1.055154                     -0.218268   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.205494                              0.603446   \n",
       "1                      -0.370242                              0.820606   \n",
       "2                      -0.502610                             -1.317236   \n",
       "3                      -0.074260                              0.564028   \n",
       "4                       1.525362                             -2.003136   \n",
       "...                          ...                                   ...   \n",
       "5192                   -0.271299                              1.282255   \n",
       "5193                    0.089083                             -0.011858   \n",
       "5194                   -0.107022                              0.255061   \n",
       "5195                   -0.768879                              0.045414   \n",
       "5196                   -0.535781                              1.010544   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                 -0.505241                  0.427700   \n",
       "1                                  0.855001                  1.621578   \n",
       "2                                  0.112504                 -0.901360   \n",
       "3                                  0.448623                  0.059153   \n",
       "4                                 -3.095378                  0.440977   \n",
       "...                                     ...                       ...   \n",
       "5192                               1.111562                  0.626829   \n",
       "5193                               0.371746                  1.276901   \n",
       "5194                               0.581225                 -0.003952   \n",
       "5195                              -0.365924                 -1.936549   \n",
       "5196                               0.521557                 -1.017779   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0                0.706744                    2.584726   \n",
       "1                1.011233                    0.998990   \n",
       "2               -1.066182                   -1.830435   \n",
       "3               -1.000780                   -0.177558   \n",
       "4               -0.547423                    0.391872   \n",
       "...                   ...                         ...   \n",
       "5192            -0.228277                    0.322290   \n",
       "5193             1.431729                   -0.549087   \n",
       "5194             0.645425                    0.252264   \n",
       "5195            -1.662178                   -1.332210   \n",
       "5196            -0.355475                   -0.624929   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                     0.720172                             1.0   \n",
       "1                    -1.312752                             0.0   \n",
       "2                     0.312635                             0.0   \n",
       "3                    -0.927596                             0.0   \n",
       "4                     1.187890                             1.0   \n",
       "...                        ...                             ...   \n",
       "5192                 -1.022479                             0.0   \n",
       "5193                 -0.927596                             0.0   \n",
       "5194                  0.477685                             0.0   \n",
       "5195                  1.991478                             0.0   \n",
       "5196                  0.720172                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  \n",
       "0                                  0.0  \n",
       "1                                  1.0  \n",
       "2                                  1.0  \n",
       "3                                  1.0  \n",
       "4                                  0.0  \n",
       "...                                ...  \n",
       "5192                               1.0  \n",
       "5193                               1.0  \n",
       "5194                               1.0  \n",
       "5195                               1.0  \n",
       "5196                               1.0  \n",
       "\n",
       "[5197 rows x 11 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversión de los datos preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos preprocesados (pipe_df) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las características generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check → Contiene los datos de entrenamiento preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check = pd.DataFrame(pipe_df, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process_Numeric__volatile acidity</th>\n",
       "      <th>Process_Numeric__citric acid</th>\n",
       "      <th>Process_Numeric__chlorides</th>\n",
       "      <th>Process_Numeric__free sulfur dioxide</th>\n",
       "      <th>Process_Numeric__total sulfur dioxide</th>\n",
       "      <th>Process_Numeric__density</th>\n",
       "      <th>Process_Numeric__pH</th>\n",
       "      <th>Process_Numeric__sulphates</th>\n",
       "      <th>Process_Numeric__alcohol</th>\n",
       "      <th>Process_Categorical__class_red</th>\n",
       "      <th>Process_Categorical__class_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>-0.277839</td>\n",
       "      <td>-0.191336</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.831639</td>\n",
       "      <td>-0.433274</td>\n",
       "      <td>-1.146519</td>\n",
       "      <td>-0.036117</td>\n",
       "      <td>-1.034552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.499803</td>\n",
       "      <td>-0.579983</td>\n",
       "      <td>0.200694</td>\n",
       "      <td>0.019098</td>\n",
       "      <td>-1.467980</td>\n",
       "      <td>-0.701377</td>\n",
       "      <td>-0.919534</td>\n",
       "      <td>1.489510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065611</td>\n",
       "      <td>0.289363</td>\n",
       "      <td>-0.684575</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>-1.164893</td>\n",
       "      <td>0.887973</td>\n",
       "      <td>0.514885</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.661389</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>-0.789574</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.594218</td>\n",
       "      <td>-1.437325</td>\n",
       "      <td>0.469593</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>1.636890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>-0.351239</td>\n",
       "      <td>-0.475795</td>\n",
       "      <td>1.255666</td>\n",
       "      <td>0.502182</td>\n",
       "      <td>-1.812097</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.395421</td>\n",
       "      <td>1.414987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>-0.292330</td>\n",
       "      <td>0.080702</td>\n",
       "      <td>0.166421</td>\n",
       "      <td>0.349361</td>\n",
       "      <td>1.050532</td>\n",
       "      <td>1.146368</td>\n",
       "      <td>-1.339665</td>\n",
       "      <td>-0.542576</td>\n",
       "      <td>-1.130887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.842435</td>\n",
       "      <td>0.888607</td>\n",
       "      <td>2.218732</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>-0.940203</td>\n",
       "      <td>1.268510</td>\n",
       "      <td>1.006277</td>\n",
       "      <td>2.132366</td>\n",
       "      <td>-0.475482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.061259</td>\n",
       "      <td>1.143008</td>\n",
       "      <td>-0.114273</td>\n",
       "      <td>-2.309748</td>\n",
       "      <td>-3.358761</td>\n",
       "      <td>-0.015075</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>1.102750</td>\n",
       "      <td>1.339897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>0.784847</td>\n",
       "      <td>-1.039336</td>\n",
       "      <td>0.419088</td>\n",
       "      <td>-1.861014</td>\n",
       "      <td>-3.091298</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>2.329225</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>0.797644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>0.186249</td>\n",
       "      <td>-1.280520</td>\n",
       "      <td>-0.527839</td>\n",
       "      <td>0.609936</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.542123</td>\n",
       "      <td>0.348801</td>\n",
       "      <td>-0.178400</td>\n",
       "      <td>-0.939147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process_Numeric__volatile acidity  Process_Numeric__citric acid  \\\n",
       "0                             -0.065611                     -0.277839   \n",
       "1                              0.061259                     -0.499803   \n",
       "2                             -0.065611                      0.289363   \n",
       "3                             -0.661389                      0.080702   \n",
       "4                              0.061259                     -0.351239   \n",
       "...                                 ...                           ...   \n",
       "1295                          -0.292330                      0.080702   \n",
       "1296                           0.842435                      0.888607   \n",
       "1297                           0.061259                      1.143008   \n",
       "1298                           0.784847                     -1.039336   \n",
       "1299                           0.186249                     -1.280520   \n",
       "\n",
       "      Process_Numeric__chlorides  Process_Numeric__free sulfur dioxide  \\\n",
       "0                      -0.191336                              0.609936   \n",
       "1                      -0.579983                              0.200694   \n",
       "2                      -0.684575                              0.441142   \n",
       "3                      -0.789574                              0.798095   \n",
       "4                      -0.475795                              1.255666   \n",
       "...                          ...                                   ...   \n",
       "1295                    0.166421                              0.349361   \n",
       "1296                    2.218732                              0.527821   \n",
       "1297                   -0.114273                             -2.309748   \n",
       "1298                    0.419088                             -1.861014   \n",
       "1299                   -0.527839                              0.609936   \n",
       "\n",
       "      Process_Numeric__total sulfur dioxide  Process_Numeric__density  \\\n",
       "0                                  0.831639                 -0.433274   \n",
       "1                                  0.019098                 -1.467980   \n",
       "2                                  0.048148                 -1.164893   \n",
       "3                                  0.594218                 -1.437325   \n",
       "4                                  0.502182                 -1.812097   \n",
       "...                                     ...                       ...   \n",
       "1295                               1.050532                  1.146368   \n",
       "1296                              -0.940203                  1.268510   \n",
       "1297                              -3.358761                 -0.015075   \n",
       "1298                              -3.091298                 -0.127250   \n",
       "1299                               0.671446                  0.542123   \n",
       "\n",
       "      Process_Numeric__pH  Process_Numeric__sulphates  \\\n",
       "0               -1.146519                   -0.036117   \n",
       "1               -0.701377                   -0.919534   \n",
       "2                0.887973                    0.514885   \n",
       "3                0.469593                    0.104306   \n",
       "4               -1.339665                   -0.395421   \n",
       "...                   ...                         ...   \n",
       "1295            -1.339665                   -0.542576   \n",
       "1296             1.006277                    2.132366   \n",
       "1297            -0.078471                    1.102750   \n",
       "1298             2.329225                    0.104306   \n",
       "1299             0.348801                   -0.178400   \n",
       "\n",
       "      Process_Numeric__alcohol  Process_Categorical__class_red  \\\n",
       "0                    -1.034552                             0.0   \n",
       "1                     1.489510                             0.0   \n",
       "2                     1.636890                             0.0   \n",
       "3                     1.636890                             0.0   \n",
       "4                     1.414987                             0.0   \n",
       "...                        ...                             ...   \n",
       "1295                 -1.130887                             0.0   \n",
       "1296                 -0.475482                             1.0   \n",
       "1297                  1.339897                             1.0   \n",
       "1298                  0.797644                             1.0   \n",
       "1299                 -0.939147                             0.0   \n",
       "\n",
       "      Process_Categorical__class_white  \n",
       "0                                  1.0  \n",
       "1                                  1.0  \n",
       "2                                  1.0  \n",
       "3                                  1.0  \n",
       "4                                  1.0  \n",
       "...                                ...  \n",
       "1295                               1.0  \n",
       "1296                               0.0  \n",
       "1297                               0.0  \n",
       "1298                               0.0  \n",
       "1299                               1.0  \n",
       "\n",
       "[1300 rows x 11 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversión de los datos de prueba preprocesados a un DataFrame con nombres de columnas.\n",
    "\n",
    "# pd.DataFrame(pipe_df_test, columns=pipe_missings_cat.get_feature_names_out())\n",
    "#    - Convierte los datos de prueba preprocesados (pipe_df_test) en un DataFrame de pandas.\n",
    "#    - Asigna los nombres de las características generados por el ColumnTransformer.\n",
    "#    - Permite verificar que las transformaciones se aplicaron correctamente.\n",
    "\n",
    "# df_check_test → Contiene los datos de prueba preprocesados en formato DataFrame, con nombres de columnas.\n",
    "\n",
    "df_check_test = pd.DataFrame(pipe_df_test, columns= pipe_missings_cat.get_feature_names_out())\n",
    "df_check_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACIÓN DE MODELOS DE CLASIFICACIÓN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic: 0.5470\n",
      "[0.52980769 0.55769231 0.54186718 0.54764196 0.55822907]\n",
      "randomF: 0.6611\n",
      "[0.66442308 0.66153846 0.6612127  0.66506256 0.65351299]\n",
      "Kneighbors: 0.5449\n",
      "[0.55288462 0.55480769 0.53224254 0.54475457 0.53994225]\n",
      "LGBM: 0.6423\n",
      "[0.65       0.63942308 0.64773821 0.63522618 0.63907603]\n"
     ]
    }
   ],
   "source": [
    "logistic_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", LogisticRegression(max_iter=10000))\n",
    "    ])\n",
    "\n",
    "random_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "Kneighbors_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "LGBM_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_cat),\n",
    "     (\"Modelo\", LGBMClassifier(verbose=-1))\n",
    "    ])\n",
    "\n",
    "\n",
    "for name, pipe in zip([\"logistic\",\"randomF\", \"Kneighbors\",\"LGBM\"],[logistic_pipeline, random_pipeline, Kneighbors_pipeline, LGBM_pipeline]):\n",
    "    resultado_\n",
    "    resultado = cross_val_score(pipe, df, y_train_cat, cv = 5, scoring = \"accuracy\")\n",
    "    print(f\"{name}: {np.mean(resultado):.4f}\")\n",
    "    print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACION DE MODELOS DE REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomF: 0.0276\n",
      "[-0.02877444 -0.0284786  -0.02691515 -0.02693453 -0.02710483]\n",
      "XGB: 0.0271\n",
      "[-0.02807295 -0.02796904 -0.02587827 -0.02658056 -0.02686444]\n",
      "LGBM: 0.0287\n",
      "[-0.02986407 -0.02965162 -0.02812008 -0.02791631 -0.02802684]\n"
     ]
    }
   ],
   "source": [
    "randomreg_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_reg),\n",
    "     (\"Modelo\", RandomForestRegressor())\n",
    "    ])\n",
    "\n",
    "XGB_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_reg),\n",
    "     (\"Modelo\", XGBRegressor())\n",
    "    ])\n",
    "\n",
    "LGBMreg_pipeline = Pipeline(\n",
    "    [(\"Preprocesado\", pipe_missings_reg),\n",
    "     (\"Modelo\", LGBMRegressor(verbose=-1))\n",
    "    ])\n",
    "\n",
    "\n",
    "for name, pipe in zip([\"RandomF\",\"XGB\",\"LGBM\"],[randomreg_pipeline, XGB_pipeline, LGBMreg_pipeline]):\n",
    "    resultado_reg = cross_val_score(pipe, df, y_train_reg, cv = 5, scoring = \"neg_mean_absolute_percentage_error\")\n",
    "    print(f\"{name}: {-np.mean(resultado_reg):.4f}\")\n",
    "    print(resultado_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACION DE PARAMETROS DE CLASIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos sus hiperparametros\n",
    "reg_log_param = {    \n",
    "                 \"penalty\": [None,\"l2\"], \n",
    "                 \"C\": np.logspace(0, 4, 10)\n",
    "                }\n",
    "\n",
    "rand_forest_param = {\n",
    "    'n_estimators': [10, 100, 200, 400],\n",
    "    'max_depth': [1,2,4,8],\n",
    "    'max_features': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'Modelo__num_leaves': [15, 31, 50],\n",
    "    'Modelo__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'Modelo__n_estimators': [50, 100, 200],\n",
    "    'Modelo__max_depth': [5, 10, 15],\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    \"Modelo__n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"Modelo__weights\": ['uniform', 'distance'],\n",
    "    \"Modelo__metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "\n",
    "cv = 5\n",
    "\n",
    "gs_reg_log = GridSearchCV(LogisticRegression(),\n",
    "                            reg_log_param,\n",
    "                            cv=cv,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "gs_rand_forest = GridSearchCV(RandomForestClassifier(),\n",
    "                            rand_forest_param,\n",
    "                            cv=cv,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "gs_lgb = GridSearchCV(LGBMClassifier(),\n",
    "                        param_grid_lgbm,\n",
    "                        cv=cv,\n",
    "                        scoring=\"accuracy\",\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=Kneighbors_pipeline,\n",
    "                               param_grid=param_grid_knn,\n",
    "                               scoring='accuracy',\n",
    "                               cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe_grids_cat = {\"gs_reg_log\":gs_reg_log,\n",
    "         \"gs_rand_forest\":gs_rand_forest,\n",
    "         \"gs_lgb\":gs_lgb,\n",
    "         \"gs_Knn\":grid_search_knn}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'white'\n\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'red'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[338], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nombre, grid_search \u001b[38;5;129;01min\u001b[39;00m pipe_grids_cat\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    994\u001b[0m     )\n\u001b[1;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'white'\n\n--------------------------------------------------------------------------------\n80 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'red'\n"
     ]
    }
   ],
   "source": [
    "for nombre, grid_search in pipe_grids_cat.items():\n",
    "    grid_search.fit(df, y_train_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
